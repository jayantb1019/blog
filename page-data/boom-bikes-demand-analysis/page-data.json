{"componentChunkName":"component---node-modules-narative-gatsby-theme-novela-src-templates-article-template-tsx","path":"/boom-bikes-demand-analysis","result":{"pageContext":{"article":{"id":"b86af459-161d-57ec-9fd4-7f55873916ab","slug":"/boom-bikes-demand-analysis","secret":false,"title":"Boom Bikes Demand Analysis","author":"Jayanth Boddu","date":"July 26th, 2020","dateForSEO":"2020-07-26T00:00:00.000Z","timeToRead":5,"excerpt":"Boom Bikes Demand Analysis using Linear Regression","canonical_url":null,"subscription":true,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Boom Bikes Demand Analysis\",\n  \"author\": \"Jayanth Boddu\",\n  \"date\": \"2020-07-26T00:00:00.000Z\",\n  \"hero\": \"./output_93_0.png\",\n  \"excerpt\": \"Boom Bikes Demand Analysis using Linear Regression\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h2\", {\n    \"id\": \"problem-statement\"\n  }, \"Problem Statement\"), mdx(\"p\", null, \"A bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \\u201Cdock\\u201D which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\"), mdx(\"p\", null, \"A US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state.\"), mdx(\"p\", null, \"In such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people\\u2019s needs once the situation gets better all around and stand out from other service providers and make huge profits.\"), mdx(\"p\", null, \"They have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Which variables are significant in predicting the demand for shared bikes.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How well those variables describe the bike demands\", mdx(\"br\", {\n    parentName: \"li\"\n  }), \"Based on various meteorological surveys and people\\u2019s styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors.\")), mdx(\"h2\", {\n    \"id\": \"business-goals\"\n  }, \"Business Goals\"), mdx(\"p\", null, \"The company needs to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer\\u2019s expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market.\"), mdx(\"h2\", {\n    \"id\": \"analysis-approach--conclusions\"\n  }, \"Analysis Approach & Conclusions\"), mdx(\"p\", null, \"This problem can be solved using Multiple Linear Regression Analysis. The company requires a two fold solution.\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"A model to predict demand with accuracy.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Insight into the significant relationships that exist between demand and available predictors.\")), mdx(\"p\", null, \"Analysis is carried out using a Mixed Feature Selection Approach. 15 features are selected algorithmically using Recursive Feature Elimination. Further selection is done manually by looking at multicollinearity and statistical significance of features and overall fit of the model.\\nThe 10 most significant features to understand demand have been reported.\"), mdx(\"p\", null, \"The data set is randomly divided into training and test data.\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Final Model\"), \" built on training data set explains 84% of the variability and achieves 81% on test data.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"The final relationship between demand and predictors is as follows.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cnt\"), \" = 2392.0791 + 1946.7864 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"yr\"), \" + 444.4907 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Saturday\"), \" + 466.0136 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"winter\"), \" - 890.3115 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"july\"), \" -1063.6669 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"spring\"), \" + 296.8008 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"workingday\"), \" - 1749.8275 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"hum\"), \" + 4471.6602 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"temp\"), \" - 1110.3191 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"windspeed\"), \" - 1273.7519 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"light snow/rain\"))), mdx(\"p\", null, \"where \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"temp\"), \" , \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"windspeed\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"hum\"), \" are normalized.\"), mdx(\"p\", null, \"Note :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Data has been cleaned to drop outliers that might affect the model adversely\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The model has been verified for Multicollinearity effects.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Residual Analysis has been carried out and the model satisfies the assumptions of Linear Regression (Residuals follow a normal distribution, Errors exhibit homoscedasticity)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Q-Q plot between residual distribution and normal distribution shows that residuals approximately follow a normal distribution. Some points significant deviation which deems further analysis\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Further Lag plot shows there is no auto-correlation in data.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Model is stable at 81%(+/-14%) coefficient of determination at 95% CI, ascertained through cross validation.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Features in the order of influence has been reported by standardizing all predictor values.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Outliers dropped during Data Understanding phase deems further analysis from business perspective.\")), mdx(\"h2\", {\n    \"id\": \"reading-and-understanding-data\"\n  }, \"Reading and Understanding Data\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data = pd.read_csv('./day.csv')\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data.head()\\n\")), mdx(\"h3\", {\n    \"id\": \"data-quality-checks\"\n  }, \"Data Quality Checks\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data.info()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"<class 'pandas.core.frame.DataFrame'>\\nRangeIndex: 730 entries, 0 to 729\\nData columns (total 16 columns):\\n #   Column      Non-Null Count  Dtype\\n---  ------      --------------  -----\\n 0   instant     730 non-null    int64\\n 1   dteday      730 non-null    object\\n 2   season      730 non-null    int64\\n 3   yr          730 non-null    int64\\n 4   mnth        730 non-null    int64\\n 5   holiday     730 non-null    int64\\n 6   weekday     730 non-null    int64\\n 7   workingday  730 non-null    int64\\n 8   weathersit  730 non-null    int64\\n 9   temp        730 non-null    float64\\n 10  atemp       730 non-null    float64\\n 11  hum         730 non-null    float64\\n 12  windspeed   730 non-null    float64\\n 13  casual      730 non-null    int64\\n 14  registered  730 non-null    int64\\n 15  cnt         730 non-null    int64\\ndtypes: float64(4), int64(11), object(1)\\nmemory usage: 91.4+ KB\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"No missing values\")), mdx(\"h3\", {\n    \"id\": \"visualizing-continuous-variables\"\n  }, \"Visualizing Continuous Variables\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# dropping `instant`,`dteday`,`casual`,`registered`\\n\\ndata = data.drop(columns=['instant','dteday','casual','registered'])\\n\")), mdx(\"p\", null, \"These variables were dropped since \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"instant\"), \" is the just the serial number of the record,\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"dteday\"), \" is redundant coz the required data for analysis is contained in mnth,yr\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"casual\"), \" + \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"registered\"), \" = \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"cnt\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# summary statistics of numerical variables\\ndata[['temp','atemp','hum','windspeed']].describe()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Scatter Plots of Continuous variables vs 'cnt'\\nsns.set_style(\\\"whitegrid\\\")\\nsns.pairplot(data=data,x_vars=['temp','atemp','hum','windspeed'],y_vars='cnt',kind='scatter',height=5,aspect=1);\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1455px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"25.42955326460481%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAABFUlEQVQY0yWQy07DQAxF+/8/wZIFEhskFgiVBQiBREt5qIiolDQFJaRp0rwm88zFdhczI9v3nrE98d5jHAOdEeu8Rd4MEtMF6zxWfw16bSVmTdEOiItONNo6fO9aVL3BGI6MiXMOgQIWXS9T3Ea5xAz7TGtcLH7kJaLknzclzp4SHAjSDhbnsy1m8R7KMIeAwTvUyuDqPcXNR4aXpKKCR3pQuHz9xXSZYcMdSQcBczKf3K0RZTUa8p0+xpiSr+q0fEhAj7dthfvVDh2PhuOoD1+FdOOozuN6H8QQZQ3mlI+LVnSLpKQOS+wJ6DwDSdQNBkobWGvBO7W0ho7GUYOGMQa8Fs47AmhjZXc9eVhnyNOTjg9r/gGai3zYJLzxJAAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/55fa9c8f9d76ef823f79b85f1626f213/4731d/output_15_0.webp 1455w\"],\n    \"sizes\": \"(max-width: 1455px) 100vw, 1455px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/55fa9c8f9d76ef823f79b85f1626f213/8df0c/output_15_0.png 1455w\"],\n    \"sizes\": \"(max-width: 1455px) 100vw, 1455px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/55fa9c8f9d76ef823f79b85f1626f213/8df0c/output_15_0.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The number of rentals per day seem to be increasing with temperature and adjusted temperature\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"adjusted temperature and temperature have similar trends\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"temp vs cnt has two outliers between 15 and 30\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"atemp vs cnt has two outliers between 20 and 35\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"hum vs cnt has two outliers below 20\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"windspeed vs cnt has one outlier above 30\")), mdx(\"h3\", {\n    \"id\": \"outliers-in-continuous-variables-vs-cnt\"\n  }, \"Outliers in Continuous Variables vs cnt\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"## Dropping outliers in continuous variables\\n# outliers in temp\\ndata = data.drop(index = data[(data['temp'] > 15) & (data['temp'] < 20) & (data['cnt'] < 100)].index)\\ndata = data.drop(index = data[(data['temp'] > 25) & (data['temp'] < 30) & (data['cnt'] < 2000)].index)\\n\\n\\n# outliers in atemp\\ndata = data.drop(index = data[(data['atemp'] > 20) & (data['atemp'] < 25) & (data['cnt'] < 100)].index)\\ndata = data.drop(index = data[(data['atemp'] > 30) & (data['atemp'] < 35) & (data['cnt'] < 2000)].index)\\n\\n\\n#outliers in hum\\ndata = data.drop(index = data[(data['hum'] < 20)].index)\\n\\n#outliers in windspeed\\ndata = data.drop(index = data[(data['windspeed'] > 30)].index)\\n\\n\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Looking at correlation with continuous variables\\ncorrelation = data[['temp','atemp','hum','windspeed','cnt']].corr()['cnt'].apply(lambda x : round(x,4))\\ncorrelation = pd.DataFrame(correlation).sort_values(by='cnt',ascending=False)\\ncorrelation.drop(index=['cnt'],inplace=True)\\n# dropping registered,casual, instant\\ncorrelation.style.background_gradient(cmap='GnBu')\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"There\\u2019s no signifcant correlation between \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"atemp\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"hum\"), \" , \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"windspeed\"), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Hence these are not dropped for now.\")), mdx(\"h3\", {\n    \"id\": \"visualizing-categorical-variables\"\n  }, \"Visualizing Categorical Variables\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Converting variables into categorical type\\ndata[['season','weathersit','mnth']] = data[['season','weathersit','mnth']].astype('category')\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Unique values in each categorical variable / [To check for disguised missing values]\\ncat_vars = ['season','yr','mnth','holiday','weekday','workingday','weathersit']\\nfor i in cat_vars :\\n    print('Unique values in ',i, data[i].unique())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Unique values in  season [1, 2, 3, 4]\\nCategories (4, int64): [1, 2, 3, 4]\\nUnique values in  yr [0 1]\\nUnique values in  mnth [1, 2, 3, 4, 5, ..., 8, 9, 10, 11, 12]\\nLength: 12\\nCategories (12, int64): [1, 2, 3, 4, ..., 9, 10, 11, 12]\\nUnique values in  holiday [0 1]\\nUnique values in  weekday [6 0 1 2 3 4 5]\\nUnique values in  workingday [0 1]\\nUnique values in  weathersit [2, 1, 3]\\nCategories (3, int64): [2, 1, 3]\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"No disguised missing values exist\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Replacing numbers with labels\\nseason_labels = {\\n    1 : 'spring',\\n    2 : 'summer',\\n    3 : 'fall',\\n    4 : 'winter'\\n}\\n\\nmnth_labels = {\\n    1 : 'january',\\n    2 : 'february',\\n    3 : 'march',\\n    4 : 'april',\\n    5 : 'may',\\n    6 : 'june',\\n    7 : 'july',\\n    8 : 'august',\\n    9 : 'september',\\n    10 : 'october',\\n    11 : 'november',\\n    12 : 'december'\\n}\\n\\nweekday_labels = { # considering the first row of dteday to be 01-01-2011\\n    0 : 'Sunday',\\n    1 : 'Monday',\\n    2 : 'Tuesday',\\n    3 : 'Wednesday',\\n    4 : 'Thursday',\\n    5 : 'Friday',\\n    6 : 'Saturday'\\n}\\n\\nweathersit_labels = {\\n    1 : 'clear',\\n    2 : 'cloudy',\\n    3 : 'light snow/rain'\\n}\\n\\n# replacing numerals with labels\\ndata['season'] = data['season'].replace(season_labels)\\ndata['mnth'] = data['mnth'].replace(mnth_labels)\\ndata['weekday'] = data['weekday'].replace(weekday_labels)\\ndata['weathersit'] = data['weathersit'].replace(weathersit_labels)\\n\\ndata.head()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"cat_vars = ['season','yr','mnth','holiday','weekday',  'workingday','weathersit']\\ndata1 = data[cat_vars]\\ndata1.loc[:,'cnt'] = data['cnt'].values\\ndata1[['yr','holiday','workingday']] = data1[['yr','holiday','workingday']].astype('category')\\nplot_dim = [3,3]\\nfig,axs = plt.subplots(*plot_dim)\\nfig.set_figheight(15)\\nfig.set_figwidth(20)\\nfor i in range(plot_dim[0]) :\\n    for j in range(plot_dim[1]) :\\n        axs[i,j].set(title = i*plot_dim[1]+j)\\n        sns.boxplot(data=data1,x='cnt',y=cat_vars[i*plot_dim[1]+j],width=0.4,ax=axs[i,j])\\n        if i*plot_dim[1]+j == 6 :\\n            break\\naxs[2,1].set_axis_off()\\naxs[2,2].set_axis_off()\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1214px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"71.82866556836903%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAACdUlEQVQ4y41Ta2/TQBD0H+bPIB4fQAIhUBFCSK0CErRFTZOqJA1NmkalebWqmzhJlZcd2+fznT3s3jVVhPjQk6zc7e3Ozs5NnCzPgUyj3h2g3vdAJ6Q6Q5ZlyOkuozt3ssDNeEZpysTSNIVIEkyuuhh2ziFpz4Vc42itoShhPPMxGNwian6Hmo+hKUETADd7Xqjg2dca1ktKiTiO4S+maLeOcFQrwLsbEI6Co5QCf9wip+KDxjYq7RLtGVATnjYg6WqK8LYFlURIEgkhhIkrmmanVsFeowFNxBwegTumRHd2dY36tx2M5hPTjUeQiQBDBpdFuO+fIJxcI4wlVkGAKIow6A9wUu3ioudRo8QC5lSYEpNcRFS5pDFJJ2X1YoYxMZqFEoGw07CGRsdYkDw+0ZdmOp7IYdqaaBMKqm0XH4pNBFFsmrDwDDD0PByWiuhc3RgW+l4GSaCFkzY+lZpYEbgBZBacxKvUm+Pl/iX8SFBTK3xKo4fBHNVfX+DeXpIMOemmzEPGpONWuYM3hz0iQYCKNGRbML9o1EV4/BbZ2Weo2DfW8X2fmgmMvTvsb23jrFw1rJiJlJYERk2kpx+hxYqVYoaZiftuC6MfTzE+eIUVPQr7URDDhAoXsznqu8do/z4nVrF5LEVsJHlr+qeM4e4LRP4MUvHIbBgCNSzpEGWwYxkrWbNa+5DR7+P8a7VXsOrbmgcNzYtR53d7p9htutZ3FOO79coN543z+o4nzPRD3OFCFpjXctjH8OdrBMMO+RLmpdfFj/0cNnAiBVreBcLlBKFLIocLrKX4F3Dz/L+9w9qEIkShUSC7rKxuuf3bbSY+dv0FWSwwcKCLoQoAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/fb58fffdaad9db38daf97d9a6821e7cb/5eb99/output_31_0.webp 1214w\"],\n    \"sizes\": \"(max-width: 1214px) 100vw, 1214px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/fb58fffdaad9db38daf97d9a6821e7cb/443e8/output_31_0.png 1214w\"],\n    \"sizes\": \"(max-width: 1214px) 100vw, 1214px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/fb58fffdaad9db38daf97d9a6821e7cb/443e8/output_31_0.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"From the season vs rentals per day plot , fall has the highest average rentals followed by summer.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Looking at year by year rentals, 2019 has had a median 2000 increase in rentals compared to 2018.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"From the month wise plot, September has the highest rentals, followed by the two months surrounding it. It seems like the trend is explained by seasonal rentals too\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Holidays show lower rental count compared to working days, with greater variability in demand on holidays.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"There is no significant difference between rentals vs weekdays, except that Thursdays and sundays have a higher variation in rentals than others.\")), mdx(\"h3\", {\n    \"id\": \"outliers-in-categorical-variables-vs-cnt\"\n  }, \"Outliers in Categorical Variables vs cnt\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Dropping outliers in Categorical Variables\\ndata = data.drop(index = data[(data['season'] == 'spring') & (data['cnt'] > 7000)].index)\\n\\n\")), mdx(\"h3\", {\n    \"id\": \"correlation\"\n  }, \"Correlation\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# correlation among variables\\nplt.figure(figsize=[10,10])\\nsns.heatmap(data.corr(),cmap='GnBu',center=0,annot=True)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"<matplotlib.axes._subplots.AxesSubplot at 0x7fde4bfdd610>\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"558px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"103.40501792114696%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsSAAALEgHS3X78AAAFhklEQVQ4yzWUe0yb5xXGP23qNGlrN03btK7dVG1SU3XTVu2fqqrUNl2T/jVNmiKSbEmkpFpJxbIQoIABAyN0DU1IyHUEsoT0stBLCgR8x/fvM9gONhcbCBeDjU3AXBIbmmSNqt+OXe2PR6+s7/XzPs85zzlKaiXLwfduUPheD1dCo3QnZ/ksNkVXfJrrc9N0zs4KZjAvTGBfjNIbn6QnMUNH5BYlXaNU3Bhj8e49jn+kEo0tooRuJVGer85jV2cXxV4zR3xODjuMFKsOCp1OCh0OGsMWmm52o7/ZT6nc2d1j5YdVBp6oNTKWusvzRR1oEeEam7nNY6818t3XjvLXHhN1wxrVQRV9wCOnRqlvgLIBH82jTs5Hrfwz7KY+pFJocfNUvZkt71iZuJ1he203/qkllFR2gwPXDez7pI/njrTy+M5m9l/+iGvzVs5HrKLIS42gIeQWlW5qhzxUDWlU+j383W6nxOVkIZPllQYTztE4SvzuuvzJTeWAnSd3NaM8U8HuU21Sq246Jo3oB23U+KzUBuWOx0K1kJc4zOiDLppCVk4M21i6t8krTU4GZ1dQJhdT1MiL5YNunn3zDN9+uZ4/n77EtalezoX78or+j7qhr9XqciWRszHs4t1hN4ubG7x+2kswvo6SfnCfmqCXaqlZS6CXyyNd7DrVzve2NfDbQxc4rGoUaz55UBV4qZK7OUdVQpr7ViLfFjY2+WPrANrUbZTYappqn4NK1cbVKRO9iR4KTrTlrf9sTwuHPV7ptsrbQljisuXVVapWdAGVQy4PxW4Pyc17FFwJEJxfRYkk4tSF/fkXW6MWPl2wsqf1fb7/hyZ+daiVfV397OvulziplAUG8wobRzzopCl7jSoHLBrxzCZ7r4UYuZ1FSWQylPl8HNFydfFQH7RTPuAVOz52/sfIdyROj25vZEdnP284g+j9bq6Ik3JpzOO6Pp7SGxiX2BT2jBGYT6NMp9Mc8WocEuk1QYFmzter2Oul4EMD33xBzyMv1lLwqYOD2lC+MZfGeymxGvlBqYGfVhiILGY4bJ1gePGu5HAjQ11Ik+6p+csNIyoVfqnZUJADvXa2FLWx5W9tbD15na1nhMjUR2fCyjuDZl48Z+TVVhOzq1nKXNNMrH2BsnI/y5lRCy2ChiGXNMien5QyGbvSAY231Ju86fLzxO6TKL+p5C+n2/ls7gaXJwycjto4N24jfX8DnTbL2LIoTKwtc3bMSsuI+WtCrT/foFKvQ+Kisr/fzz6zjx/tEMJnKtl7/t+YV4x8OGuiKWylWYK9LIQNgSmi6fWcwk2aRj28O+LOW64N+0Sh5C3kyxPXSoD18ntP61V2HL/IrpZ2dp5s5633P6BtykbbpI2cy+PhCeYkj0pKUq4bcFMuFnUS7jK3NT9elaL0aMjJv8aMAgMfz5swpY3syGX06Up+/UYzH8g0dURusPYgy9lIhNk7d1CiC3GOyobJzWYuY29rjjxh1aAzP1rtkxaBmauTfVyP9/KnYxdRntXx3MFTklkz12Im1v+b5dLkCNNrEptIcpltV5xsvdRPuebmWETIAl7Kg36KHF62txl5vd3IsaCFyzE7ddbPKRK7+y928FLFOX5fdYHY0iofzw2T+iIj+zC5zi/+YZHdZqHYbpMlapIpUCnqd1DwuZMflxv5iWStzGnhRNhM2y0b3SnZQoZOlN/V8I0X6hiLLdGXGiKZXROFqXWebrTyy0YzpW4HJ6NiXea0dDDAXoPKk9VGfq43ovPaODth50JExlNyWN37Cd96qZ7HtjUyPr+MfSnAwh1ZsPcffoV/boXB2ApTqysMz0/nT3XyFqFECtd4Emc0QezOGlPpJIlMmpFYhIlkHOfNGdyhGe49eEjmyyxffvWQ/wEqc+w6W3LlxwAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/280f33370459e073e9d90e18e34b9d86/c9b7d/output_36_1.webp 558w\"],\n    \"sizes\": \"(max-width: 558px) 100vw, 558px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/280f33370459e073e9d90e18e34b9d86/df9f3/output_36_1.png 558w\"],\n    \"sizes\": \"(max-width: 558px) 100vw, 558px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/280f33370459e073e9d90e18e34b9d86/df9f3/output_36_1.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Highest correlation with \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cnt\"), \" is seen in \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"temp\"), \" followed by \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"yr\"))), mdx(\"h2\", {\n    \"id\": \"data-preparation\"\n  }, \"Data Preparation\"), mdx(\"h3\", {\n    \"id\": \"creating-indictor-variables\"\n  }, \"Creating Indictor Variables\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# creating indicator variable columns\\nseason_indicators = pd.get_dummies(data['season'],drop_first=True)\\nmnth_indicators = pd.get_dummies(data['mnth'],drop_first=True)\\nweekday_indicators = pd.get_dummies(data['weekday'],drop_first=True)\\nweathersit_indicators = pd.get_dummies(data['weathersit'],drop_first=True)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# adding indicator variable columns to the dataset . Dropping original columns\\ndata = pd.concat([data,season_indicators,mnth_indicators,weekday_indicators,weathersit_indicators],axis=1)\\ndata = data.drop(columns=['season','mnth','weekday','weathersit'])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data.head()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data.columns\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Index(['yr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'cnt',\\n       'spring', 'summer', 'winter', 'august', 'december', 'february',\\n       'january', 'july', 'june', 'march', 'may', 'november', 'october',\\n       'september', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\\n       'Wednesday', 'cloudy', 'light snow/rain'],\\n      dtype='object')\\n\")), mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"Variable\"), mdx(\"th\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"Reference Label\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"season\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"fall\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"mnth\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"april\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"weekday\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"Friday\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"weathersit\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"clear\")))), mdx(\"h3\", {\n    \"id\": \"splitting-the-data-set-into-test--train-subsets\"\n  }, \"Splitting the data set into Test & Train subsets\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.model_selection import train_test_split\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"dtrain,dtest = train_test_split(data,train_size=0.7,test_size=0.3,random_state=120)\\n\")), mdx(\"h3\", {\n    \"id\": \"scaling-numerical-features\"\n  }, \"Scaling Numerical Features\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# normalization of continuous variables\\nfrom sklearn.preprocessing import MinMaxScaler\\nnumerical_scaler = MinMaxScaler()\\nnum_vars = ['temp','hum','windspeed']\\n\\nnumerical_scaler.fit(dtrain[num_vars])\\ndtrain[num_vars] = numerical_scaler.transform(dtrain[num_vars])\\n\")), mdx(\"h4\", {\n    \"id\": \"x_train--y_train\"\n  }, \"X_train , y_train\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"y_train = dtrain.pop('cnt')\\nX_train = dtrain\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"y_train.head()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"231    5191\\n717    5267\\n107    3429\\n595    4549\\n485    5740\\nName: cnt, dtype: int64\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_train.head()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_train.columns\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Index(['yr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'spring',\\n       'summer', 'winter', 'august', 'december', 'february', 'january', 'july',\\n       'june', 'march', 'may', 'november', 'october', 'september', 'Monday',\\n       'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', 'cloudy',\\n       'light snow/rain'],\\n      dtype='object')\\n\")), mdx(\"h2\", {\n    \"id\": \"modelling\"\n  }, \"Modelling\"), mdx(\"p\", null, \"Approach\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A mixed approach is followed.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"15 Best columns are chosen using RFE\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"And then p-value method is followed for further elimination.\")), mdx(\"h4\", {\n    \"id\": \"recursive-feature-elimination\"\n  }, \"Recursive Feature Elimination\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Selecting 15 Features using RFE\\n\\nfrom sklearn.feature_selection import RFE\\nfrom sklearn.linear_model import LinearRegression\\n\\nlr_estimator = LinearRegression()\\nrfe = RFE(lr_estimator,n_features_to_select=15, step=1)\\nselector = rfe.fit(X_train,y_train)\\n\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# RFE Feature Ranking\\nrfe_ranking = pd.DataFrame({'rank' : selector.ranking_, 'support': selector.support_, 'features' : X_train.columns}).sort_values(by='rank',ascending=True)\\nrfe_ranking\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Selected Features\\nselected_features = rfe_ranking.loc[rfe_ranking['rank'] == 1,'features'].values\\nselected_features\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"array(['yr', 'Sunday', 'Saturday', 'november', 'january', 'december',\\n       'winter', 'july', 'spring', 'holiday', 'workingday', 'hum', 'temp',\\n       'windspeed', 'light snow/rain'], dtype=object)\\n\")), mdx(\"h3\", {\n    \"id\": \"manual-elimination\"\n  }, \"Manual Elimination\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Following a stepwise elimination\\nimport statsmodels.api as sm\\ndef ols_fit(y,X) :\\n    X_train_sm = sm.add_constant(X)\\n    model = sm.OLS(y,X_train_sm).fit()\\n    print(model.summary())\\n    return model\\ndef vif(X) :\\n    df = sm.add_constant(X)\\n    vif = [variance_inflation_factor(df.values,i) for i in range(df.shape[1])]\\n    vif_frame = pd.DataFrame({'vif' : vif[0:]},index = df.columns).reset_index()\\n    print(vif_frame.sort_values(by='vif',ascending=False))\\n\")), mdx(\"h4\", {\n    \"id\": \"model-1\"\n  }, \"Model 1\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Using features selected by RFE : \\u2018yr\\u2019, \\u2018Sunday\\u2019, \\u2018Saturday\\u2019, \\u2018november\\u2019, \\u2018january\\u2019, \\u2018december\\u2019,\\n\\u2018winter\\u2019, \\u2018july\\u2019, \\u2018spring\\u2019, \\u2018holiday\\u2019, \\u2018workingday\\u2019, \\u2018hum\\u2019, \\u2018temp\\u2019,\\n\\u2018windspeed\\u2019, \\u2018light snow/rain\\u2019\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"features_1 = selected_features\\nols_fit(y_train,X_train[features_1])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.844\\nModel:                            OLS   Adj. R-squared:                  0.840\\nMethod:                 Least Squares   F-statistic:                     189.8\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          9.27e-188\\nTime:                        20:41:57   Log-Likelihood:                -4072.4\\nNo. Observations:                 506   AIC:                             8175.\\nDf Residuals:                     491   BIC:                             8238.\\nDf Model:                          14\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2278.2820    192.838     11.815      0.000    1899.393    2657.171\\nyr               1959.7590     69.543     28.180      0.000    1823.120    2096.398\\nSunday            497.0421     97.123      5.118      0.000     306.214     687.871\\nSaturday          874.2613     95.093      9.194      0.000     687.422    1061.101\\nnovember         -617.4927    158.994     -3.884      0.000    -929.885    -305.100\\njanuary          -391.9320    149.160     -2.628      0.009    -685.002     -98.862\\ndecember         -475.8630    142.634     -3.336      0.001    -756.112    -195.614\\nwinter            687.2832    121.588      5.653      0.000     448.387     926.180\\njuly             -804.3128    141.415     -5.688      0.000   -1082.166    -526.459\\nspring          -1010.6061    134.437     -7.517      0.000   -1274.749    -746.464\\nholiday           165.4153    160.101      1.033      0.302    -149.152     479.982\\nworkingday        741.5633     73.655     10.068      0.000     596.846     886.280\\nhum             -1782.6033    198.667     -8.973      0.000   -2172.947   -1392.260\\ntemp             4036.2727    275.497     14.651      0.000    3494.974    4577.571\\nwindspeed       -1167.6983    188.628     -6.190      0.000   -1538.315    -797.081\\nlight snow/rain -1276.7947    234.425     -5.446      0.000   -1737.395    -816.194\\n==============================================================================\\nOmnibus:                       74.940   Durbin-Watson:                   1.920\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              164.191\\nSkew:                          -0.800   Prob(JB):                     2.22e-36\\nKurtosis:                       5.286   Cond. No.                     6.67e+15\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n[2] The smallest eigenvalue is 3.03e-29. This might indicate that there are\\nstrong multicollinearity problems or that the design matrix is singular.\\n              index       vif\\n2            Sunday       inf\\n3          Saturday       inf\\n10          holiday       inf\\n11       workingday       inf\\n13             temp  3.530342\\n9            spring  2.972066\\n7            winter  2.265754\\n5           january  1.667765\\n4          november  1.649107\\n6          december  1.384399\\n8              july  1.332786\\n12              hum  1.302061\\n15  light snow/rain  1.179013\\n14        windspeed  1.161178\\n1                yr  1.035227\\n0             const  0.000000\\n\")), mdx(\"h4\", {\n    \"id\": \"model-2-\"\n  }, \"Model 2 :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"holiday\"), \" because of high p-value\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"del_feature = 'holiday'\\nselected_features = selected_features[selected_features!=del_feature]\\nols_fit(y_train,X_train[selected_features])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.844\\nModel:                            OLS   Adj. R-squared:                  0.840\\nMethod:                 Least Squares   F-statistic:                     189.8\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          9.27e-188\\nTime:                        20:41:57   Log-Likelihood:                -4072.4\\nNo. Observations:                 506   AIC:                             8175.\\nDf Residuals:                     491   BIC:                             8238.\\nDf Model:                          14\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2443.6973    302.113      8.089      0.000    1850.103    3037.291\\nyr               1959.7590     69.543     28.180      0.000    1823.120    2096.398\\nSunday            331.6268    208.945      1.587      0.113     -78.910     742.164\\nSaturday          708.8460    208.062      3.407      0.001     300.043    1117.649\\nnovember         -617.4927    158.994     -3.884      0.000    -929.885    -305.100\\njanuary          -391.9320    149.160     -2.628      0.009    -685.002     -98.862\\ndecember         -475.8630    142.634     -3.336      0.001    -756.112    -195.614\\nwinter            687.2832    121.588      5.653      0.000     448.387     926.180\\njuly             -804.3128    141.415     -5.688      0.000   -1082.166    -526.459\\nspring          -1010.6061    134.437     -7.517      0.000   -1274.749    -746.464\\nworkingday        576.1480    191.468      3.009      0.003     199.950     952.346\\nhum             -1782.6033    198.667     -8.973      0.000   -2172.947   -1392.260\\ntemp             4036.2727    275.497     14.651      0.000    3494.974    4577.571\\nwindspeed       -1167.6983    188.628     -6.190      0.000   -1538.315    -797.081\\nlight snow/rain -1276.7947    234.425     -5.446      0.000   -1737.395    -816.194\\n==============================================================================\\nOmnibus:                       74.940   Durbin-Watson:                   1.920\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              164.191\\nSkew:                          -0.800   Prob(JB):                     2.22e-36\\nKurtosis:                       5.286   Cond. No.                         20.6\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n              index        vif\\n0             const  78.227579\\n10       workingday   6.747604\\n3          Saturday   4.580552\\n2            Sunday   4.352788\\n12             temp   3.530342\\n9            spring   2.972066\\n7            winter   2.265754\\n5           january   1.667765\\n4          november   1.649107\\n6          december   1.384399\\n8              july   1.332786\\n11              hum   1.302061\\n14  light snow/rain   1.179013\\n13        windspeed   1.161178\\n1                yr   1.035227\\n\")), mdx(\"h4\", {\n    \"id\": \"model-3-\"\n  }, \"Model 3 :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Sunday\"), \" because of high p-value\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"del_feature = 'Sunday'\\nselected_features = selected_features[selected_features!=del_feature]\\nols_fit(y_train,X_train[selected_features])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.843\\nModel:                            OLS   Adj. R-squared:                  0.839\\nMethod:                 Least Squares   F-statistic:                     203.6\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          2.22e-188\\nTime:                        20:41:57   Log-Likelihood:                -4073.7\\nNo. Observations:                 506   AIC:                             8175.\\nDf Residuals:                     492   BIC:                             8234.\\nDf Model:                          13\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2717.6842    248.317     10.944      0.000    2229.791    3205.578\\nyr               1958.8083     69.648     28.124      0.000    1821.964    2095.652\\nSaturday          442.9774    123.597      3.584      0.000     200.134     685.820\\nnovember         -627.3327    159.118     -3.943      0.000    -939.968    -314.698\\njanuary          -391.6152    149.390     -2.621      0.009    -685.136     -98.095\\ndecember         -485.7607    142.718     -3.404      0.001    -766.172    -205.350\\nwinter            687.9955    121.774      5.650      0.000     448.733     927.258\\njuly             -808.0743    141.613     -5.706      0.000   -1086.316    -529.833\\nspring          -1018.8530    134.544     -7.573      0.000   -1283.204    -754.502\\nworkingday        310.9383     93.623      3.321      0.001     126.989     494.888\\nhum             -1777.8858    198.952     -8.936      0.000   -2168.785   -1386.986\\ntemp             4023.0506    275.796     14.587      0.000    3481.168    4564.933\\nwindspeed       -1166.7398    188.918     -6.176      0.000   -1537.925    -795.555\\nlight snow/rain -1274.2371    234.781     -5.427      0.000   -1735.535    -812.939\\n==============================================================================\\nOmnibus:                       76.586   Durbin-Watson:                   1.907\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              168.964\\nSkew:                          -0.814   Prob(JB):                     2.04e-37\\nKurtosis:                       5.316   Cond. No.                         17.6\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n              index        vif\\n0             const  52.686107\\n11             temp   3.527114\\n8            spring   2.967626\\n6            winter   2.265723\\n4           january   1.667762\\n3          november   1.646599\\n2          Saturday   1.611416\\n9        workingday   1.608346\\n5          december   1.381753\\n7              july   1.332412\\n10              hum   1.301769\\n13  light snow/rain   1.178957\\n12        windspeed   1.161167\\n1                yr   1.035151\\n\")), mdx(\"h4\", {\n    \"id\": \"model-4\"\n  }, \"Model 4\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"january\"), \" because this information might also be contained in \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"winter\"), \".\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"del_feature = 'january'\\nselected_features = selected_features[selected_features!=del_feature]\\nols_fit(y_train,X_train[selected_features])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.841\\nModel:                            OLS   Adj. R-squared:                  0.837\\nMethod:                 Least Squares   F-statistic:                     217.4\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          4.41e-188\\nTime:                        20:41:58   Log-Likelihood:                -4077.2\\nNo. Observations:                 506   AIC:                             8180.\\nDf Residuals:                     493   BIC:                             8235.\\nDf Model:                          12\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2563.5282    242.686     10.563      0.000    2086.701    3040.355\\nyr               1951.9279     70.012     27.880      0.000    1814.370    2089.486\\nSaturday          437.2585    124.312      3.517      0.000     193.013     681.504\\nnovember         -576.6481    158.877     -3.630      0.000    -888.808    -264.489\\ndecember         -380.3554    137.749     -2.761      0.006    -651.004    -109.707\\nwinter            696.8818    122.450      5.691      0.000     456.294     937.470\\njuly             -846.1814    141.702     -5.972      0.000   -1124.595    -567.768\\nspring          -1101.5863    131.566     -8.373      0.000   -1360.086    -843.087\\nworkingday        310.1011     94.178      3.293      0.001     125.061     495.141\\nhum             -1775.7238    200.131     -8.873      0.000   -2168.939   -1382.508\\ntemp             4232.4252    265.545     15.939      0.000    3710.686    4754.164\\nwindspeed       -1126.2015    189.402     -5.946      0.000   -1498.335    -754.068\\nlight snow/rain -1259.9614    236.112     -5.336      0.000   -1723.871    -796.052\\n==============================================================================\\nOmnibus:                       70.215   Durbin-Watson:                   1.923\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              144.730\\nSkew:                          -0.775   Prob(JB):                     3.74e-32\\nKurtosis:                       5.112   Cond. No.                         16.9\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n              index        vif\\n0             const  49.731331\\n10             temp   3.231303\\n7            spring   2.804334\\n5            winter   2.263968\\n3          november   1.622287\\n2          Saturday   1.610914\\n8        workingday   1.608327\\n6              july   1.318372\\n9               hum   1.301747\\n4          december   1.272074\\n12  light snow/rain   1.178323\\n11        windspeed   1.153386\\n1                yr   1.033680\\n\")), mdx(\"h4\", {\n    \"id\": \"model-5\"\n  }, \"Model 5\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"december\"), \" because this information might also be contained in \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"winter\"), \".\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"del_feature = 'december'\\nselected_features = selected_features[selected_features!=del_feature]\\nols_fit(y_train,X_train[selected_features])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.839\\nModel:                            OLS   Adj. R-squared:                  0.835\\nMethod:                 Least Squares   F-statistic:                     233.3\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          1.22e-187\\nTime:                        20:41:58   Log-Likelihood:                -4081.1\\nNo. Observations:                 506   AIC:                             8186.\\nDf Residuals:                     494   BIC:                             8237.\\nDf Model:                          11\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2484.0272    242.583     10.240      0.000    2007.406    2960.648\\nyr               1945.4495     70.440     27.619      0.000    1807.051    2083.848\\nSaturday          435.8371    125.141      3.483      0.001     189.962     681.712\\nnovember         -443.0313    152.340     -2.908      0.004    -742.345    -143.718\\nwinter            603.4461    118.468      5.094      0.000     370.683     836.209\\njuly             -874.0132    142.287     -6.143      0.000   -1153.576    -594.450\\nspring          -1106.1972    132.435     -8.353      0.000   -1366.402    -845.992\\nworkingday        296.4789     94.677      3.131      0.002     110.459     482.499\\nhum             -1801.9289    201.242     -8.954      0.000   -2197.325   -1406.533\\ntemp             4372.9630    262.363     16.668      0.000    3857.478    4888.448\\nwindspeed       -1096.9814    190.369     -5.762      0.000   -1471.015    -722.948\\nlight snow/rain -1259.4132    237.690     -5.299      0.000   -1726.420    -792.406\\n==============================================================================\\nOmnibus:                       67.769   Durbin-Watson:                   1.914\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              129.549\\nSkew:                          -0.778   Prob(JB):                     7.39e-29\\nKurtosis:                       4.929   Cond. No.                         16.7\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n              index        vif\\n0             const  49.031354\\n9              temp   3.112593\\n6            spring   2.803882\\n4            winter   2.091074\\n2          Saturday   1.610886\\n7        workingday   1.603914\\n3          november   1.471790\\n5              july   1.311701\\n8               hum   1.298820\\n11  light snow/rain   1.178322\\n10        windspeed   1.149786\\n1                yr   1.032520\\n\")), mdx(\"h4\", {\n    \"id\": \"model-6\"\n  }, \"Model 6\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"november\"), \" because this information might also be contained in \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"winter\"), \".\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"del_feature = 'november'\\nselected_features = selected_features[selected_features!=del_feature]\\nfinal_model = ols_fit(y_train,X_train[selected_features])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.836\\nModel:                            OLS   Adj. R-squared:                  0.833\\nMethod:                 Least Squares   F-statistic:                     252.0\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          4.89e-187\\nTime:                        20:41:58   Log-Likelihood:                -4085.3\\nNo. Observations:                 506   AIC:                             8193.\\nDf Residuals:                     495   BIC:                             8239.\\nDf Model:                          10\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2392.0791    242.318      9.872      0.000    1915.980    2868.178\\nyr               1946.7864     70.967     27.432      0.000    1807.353    2086.220\\nSaturday          444.4907    126.045      3.526      0.000     196.842     692.139\\nwinter            466.0136    109.450      4.258      0.000     250.970     681.057\\njuly             -890.3115    143.244     -6.215      0.000   -1171.752    -608.871\\nspring          -1063.6669    132.613     -8.021      0.000   -1324.220    -803.114\\nworkingday        296.8008     95.388      3.112      0.002     109.386     484.216\\nhum             -1749.8275    201.947     -8.665      0.000   -2146.607   -1353.048\\ntemp             4471.6602    262.111     17.060      0.000    3956.673    4986.648\\nwindspeed       -1110.3191    191.742     -5.791      0.000   -1487.049    -733.590\\nlight snow/rain -1273.7519    239.422     -5.320      0.000   -1744.160    -803.344\\n==============================================================================\\nOmnibus:                       69.587   Durbin-Watson:                   1.898\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              136.276\\nSkew:                          -0.788   Prob(JB):                     2.56e-30\\nKurtosis:                       4.995   Cond. No.                         16.5\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n              index        vif\\n0             const  48.198446\\n8              temp   3.060511\\n5            spring   2.769692\\n3            winter   1.758336\\n2          Saturday   1.609975\\n6        workingday   1.603912\\n4              july   1.309666\\n7               hum   1.288526\\n10  light snow/rain   1.177815\\n9         windspeed   1.149118\\n1                yr   1.032476\\n\")), mdx(\"h2\", {\n    \"id\": \"verifying-multicollinearity\"\n  }, \"Verifying MultiCollinearity\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"vif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"              index        vif\\n0             const  48.198446\\n8              temp   3.060511\\n5            spring   2.769692\\n3            winter   1.758336\\n2          Saturday   1.609975\\n6        workingday   1.603912\\n4              july   1.309666\\n7               hum   1.288526\\n10  light snow/rain   1.177815\\n9         windspeed   1.149118\\n1                yr   1.032476\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"VIF < 5 for selected features. No significant multicollinearity observed. Similar indicating comparison of R-squared and adjusted R-squared.\")), mdx(\"h2\", {\n    \"id\": \"final-model\"\n  }, \"Final Model\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"final_model = ols_fit(y_train,X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.836\\nModel:                            OLS   Adj. R-squared:                  0.833\\nMethod:                 Least Squares   F-statistic:                     252.0\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          4.89e-187\\nTime:                        20:41:58   Log-Likelihood:                -4085.3\\nNo. Observations:                 506   AIC:                             8193.\\nDf Residuals:                     495   BIC:                             8239.\\nDf Model:                          10\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2392.0791    242.318      9.872      0.000    1915.980    2868.178\\nyr               1946.7864     70.967     27.432      0.000    1807.353    2086.220\\nSaturday          444.4907    126.045      3.526      0.000     196.842     692.139\\nwinter            466.0136    109.450      4.258      0.000     250.970     681.057\\njuly             -890.3115    143.244     -6.215      0.000   -1171.752    -608.871\\nspring          -1063.6669    132.613     -8.021      0.000   -1324.220    -803.114\\nworkingday        296.8008     95.388      3.112      0.002     109.386     484.216\\nhum             -1749.8275    201.947     -8.665      0.000   -2146.607   -1353.048\\ntemp             4471.6602    262.111     17.060      0.000    3956.673    4986.648\\nwindspeed       -1110.3191    191.742     -5.791      0.000   -1487.049    -733.590\\nlight snow/rain -1273.7519    239.422     -5.320      0.000   -1744.160    -803.344\\n==============================================================================\\nOmnibus:                       69.587   Durbin-Watson:                   1.898\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              136.276\\nSkew:                          -0.788   Prob(JB):                     2.56e-30\\nKurtosis:                       4.995   Cond. No.                         16.5\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"10 features have been selected.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"All the features are statistically significant \", \"[low p-value]\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The model over is a good fit with Prob (F-statistic): 4.89e-187\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The model explains 83.6% variability in the training data. Adjusted R-square being 83.3%\")), mdx(\"h2\", {\n    \"id\": \"residual-analysis\"\n  }, \"Residual Analysis\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Residual Analysis of Trained Data\\nX_train_sm = sm.add_constant(X_train[selected_features])\\n\\ny_train_pred = final_model.predict(X_train_sm)\\nfig,ax = plt.subplots(1,2)\\nfig.set_figheight(8)\\nfig.set_figwidth(16)\\n\\nax[0].set(title='Frequency Distribution of Residuals')\\nsns.distplot(y_train-y_train_pred, bins=30, ax=ax[0])\\n\\nax[1].set(title='Predicted Values vs Residuals')\\n\\\\\\nsns.regplot(y_train_pred,y_train-y_train_pred,ax=ax[1])\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"953px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"50.2623294858342%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABsklEQVQoz12S3WsTQRTF8/8j9M0nH4QWBB+s0JeCtIUqsTXYNhba1JgPmxjjJulmd2cz33u8d2Y3sS4cZmbvnd/cOXdaWms45+C9hxACWZYhz3M8pWsYY8L/qqpCjrU2rJXSIS+jPB415SnjQk5LSrkF8kb+CmkxXIgw51gDNCYCgZhnfQVJoEIapKWGZ2BTBcs5HxJ/pyU6w2UN3FXIGxRB5+tNWPdma4wWBdr9BCd3czrHo8VX3gJ9BP4i4MVgEYF1zBO0kBrfJinedh7RpfHFcQ97Hx7w7usEh1cTzJ7K/4B1heOlwNHNNPhSVTugIOCqUOg+pvj4PcHLsz5enQ9wdj9HZ7TCZCWeexgqpI2nlPDmcow1+cJ+cSw2xIU4H7zIZQBMSb1ZBqEMNqRnHjbQ49sZ9tsjJLSpAf7bZa6avSyVhbEOqVDYaEvdtjugq7vHgfdXUxx8HuPnUmx9ZKCrgSwGaVPLRilNFSqltkDWNfnz+tMw6PwhCR1mcXUsnu+eWBXBNlph+dkwcCMVlnmJ0Z8Mlz+SKOryl0GCeSpg6Rb8NV5yIxvxI+eRb6qoH38ByeUAcfS3uaEAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/f569aa67afc4f2c48d079ec72b0bd1aa/49089/output_82_0.webp 953w\"],\n    \"sizes\": \"(max-width: 953px) 100vw, 953px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/f569aa67afc4f2c48d079ec72b0bd1aa/0d20c/output_82_0.png 953w\"],\n    \"sizes\": \"(max-width: 953px) 100vw, 953px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/f569aa67afc4f2c48d079ec72b0bd1aa/0d20c/output_82_0.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Mean of Residuals\\n(y_train-y_train_pred).mean()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"4.763163951972846e-12\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Residual errors follow a normal distribution with mean=0\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Variance of Errors doesnt follow any trends\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Residual errors are independent of each other since the Predicted values vs Residuals plot doesn\\u2019t show any trend.\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Verifying the normality of distribution of residuals\\nmean = (y_train-y_train_pred).mean()\\nstd = (y_train-y_train_pred).std()\\n\\nref_normal = np.random.normal(mean,std,(y_train-y_train_pred).shape[0])\\n\\n\\npercs = np.linspace(0,100,21)\\nqn_ref_normal = np.percentile(ref_normal, percs)\\nqn_residual = np.percentile(y_train - y_train_pred , percs)\\n\\nplt.plot(qn_ref_normal,qn_residual, ls=\\\"\\\", marker=\\\"o\\\")\\n\\nx = np.linspace(np.min((qn_ref_normal.min(),qn_residual.min())), np.max((qn_ref_normal.max(),qn_residual.max())))\\nm = plt.plot(x,x, color=\\\"k\\\", ls=\\\"--\\\")\\nplt.title('Q-Q Plot : Reference Normal vs Distribution of Residuals ')\\nplt.savefig('q-q-plot.png')\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"384px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"67.96875%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAABoElEQVQ4y41U2U7DQAzM/38LPwESUl94AAFCUCHlaHPfd3MMGSdbQptKjLSK1/baY683GiYMwwDf93E4HBAEAY7HI0zThG3bIlPveZ7sdV0Xm/K3LAuGYaBtaoaCFoYhTqcTqqpCURTyLcsSaZrKnivLMtFxUVb6fPEnib3pTsRGaDSQITGOIxT+IxPlkrCoG4mjMXrXdbIh077vZV3Ks73DOPQSKEgyvOwNhEnOLOcYGikrhjxMBlxruVtkIi5qPLwZePqykFYN1B2cAzZNg7ZtNxnOjj2Gfma1+7Rx9/iObzuaA/Ud+sln7a8Ni+IWQ4L9uX/Vsfswp/JUNb/nVAwJyLHY6iF1hBcleP4yEaa57OnTrXyGS4Ys95IhQX2aJHCCGO0SfM1KVXHF0HEcyaQy0pFjwMFlfwllXzO5ybCu63MmsoqiSGZrXG5+3eMtVle3TIY05HkuE89MPNi020zWsirzD0PVaD4rlsgRqdsOpp+KzL6pKtRBJuSX/mtZAqoxIcg2jmOR7en2+Sxp4ySoB8AvwYpc1xWZ/wNWR/wAScVDqAPmkAIAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/13143c212e4aee8e78ed4f76cf5c977e/8d1ab/output_85_0.webp 384w\"],\n    \"sizes\": \"(max-width: 384px) 100vw, 384px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/13143c212e4aee8e78ed4f76cf5c977e/b492f/output_85_0.png 384w\"],\n    \"sizes\": \"(max-width: 384px) 100vw, 384px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/13143c212e4aee8e78ed4f76cf5c977e/b492f/output_85_0.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"This plot further shows that the residual distribution is approximately normal for all test data with values within range of training data.\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# lag plot to assess independence of data points\\nfrom pandas.plotting import lag_plot\\nlag_plot(y_train-y_train_pred)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"<matplotlib.axes._subplots.AxesSubplot at 0x7fde4fb985d0>\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"397px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"65.4911838790932%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAACWUlEQVQ4y3VTy2oUURCd/3AnLtwpuHQhih/hL7iVgCLZiAslJmtxLSKKGJTEOEGNq2ggYUwiM+Mz0clMJky/u2/f24/bx6pqexTEC0XfR9WpU6eqW6AVxzGUUijLEkVRIM9z+capobsCUZrBjzVQWeR0fxQowFqYLJf3guIqW8e2GJDB0jQlHyvGwNZWcKKUHC0F1EDdYYBxkErw5p6L/UksICW9T8hXUwIBjKJIWNaApWTWeQFlciidIc0K9IY+3n+b4M7LPu6ufcHVJ9tYaPex+nEENzYYeYlUJIBZlonZqkJFxplMXiJQGZZ3hlj/6uDhxj5mF3dxfn4Nx2ae4+TsCs7NvcF8u4dX3bEkZSItZsXLGEP0S9rVgJx1i8r6PA7xrHOAS/fWcfbWa5y60caJ68s4Td8zN1cx8/gDlraHJIWqGXKpDMYMmZ0yBWkT4ZC0OiLbGXiS/dNhgMv3N3Fx4S2OX1vCBWI6t9LDg3d7yIhITqZJIgEMgkA0dIiVlxjqqkG9LGLSkEVn1k+3BqLh7RddXHnUQeeHK02J0lwm4J8ucyBYR2oM68kSNJIMSfSBmxDTEItbP7Hx3ZG9AJV2OnICmCSJAHLJDMAPvGcnNtbViTQOPEWgCv1RIF+dFfJeCYm/GDYl/w+Q79w4JdMSyFKENOw8m1xNSXeBMn8AuSlsTbZmwNmaM0vBTMvfCbkJvqpnlN95z/GtShzrJTOoNVzXlXMYhmK8PM+bypKSj9yFEVw/QF2lL71oNUANMP/HXD4vBmAnXr7vw3GcqU/zQ2jyafrA51/kktNlQxkQTAAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/ac624317c9e71585e8a69e1ffd54f707/ae302/output_87_1.webp 397w\"],\n    \"sizes\": \"(max-width: 397px) 100vw, 397px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/ac624317c9e71585e8a69e1ffd54f707/4e17c/output_87_1.png 397w\"],\n    \"sizes\": \"(max-width: 397px) 100vw, 397px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/ac624317c9e71585e8a69e1ffd54f707/4e17c/output_87_1.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Lagplot of residuals shows no trend. Hence the error terms have constant variance\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hence, assumptions of Linear Regression are satisfied by this model\")), mdx(\"h2\", {\n    \"id\": \"prediction\"\n  }, \"Prediction\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"y_test = dtest.pop('cnt')\\nX_test = dtest\\nX_test[num_vars] = numerical_scaler.transform(X_test[num_vars])\\nX_test = X_test[selected_features]\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_test = sm.add_constant(X_test)\\ny_test_pred = final_model.predict(X_test)\\n\")), mdx(\"h2\", {\n    \"id\": \"model-evaluation\"\n  }, \"Model Evaluation\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Plotting Actual vs Predicted No of rentals\\nfig,ax = plt.subplots()\\nfig.set_figheight(8)\\nfig.set_figwidth(20)\\nl1,=ax.plot(range(len(y_test)),y_test)\\nl2, = ax.plot(range(len(y_test_pred)),y_test_pred)\\nplt.legend([l1,l2],['Actual','Predicted'])\\nplt.title('Predicted vs Actual No of Rentals');\\nplt.ylabel('No of Bike Rentals')\\nplt.xticks([])\\nplt.show()\\n\\nplt.figure(figsize=[8,8])\\nplt.scatter(y_test,y_test_pred);\\nplt.title('Predicted vs Actual No of Rentals');\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1172px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"39.50511945392492%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABpElEQVQozzWSCZPTMAyF8/9/F7OwQGFgaUvTg15Jm6O5beew86Fku57R2JKfniU/ec45mqZmGAamNY4ON46yj5PDdK+Ums1oJb6d4xNufOIEyWDdjPX6vqftBzqj6FtF0zkK1VKbjnawqLZHdRbTy8OtpRsclbFYYanaYSbqTUNSaXo5e1NlphuILjuy4y/SKCC9nWjKB3FW8rj4cs7Is5R7cERXOcdbQpymxFHIPU4o70eO/pt0UeMpbeh0RbRdEK9fCNefuYmVhZBcNyT+V6LzlizcU5yXJNcdweoLp81Pon9/uPk/UMGKy+oVkwV4TdOgtSY5bwT4wm35iXz3TQgOJJIQ/n0l9BcUhwXZeT0/bPI7VXIlf8TS1W+q0Ge3XFA+7u9/aKVtnZyIjmuqMsfqkiQ4SPJ36jSgjK8Upzeq25b6vsf2rXRVY0WEtogos4T9JcS0LV7XdTg7zIJoY2bFpqWbEhVJ8tAxCEFbxvQqR8vfTgU4289YayqUxCqlGQXrWWtn6Z3cuuc4TPJ/jIx143OcmAlm+xiXyYRklIKY8yz/AXR1Ys6SX9XNAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/edbf5da11059d439e8b21f5487aef0f7/fccb5/output_93_0.webp 1172w\"],\n    \"sizes\": \"(max-width: 1172px) 100vw, 1172px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/edbf5da11059d439e8b21f5487aef0f7/08110/output_93_0.png 1172w\"],\n    \"sizes\": \"(max-width: 1172px) 100vw, 1172px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/edbf5da11059d439e8b21f5487aef0f7/08110/output_93_0.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"489px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"97.95501022494886%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAACk0lEQVQ4y51VyY7TQBD1/x/5Ac5cENw4ICHQjEAgBmYkGMJkgCyOHe9be2kvj6qyOzhRBiQsdbrdS/Wr9145Vtu26LrubPM8D9vtFmEYwnVdOI4D3/exs23EcYS+72Vf3/85YyVJAqXUYXHetNbgC5umOfQ8v48LqGoca5pv21lA0DMMgwTk/rTxw2sYN0J3PcKiRqU7mUpLjW1U8qLst9I0RVEUZxEyKp4XWqjvaa7RhJSQdxR4FeR48n6Fq18hhn5E+1eEBlk39fy+CRXsWMFNK3z4GeC7m+H1wsPl0kesmhHhQxxy48DjuEeQlYLKoYCvbl0s9xmeX20kcJBVqBpC2AqpY2qmMVd5pVE2nOqAHQVQNL6nAKugwPU6ws02QUuX7OJyymTisK5rUW8e0KRfUNDlPh/5pMNf7EQ4e0fpiWBDL5c2bXc4Z7EgVVUdpWwWs7JGkNdQdYOnHzd49HKBhZMym8KrUDLtNecsQ7ZBNY5HuzBvd4TQjhQu7nwJuiZRWuEWR0KasRVFEYky8qCnquFUVK2Jn0IIf3FjU6prLN1U5lmUh0ScbCO/KOpWSFbU3+5SQlPg2Scbjy9+4O19ICoam5n+tEnpMY9iXDJnmFdYk5Jf7Rg+2eR6EwuXYp8pA+OKswiNzxihJrXYnCyEk5RiHX543nA9N/xZDotCiW1Y+pwK/hupyIb1yKhc9OZC0xtk8/cjlcuypK9KI/yURPibxR6fybg+BdT/E1CKn15YPa7Tyztv9NjMSiMlxymf1v8hZa7luq6QEV8sBgdm27AHza3zr868nxfCkbFN7XJ5sThs7HNI/oVQAhpPJXEMrus8z5FlmYzZ9PzVDoJANvNfAiPhd7OXLcdfq5jO8/MbGqQT+Lp231MAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/c015ff3ed7b50f920d936d862c27b8be/1b445/output_93_1.webp 489w\"],\n    \"sizes\": \"(max-width: 489px) 100vw, 489px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/c015ff3ed7b50f920d936d862c27b8be/7600e/output_93_1.png 489w\"],\n    \"sizes\": \"(max-width: 489px) 100vw, 489px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/c015ff3ed7b50f920d936d862c27b8be/7600e/output_93_1.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Predicted vs observed value plots shows that the model is reasonably accurate.\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.metrics import mean_squared_error,r2_score\\nmse = mean_squared_error(y_test, y_test_pred)\\nrsquared_test = r2_score(y_test, y_test_pred)\\nrsquared_train = r2_score(y_train, y_train_pred)\\nprint('R-squared for train data:',round(rsquared_train,2))\\nprint('R-squared for test data:',round(rsquared_test,2))\\nprint('Mean Squared Error',round(mse,3))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"R-squared for train data: 0.84\\nR-squared for test data: 0.81\\nMean Squared Error 666097.695\\n\")), mdx(\"h2\", {\n    \"id\": \"model-stability\"\n  }, \"Model Stability\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# R-square using cross validation\\n\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.linear_model import LinearRegression\\nlr = LinearRegression()\\nclr = cross_val_score(lr,X_train[selected_features],y_train,cv=10, scoring='r2')\\nclr\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"array([0.76577509, 0.89378885, 0.73439962, 0.87831664, 0.84127272,\\n       0.85375903, 0.87521829, 0.68697543, 0.73861901, 0.87571386])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(\\\"R-square at 0.95 confidence level : %0.2f (+/- %0.2f)\\\" % (clr.mean(), clr.std() * 2))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"R-square at 0.95 confidence level : 0.81 (+/- 0.14)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"selected_features\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"array(['yr', 'Saturday', 'winter', 'july', 'spring', 'workingday', 'hum',\\n       'temp', 'windspeed', 'light snow/rain'], dtype=object)\\n\")), mdx(\"h2\", {\n    \"id\": \"top-features\"\n  }, \"Top Features\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# standardizing numerical variables\\n\\nfrom sklearn.preprocessing import StandardScaler\\nreg_features = selected_features\\nscaler = StandardScaler()\\ndata = X_train[selected_features]\\nstd_num = scaler.fit(data[['temp','windspeed','hum']])\\n\\n\\nstd_X_train = pd.DataFrame(data = scaler.transform(data[['temp','windspeed','hum']]), columns=['temp','windspeed','hum'])\\nfor i in reg_features :\\n    std_X_train[i] = data[i].values\\n\\n\\nreshaped_y_train = y_train.values.reshape(-1,1)\\n\\n# Fitting linear regression model\\nstd_model = lr.fit(std_X_train, reshaped_y_train)\\n\\n# Coefficients and intercept\\nresult = pd.DataFrame(data = std_model.coef_, columns = std_X_train.columns, index=['MLR Coefficients']).T\\nresult = result.sort_values(by='MLR Coefficients',ascending=False)\\nprint('\\\\nIntercept :',std_model.intercept_)\\nresult\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Intercept : [2392.07911232]\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Upon standardized the values of predictor variables, the above shows that the top features influencing demand are \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"temp\"), \", followed by \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"yr\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"hum\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"In case of continuous variables, the above data could be interpreted as - With every standard deviation increase in continuous variables, demand increases by \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"xxx\"), \", when all other modelled paramters are held unchanged.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"In case of categorical variables, the above data could be interpreted as - Compared to the reference level, the change in demand is \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"xxx\"), \",, when all other modelled paramters are held unchanged.\")), mdx(\"h2\", {\n    \"id\": \"conclusion\"\n  }, \"Conclusion\"), mdx(\"p\", null, \"Analysis is carried out using a Mixed Feature Selection Approach. 15 features are selected algorithmically using Recursive Feature Elimination. Further selection is done manually by looking at multicollinearity and statistical significance of features and overall fit of the model.\\nThe 10 most significant features to understand demand have been reported.\"), mdx(\"p\", null, \"The data set is randomly divided into training and test data.\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Final Model\"), \" built on training data set explains 84% of the variability and achieves 81% on test data.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"The final relationship between demand and predictors is as follows.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cnt\"), \" = 2392.0791 + 1946.7864 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"yr\"), \" + 444.4907 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Saturday\"), \" + 466.0136 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"winter\"), \" - 890.3115 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"july\"), \" -1063.6669 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"spring\"), \" + 296.8008 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"workingday\"), \" - 1749.8275 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"hum\"), \" + 4471.6602 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"temp\"), \" - 1110.3191 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"windspeed\"), \" - 1273.7519 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"light snow/rain\"))), mdx(\"p\", null, \"where \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"temp\"), \" , \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"windspeed\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"hum\"), \" are normalized.\"), mdx(\"p\", null, \"Note :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Data has been cleaned to drop outliers that might affect the model adversely\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The model has been verified for Multicollinearity effects.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Residual Analysis has been carried out and the model satisfies the assumptions of Linear Regression (Residuals follow a normal distribution, Errors exhibit homoscedasticity)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Q-Q plot between residual distribution and normal distribution shows that residuals follow a normal distribution for all interpolations. Extraplorations show significant deviation, not affecting Linear Regression applicability.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Further Lag plot shows there is no auto-correlation in data.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Model is stable at 81%(+/-14%) coefficient of determination at 95% CI, ascertained through cross validation.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Features in the order of influence has been reported by standardizing all predictor values.\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","hero":{"full":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABpElEQVQozzWSCZPTMAyF8/9/F7OwQGFgaUvTg15Jm6O5beew86Fku57R2JKfniU/ec45mqZmGAamNY4ON46yj5PDdK+Ums1oJb6d4xNufOIEyWDdjPX6vqftBzqj6FtF0zkK1VKbjnawqLZHdRbTy8OtpRsclbFYYanaYSbqTUNSaXo5e1NlphuILjuy4y/SKCC9nWjKB3FW8rj4cs7Is5R7cERXOcdbQpymxFHIPU4o70eO/pt0UeMpbeh0RbRdEK9fCNefuYmVhZBcNyT+V6LzlizcU5yXJNcdweoLp81Pon9/uPk/UMGKy+oVkwV4TdOgtSY5bwT4wm35iXz3TQgOJJIQ/n0l9BcUhwXZeT0/bPI7VXIlf8TS1W+q0Ge3XFA+7u9/aKVtnZyIjmuqMsfqkiQ4SPJ36jSgjK8Upzeq25b6vsf2rXRVY0WEtogos4T9JcS0LV7XdTg7zIJoY2bFpqWbEhVJ8tAxCEFbxvQqR8vfTgU4289YayqUxCqlGQXrWWtn6Z3cuuc4TPJ/jIx143OcmAlm+xiXyYRklIKY8yz/AXR1Ys6SX9XNAAAAAElFTkSuQmCC","aspectRatio":2.5376344086021505,"src":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/a1946/output_93_0.png","srcSet":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/5b37e/output_93_0.png 236w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/49058/output_93_0.png 472w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/a1946/output_93_0.png 944w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/fa56b/output_93_0.png 1172w","srcWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/99fbb/output_93_0.webp","srcSetWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/77392/output_93_0.webp 236w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/1f177/output_93_0.webp 472w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/99fbb/output_93_0.webp 944w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/cd064/output_93_0.webp 1172w","sizes":"(max-width: 944px) 100vw, 944px"},"regular":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABpElEQVQozzWSCZPTMAyF8/9/F7OwQGFgaUvTg15Jm6O5beew86Fku57R2JKfniU/ec45mqZmGAamNY4ON46yj5PDdK+Ums1oJb6d4xNufOIEyWDdjPX6vqftBzqj6FtF0zkK1VKbjnawqLZHdRbTy8OtpRsclbFYYanaYSbqTUNSaXo5e1NlphuILjuy4y/SKCC9nWjKB3FW8rj4cs7Is5R7cERXOcdbQpymxFHIPU4o70eO/pt0UeMpbeh0RbRdEK9fCNefuYmVhZBcNyT+V6LzlizcU5yXJNcdweoLp81Pon9/uPk/UMGKy+oVkwV4TdOgtSY5bwT4wm35iXz3TQgOJJIQ/n0l9BcUhwXZeT0/bPI7VXIlf8TS1W+q0Ge3XFA+7u9/aKVtnZyIjmuqMsfqkiQ4SPJ36jSgjK8Upzeq25b6vsf2rXRVY0WEtogos4T9JcS0LV7XdTg7zIJoY2bFpqWbEhVJ8tAxCEFbxvQqR8vfTgU4289YayqUxCqlGQXrWWtn6Z3cuuc4TPJ/jIx143OcmAlm+xiXyYRklIKY8yz/AXR1Ys6SX9XNAAAAAElFTkSuQmCC","aspectRatio":2.546875,"src":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/3ddd4/output_93_0.png","srcSet":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/078a8/output_93_0.png 163w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/e56da/output_93_0.png 327w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/3ddd4/output_93_0.png 653w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/c5cc7/output_93_0.png 980w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/fa56b/output_93_0.png 1172w","srcWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/0acdf/output_93_0.webp","srcSetWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/ac59e/output_93_0.webp 163w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/7660b/output_93_0.webp 327w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/0acdf/output_93_0.webp 653w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/75470/output_93_0.webp 980w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/cd064/output_93_0.webp 1172w","sizes":"(max-width: 653px) 100vw, 653px"},"narrow":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABpElEQVQozzWSCZPTMAyF8/9/F7OwQGFgaUvTg15Jm6O5beew86Fku57R2JKfniU/ec45mqZmGAamNY4ON46yj5PDdK+Ums1oJb6d4xNufOIEyWDdjPX6vqftBzqj6FtF0zkK1VKbjnawqLZHdRbTy8OtpRsclbFYYanaYSbqTUNSaXo5e1NlphuILjuy4y/SKCC9nWjKB3FW8rj4cs7Is5R7cERXOcdbQpymxFHIPU4o70eO/pt0UeMpbeh0RbRdEK9fCNefuYmVhZBcNyT+V6LzlizcU5yXJNcdweoLp81Pon9/uPk/UMGKy+oVkwV4TdOgtSY5bwT4wm35iXz3TQgOJJIQ/n0l9BcUhwXZeT0/bPI7VXIlf8TS1W+q0Ge3XFA+7u9/aKVtnZyIjmuqMsfqkiQ4SPJ36jSgjK8Upzeq25b6vsf2rXRVY0WEtogos4T9JcS0LV7XdTg7zIJoY2bFpqWbEhVJ8tAxCEFbxvQqR8vfTgU4289YayqUxCqlGQXrWWtn6Z3cuuc4TPJ/jIx143OcmAlm+xiXyYRklIKY8yz/AXR1Ys6SX9XNAAAAAElFTkSuQmCC","aspectRatio":2.533333333333333,"src":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/502b1/output_93_0.png","srcSet":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/f2e6d/output_93_0.png 114w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/4ddba/output_93_0.png 229w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/502b1/output_93_0.png 457w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/7ddc2/output_93_0.png 686w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/435bf/output_93_0.png 914w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/fa56b/output_93_0.png 1172w","srcWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/15384/output_93_0.webp","srcSetWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/31fce/output_93_0.webp 114w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/e3e25/output_93_0.webp 229w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/15384/output_93_0.webp 457w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/0258d/output_93_0.webp 686w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/64ea2/output_93_0.webp 914w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/cd064/output_93_0.webp 1172w","sizes":"(max-width: 457px) 100vw, 457px"},"seo":{"src":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/fa56b/output_93_0.png"}}},"authors":[{"authorsPage":true,"bio":"The boy who believes in standing in the gutter but looking at the stars.\n","id":"b4bc9878-0ca0-5111-bfd2-1a9c4a111d95","name":"Jayanth Boddu","featured":true,"social":[{"url":"http://twitter.com/JayanthBoddu/"},{"url":"https://github.com/jayantb1019"},{"url":"https://www.instagram.com/jayantb1019/"},{"url":"https://www.linkedin.com/in/jayanthboddu/"}],"slug":"/authors/jayanth-boddu","avatar":{"small":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAAFjUlEQVQ4yx2UW1DU5xnG/1AEAeV8EHcRFthlOW05LC66LLsIC+4BZDktLLCwuxyWPQgIiqcoGCwqahvqGCwi0WSpiWZSbbQaY83Yqmmn7WRsrI2pbaZ2Jhed6U0mF51M5tf/9OKb7+73Pt/zvM8nnGzSIEuIxOsy8/pIA9OdanwOA9qiTN6cd3N9aTee5nI6zSW0G3JRpMeyszKbCnkSNZo0dFtTKcrZQF5WFPIt6xEWZ3uRp0dz/KiLEyNmDljLmOjSiwMaefTRWS6fGqK9oZQOqxqrvoCs5GjaapWUSeKprZbSaJCiyo+jOD+e/Jx1CBfe8CKJX4e/Tc+FE3387HgPg/oS9npM3Lw6h7lBjUKWTkVxNlnSJGIiI5BsSkBTvJmdddnYLHlUliYjlyWIJxLh/JlBspPXYSuUMr/bxOo5L9OjVvpbq6jVKJFJkpBlJKKQxJEmDg4TBCLCIlgfFUFDfQ6O9mKMOglF8gRKlHEIcwe7UeensnIqyNKCh4unh/HYdWSmxVCQJ6W6OJ2lfVY+fMPD+3O78JpyyUiMJTw8HFXxJtx95VhFsGF7BmpVPEK/pRJNwRZ+//Aia6tT/PLNvfQ1biU+JhyNSsrt023w/AL87RrfPj7N5yuddIveRUVGkpGxkZ7uMjqaCzHqt1BVkYzgc2hxd1Xz8vkNbl6b5eEHC4zY9UjENDtqc/jq1j6+fRni+//c579fhrh3rpehRhlx6yOIj9tAS7OKHnsppjoZ1Zp0hMOTFnzdOp59colP7ixwY/Uo/Q0VFMlSsFXncGPRzW9DU3z3zw94vDbJbH8ZY7sKSYwKJzY6koE+Db2OcppMcgzazQjN23Lxaou5fdjFvdAsiwcHcGwvpEmdy9KBZv4sQp5cGufrezP86pSNSweszHUo0eZGkyUGFRjU4XRspcWqpF6fidCilzPnNPPs18vcfecY+9tqOHfCy4PrP+Lx1T18cW+Ol3fm+ebBMT6ab+Kd6TpWx7cxZMxCX5iKw6bC1VtFq+jjznoZQk1BMj8//xqvnt/kya1zzPlbufyTCV48eotnd18HfsP3X78HXyzzp9UhPl9y8I+1flw14qpsjhXTlYoKK2m1lYg7q0DYrkrjsyfXePHpuzx7GCK0fIjQ2XH+8vBtvrx/hu/+fZ1vvrrCv+4c4cq0kZUxHb9btFGTt5G46Aiqt0mwt6lobirAZJQj1Kml/PHuCq9e3OIPV89wfKSJp49W+OujEJ/dP8+rj2d4+m6Av18/zIP5Pk70/5CZ7kJSYiIICxOoN+TQbivGYlZg3CE+2VKxhcueFj5eO8mlU3vxdZm5uDzP+6GTfPiL81x4rY2nV/08vTLG7ePdrEzpUMsTEcTGRP0gjB26TGxNCkyifwatBCHQV8/SkQmOHJ1jwB/A1GHB2GTB1mXH7hrmYLCds7vFnh8wsTheT21ZBlHhAqkJsSSlxKEoSGFrlZSabVK0mlQE//g4gUPH2DOzwMShWVodnbR0t9PS1YljyMOw183awiDLkzvwNWRhVCbQokpg2KIkq0BO/KZUEtNTSEyOIyVtI4J36iiesf349s+wb2Yeh3tAVOYUoXaGgl5s4t3rdnLtx6N8+tNW3pvScNFfwsGhWuSlKjIV2UjzskVYGjEbRKBzVOzu6BQDwWkmRYVDwVFcfi8dTic9g4O4fF7Mbe3UmpvFijYyM2rEba9DZ2ygoLycbKWCFKmUZMkmNiaJv40nMC0qCtDm9BHcd4Tg5B4R6mcwGKCz34lXtKS5s4M6s5mqugYqDDvQNlpQaw2UqLUUVVSKChVkKfNJkqQh9Lj8dA+M0tjaS59v4v+A4bHdjIwHcHjceIJB+rwjWNvtoh1u6qxm6nftwipaUWuxUmM0UaGtRl5SyubcbP4HqS403PJT4JQAAAAASUVORK5CYII=","aspectRatio":1,"src":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/02603/jayanth-boddu.png","srcSet":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/d406d/jayanth-boddu.png 13w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/12717/jayanth-boddu.png 25w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/02603/jayanth-boddu.png 50w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/5acf8/jayanth-boddu.png 75w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/3ba9f/jayanth-boddu.png 100w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/3891b/jayanth-boddu.png 400w","srcWebp":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/e7b2c/jayanth-boddu.webp","srcSetWebp":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/58718/jayanth-boddu.webp 13w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/74aad/jayanth-boddu.webp 25w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/e7b2c/jayanth-boddu.webp 50w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/ed320/jayanth-boddu.webp 75w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/66016/jayanth-boddu.webp 100w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/fc32b/jayanth-boddu.webp 400w","sizes":"(max-width: 50px) 100vw, 50px"},"medium":{"base64":"data:image/png;base64,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","aspectRatio":1,"src":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/3ba9f/jayanth-boddu.png","srcSet":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/12717/jayanth-boddu.png 25w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/02603/jayanth-boddu.png 50w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/3ba9f/jayanth-boddu.png 100w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/95f17/jayanth-boddu.png 150w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/8ac63/jayanth-boddu.png 200w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/3891b/jayanth-boddu.png 400w","srcWebp":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/66016/jayanth-boddu.webp","srcSetWebp":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/74aad/jayanth-boddu.webp 25w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/e7b2c/jayanth-boddu.webp 50w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/66016/jayanth-boddu.webp 100w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/d9b14/jayanth-boddu.webp 150w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/6b183/jayanth-boddu.webp 200w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/fc32b/jayanth-boddu.webp 400w","sizes":"(max-width: 100px) 100vw, 100px"},"large":{"base64":"data:image/png;base64,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","aspectRatio":1,"src":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/19999/jayanth-boddu.png","srcSet":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/6bc0d/jayanth-boddu.png 82w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/6a68f/jayanth-boddu.png 164w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/19999/jayanth-boddu.png 328w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/3891b/jayanth-boddu.png 400w","srcWebp":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/5a48e/jayanth-boddu.webp","srcSetWebp":"//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/2d087/jayanth-boddu.webp 82w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/29d87/jayanth-boddu.webp 164w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/5a48e/jayanth-boddu.webp 328w,\n//blog/static/d5a2cf05f534804ead9aa4d5a0381edc/fc32b/jayanth-boddu.webp 400w","sizes":"(max-width: 328px) 100vw, 328px"}}}],"basePath":"/","permalink":"https://jayantb1019.github.io/boom-bikes-demand-analysis/","slug":"/boom-bikes-demand-analysis","id":"b86af459-161d-57ec-9fd4-7f55873916ab","title":"Boom Bikes Demand Analysis","canonicalUrl":null,"mailchimp":"","next":[{"id":"df100e02-f7ae-5913-847f-a86c4f4efa27","slug":"/wine-quality-classification","secret":false,"title":"Wine Quality Classification","author":"Jayanth Boddu","date":"August 7th, 2020","dateForSEO":"2020-08-07T00:00:00.000Z","timeToRead":2,"excerpt":"Predicting Wine Quality using Logistic Regression","canonical_url":null,"subscription":true,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Wine Quality Classification\",\n  \"author\": \"Jayanth Boddu\",\n  \"date\": \"2020-08-07T00:00:00.000Z\",\n  \"excerpt\": \"Predicting Wine Quality using Logistic Regression\",\n  \"hero\": \"./evgeniy-konev-3OrRheb618Y-unsplash.jpg\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Photo by \", mdx(\"a\", {\n    href: \"https://unsplash.com/@ekonev?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\",\n    target: \"_blank\"\n  }, \"EVGENIY KONEV\"), \" on \", mdx(\"a\", {\n    href: \"https://unsplash.com/@ekonev?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\",\n    target: \"_blank\"\n  }, \"Unsplash\")), mdx(\"h3\", {\n    \"id\": \"data-set\"\n  }, \"Data Set\"), mdx(\"p\", null, \"This Data set contains the information related to red wine , Various factors affecting the quality. This data set was prepossessed and downloaded from the UCI Machine Learning Repository. This data set was simple, cleaned, practice data set for classification modelling. Source of this Dataset: \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://archive.ics.uci.edu/ml/datasets/wine+quality\",\n    \"target\": \"_blank\",\n    \"rel\": \"noreferrer\"\n  }), \"https://archive.ics.uci.edu/ml/datasets/wine+quality\")), mdx(\"p\", null, \"Attribute Information:\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Input variables (based on physicochemical tests):\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"fixed acidity\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"volatile acidity\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"citric acid\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"residual sugar\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"chlorides\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"free sulfur dioxide\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"total sulfur dioxide\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"density\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"pH\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"sulphates\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"alcohol\", mdx(\"br\", {\n    parentName: \"li\"\n  }), \"Output variable (based on sensory data):\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"quality (\\u2018good\\u2019 and \\u2018bad\\u2019 based on score >5 and <5)\")), mdx(\"h3\", {\n    \"id\": \"analysis-approach--conclusions\"\n  }, \"Analysis Approach & Conclusions\"), mdx(\"p\", null, \"This analysis focuses on finding attributes that significantly affect wine quality classification and training a predictive model to classify wine quality into \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"good\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"bad\"), \" based on attributes. Analysis is pivoted on the variable \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"quality\"), \"(target variable). Exploratory data analysis steps like removing null values, observing summary statistics, visualizing the variables, removing oultiers, checking for correlations are carried out.\"), mdx(\"p\", null, \"Following significant correlations are observed.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Fixed acidity vs pH : -0.69\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Fixed acidity vs density : 0.69\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"fixed acidity vs citric acid : 0.67\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Volatile acidity vs citric acid : -0.53\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"citric acid vs pH : -0.54\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"density vs alcohol : -0.51\")), mdx(\"p\", null, \"A 70-30 split is done to divide dataset into test and train sets.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"10 variables are selected using automated RFE. Further, manual selection is carried out using p-value method.\\nModels are build on train data using \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"statsmodels.api\"), \" package.\\nFinal Model is build on the following variables.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"citric acid\"), \",\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"fixed acidity\"), \",\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"volatile acidity\"), \",\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"alcohol\"), \",\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"sulphates\"), \",\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"total sulfur dioxide\"), mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Variance inflation factor is calculated for all final selection of variables. VIF < 5. No significant Multicollinearity observed.\"), mdx(\"p\", null, \"ROC, Precision-Recall / Sensitivity - Specificity curves have been plotted. The optimum threshold for classification seems to be 0.5\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Model metrics on train data at classification threshold of 0.5 :\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Accuracy : 0.752\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Misclassification Rate / Error Rate : 0.248\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Sensitivity / True Positive Rate / Recall : 0.755\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Specificity / True Negative Rate : 0.75\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"False Positive Rate : 0.25\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Precision / Positive Predictive Value : 0.777\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Prevalance : 0.535\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Negative Predictive Value 0.726\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Likelihood Ratio : Sensitivity / 1-Specificity : 3.02\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"F1-score : 0.766\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Model metrics on test data at classification threshold of 0.5 :\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Accuracy : 0.746\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Misclassification Rate / Error Rate : 0.254\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Sensitivity / True Positive Rate / Recall : 0.797\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Specificity / True Negative Rate : 0.688\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"False Positive Rate : 0.312\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Precision / Positive Predictive Value : 0.745\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Prevalance : 0.533\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Negative Predictive Value 0.748\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Likelihood Ratio : Sensitivity / 1-Specificity : 2.554\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"F1-score : 0.77\")), mdx(\"h2\", {\n    \"id\": \"analysis\"\n  }, \"Analysis\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"import pandas as pd, numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\")), mdx(\"h3\", {\n    \"id\": \"importing-data\"\n  }, \"Importing Data\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data = pd.read_csv('./wine_quality_classification.csv')\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(data.head())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\\\\n0            7.4              0.70         0.00             1.9      0.076\\n1            7.8              0.88         0.00             2.6      0.098\\n2            7.8              0.76         0.04             2.3      0.092\\n3           11.2              0.28         0.56             1.9      0.075\\n4            7.4              0.70         0.00             1.9      0.076\\n\\n   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\\\\n0                 11.0                  34.0   0.9978  3.51       0.56\\n1                 25.0                  67.0   0.9968  3.20       0.68\\n2                 15.0                  54.0   0.9970  3.26       0.65\\n3                 17.0                  60.0   0.9980  3.16       0.58\\n4                 11.0                  34.0   0.9978  3.51       0.56\\n\\n   alcohol quality\\n0      9.4     bad\\n1      9.8     bad\\n2      9.8     bad\\n3      9.8    good\\n4      9.4     bad\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data.info()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"<class 'pandas.core.frame.DataFrame'>\\nRangeIndex: 1599 entries, 0 to 1598\\nData columns (total 12 columns):\\n #   Column                Non-Null Count  Dtype\\n---  ------                --------------  -----\\n 0   fixed acidity         1599 non-null   float64\\n 1   volatile acidity      1599 non-null   float64\\n 2   citric acid           1599 non-null   float64\\n 3   residual sugar        1599 non-null   float64\\n 4   chlorides             1599 non-null   float64\\n 5   free sulfur dioxide   1599 non-null   float64\\n 6   total sulfur dioxide  1599 non-null   float64\\n 7   density               1599 non-null   float64\\n 8   pH                    1599 non-null   float64\\n 9   sulphates             1599 non-null   float64\\n 10  alcohol               1599 non-null   float64\\n 11  quality               1599 non-null   object\\ndtypes: float64(11), object(1)\\nmemory usage: 150.0+ KB\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data.isnull().sum()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"fixed acidity           0\\nvolatile acidity        0\\ncitric acid             0\\nresidual sugar          0\\nchlorides               0\\nfree sulfur dioxide     0\\ntotal sulfur dioxide    0\\ndensity                 0\\npH                      0\\nsulphates               0\\nalcohol                 0\\nquality                 0\\ndtype: int64\\n\")), mdx(\"p\", null, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"quality\"), \" is our target variable. It has two levels - good & bad. No null or missing values. All the other variables are continuous variables.\"), mdx(\"h3\", {\n    \"id\": \"replacing-quality-levels-with-01\"\n  }, \"Replacing \", mdx(\"inlineCode\", {\n    parentName: \"h3\"\n  }, \"quality\"), \" levels with 0,1\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data['quality'] = data['quality'].replace({'good' : 1, 'bad' : 0})\\n\")), mdx(\"h3\", {\n    \"id\": \"summary-statistics\"\n  }, \"Summary Statistics\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(data.describe())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"fixed acidity  volatile acidity  citric acid  residual sugar  \\\\\\ncount    1599.000000       1599.000000  1599.000000     1599.000000\\nmean        8.319637          0.527821     0.270976        2.538806\\nstd         1.741096          0.179060     0.194801        1.409928\\nmin         4.600000          0.120000     0.000000        0.900000\\n25%         7.100000          0.390000     0.090000        1.900000\\n50%         7.900000          0.520000     0.260000        2.200000\\n75%         9.200000          0.640000     0.420000        2.600000\\nmax        15.900000          1.580000     1.000000       15.500000\\n\\n         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\\\\ncount  1599.000000          1599.000000           1599.000000  1599.000000\\nmean      0.087467            15.874922             46.467792     0.996747\\nstd       0.047065            10.460157             32.895324     0.001887\\nmin       0.012000             1.000000              6.000000     0.990070\\n25%       0.070000             7.000000             22.000000     0.995600\\n50%       0.079000            14.000000             38.000000     0.996750\\n75%       0.090000            21.000000             62.000000     0.997835\\nmax       0.611000            72.000000            289.000000     1.003690\\n\\n                pH    sulphates      alcohol      quality\\ncount  1599.000000  1599.000000  1599.000000  1599.000000\\nmean      3.311113     0.658149    10.422983     0.534709\\nstd       0.154386     0.169507     1.065668     0.498950\\nmin       2.740000     0.330000     8.400000     0.000000\\n25%       3.210000     0.550000     9.500000     0.000000\\n50%       3.310000     0.620000    10.200000     1.000000\\n75%       3.400000     0.730000    11.100000     1.000000\\nmax       4.010000     2.000000    14.900000     1.000000\\n\")), mdx(\"h3\", {\n    \"id\": \"checking-for-outliers\"\n  }, \"Checking for Outliers\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(data.quantile(np.linspace(0.90,1,12)))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"fixed acidity  volatile acidity  citric acid  residual sugar  \\\\\\n0.900000      10.700000          0.745000     0.522000        3.600000\\n0.909091      10.872727          0.760000     0.537273        3.800000\\n0.918182      11.100000          0.775000     0.550000        4.000000\\n0.927273      11.300000          0.785000     0.560000        4.200000\\n0.936364      11.500000          0.810000     0.580000        4.400000\\n0.945455      11.600000          0.834182     0.590000        4.783636\\n0.954545      11.900000          0.851818     0.630000        5.500000\\n0.963636      12.089091          0.880000     0.640000        5.789091\\n0.972727      12.500000          0.910000     0.660000        6.141818\\n0.981818      12.794545          0.965000     0.680000        6.983636\\n0.990909      13.300000          1.022364     0.714727        8.694545\\n1.000000      15.900000          1.580000     1.000000       15.500000\\n\\n          chlorides  free sulfur dioxide  total sulfur dioxide   density  \\\\\\n0.900000   0.109000            31.000000             93.200000  0.999140\\n0.909091   0.111000            31.000000             96.000000  0.999300\\n0.918182   0.114000            32.000000             99.000000  0.999400\\n0.927273   0.117000            33.000000            102.781818  0.999478\\n0.936364   0.120000            34.000000            106.000000  0.999700\\n0.945455   0.123000            35.000000            110.000000  0.999800\\n0.954545   0.136364            36.000000            115.000000  1.000000\\n0.963636   0.164564            38.000000            121.000000  1.000200\\n0.972727   0.187673            40.000000            129.000000  1.000400\\n0.981818   0.234727            42.945455            136.000000  1.000989\\n0.990909   0.368473            51.000000            145.945455  1.001942\\n1.000000   0.611000            72.000000            289.000000  1.003690\\n\\n                pH  sulphates  alcohol  quality\\n0.900000  3.510000   0.850000     12.0      1.0\\n0.909091  3.520000   0.860000     12.0      1.0\\n0.918182  3.530000   0.870000     12.1      1.0\\n0.927273  3.540000   0.887818     12.2      1.0\\n0.936364  3.543091   0.903091     12.4      1.0\\n0.945455  3.560000   0.930000     12.5      1.0\\n0.954545  3.573636   0.953636     12.5      1.0\\n0.963636  3.590000   0.998909     12.7      1.0\\n0.972727  3.610000   1.060000     12.8      1.0\\n0.981818  3.660000   1.140000     12.9      1.0\\n0.990909  3.710000   1.280000     13.4      1.0\\n1.000000  4.010000   2.000000     14.9      1.0\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"There are outlier in \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"fixed acidity\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"volatile acidity\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"citric acid\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"residual sugar\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"chlorides\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"free sulfur dioxide\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"total sulfur dioxide\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"pH\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"sulphates\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"alcohol\"))), mdx(\"h3\", {\n    \"id\": \"visualizing-independent-variables\"\n  }, \"Visualizing Independent Variables\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"x_vars = data.columns[data.columns != 'quality']\\nfig,ax = plt.subplots(len(x_vars))\\nfig.set_figheight(24)\\nfig.set_figwidth(12)\\nfor num,i in enumerate(x_vars) :\\n    ax[num].set_title(i)\\n    ax[num].set_xlabel('')\\n    sns.boxplot(data[i],ax=ax[num])\\n\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"/blog/319b742008a89b4e0b27ff70af4650db/output_16_0.svg\",\n    \"alt\": \"svg\"\n  }))), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# removing outliers :\\nx_vars = data.columns[data.columns != 'quality']\\nfor i in x_vars :\\n    q1 = data[i].quantile(0.25)\\n    q3 = data[i].quantile(0.75)\\n    upper_extreme = data[i].quantile(0.75) + 1.5*(q3-q1) # q3-q1 is IQR\\n    lower_extreme = data[i].quantile(0.75) - 1.5*(q3-q1)\\n    mask =  (data[i] > lower_extreme) & (data[i] < upper_extreme)  # sans outliers\\n    outliers = data[mask].index\\n    data.drop(index=outliers)\\n\\n\")), mdx(\"h3\", {\n    \"id\": \"test-train-split\"\n  }, \"Test Train Split\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.model_selection import train_test_split\\ny = data.pop('quality')\\nX = data\\n\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=100)\\n\")), mdx(\"h3\", {\n    \"id\": \"scaling-continuous-variables\"\n  }, \"Scaling Continuous Variables\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# In our case, all the independent variables are continuous\\nfrom sklearn.preprocessing import StandardScaler\\nscaler = StandardScaler()\\nX_train[X_train.columns] = scaler.fit_transform(X_train[X_train.columns])\\n\\n# Scaling test set for later use\\nX_test[X_train.columns] = scaler.transform(X_test[X_train.columns])\\n\")), mdx(\"h3\", {\n    \"id\": \"correlations\"\n  }, \"Correlations\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"plt.figure(figsize=[20,10])\\nsns.heatmap(X_train.corr(),annot=True)\\nplt.title('Visualizing Correlations')\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"/blog/0b9e55431e744d35e3d365e58c19bd02/output_24_0.svg\",\n    \"alt\": \"svg\"\n  }))), mdx(\"p\", null, \"High Correlations :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Fixed acidity vs pH : -0.69\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Fixed acidity vs density : 0.69\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"fixed acidity vs citric acid : 0.67\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Volatile acidity vs citric acid : -0.53\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"citric acid vs pH : -0.54\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"density vs alcohol : -0.51\")), mdx(\"h3\", {\n    \"id\": \"model-building\"\n  }, \"Model Building\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"import statsmodels.api as sm\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Logistic Regression Model\\nlogm1 = sm.GLM(y_train, sm.add_constant(X_train),family=sm.families.Binomial())\\nlogm1.fit().summary()\\n\")), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"caption\", null, \"Generalized Linear Model Regression Results\"), mdx(\"tr\", null, mdx(\"th\", null, \"Dep. Variable:\"), \"        \", mdx(\"td\", null, \"quality\"), \"     \", mdx(\"th\", null, \"  No. Observations:  \"), \"  \", mdx(\"td\", null, \"  1119\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model:\"), \"                  \", mdx(\"td\", null, \"GLM\"), \"       \", mdx(\"th\", null, \"  Df Residuals:      \"), \"  \", mdx(\"td\", null, \"  1107\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model Family:\"), \"        \", mdx(\"td\", null, \"Binomial\"), \"     \", mdx(\"th\", null, \"  Df Model:          \"), \"  \", mdx(\"td\", null, \"    11\")), mdx(\"tr\", null, mdx(\"th\", null, \"Link Function:\"), \"         \", mdx(\"td\", null, \"logit\"), \"      \", mdx(\"th\", null, \"  Scale:             \"), \" \", mdx(\"td\", null, \"  1.0000\")), mdx(\"tr\", null, mdx(\"th\", null, \"Method:\"), \"                \", mdx(\"td\", null, \"IRLS\"), \"       \", mdx(\"th\", null, \"  Log-Likelihood:    \"), \" \", mdx(\"td\", null, \" -570.86\")), mdx(\"tr\", null, mdx(\"th\", null, \"Date:\"), \"            \", mdx(\"td\", null, \"Fri, 07 Aug 2020\"), \" \", mdx(\"th\", null, \"  Deviance:          \"), \" \", mdx(\"td\", null, \"  1141.7\")), mdx(\"tr\", null, mdx(\"th\", null, \"Time:\"), \"                \", mdx(\"td\", null, \"18:45:03\"), \"     \", mdx(\"th\", null, \"  Pearson chi2:      \"), \" \", mdx(\"td\", null, \"1.08e+03\")), mdx(\"tr\", null, mdx(\"th\", null, \"No. Iterations:\"), \"          \", mdx(\"td\", null, \"5\"), \"        \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \")), mdx(\"tr\", null, mdx(\"th\", null, \"Covariance Type:\"), \"     \", mdx(\"td\", null, \"nonrobust\"), \"    \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \"))), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"tr\", null, mdx(\"td\", null), \"              \", mdx(\"th\", null, \"coef\"), \"     \", mdx(\"th\", null, \"std err\"), \"      \", mdx(\"th\", null, \"z\"), \"      \", mdx(\"th\", null, \"P>|z|\"), \"  \", mdx(\"th\", null, \"[0.025\"), \"    \", mdx(\"th\", null, \"0.975]\")), mdx(\"tr\", null, mdx(\"th\", null, \"const\"), \"                \", mdx(\"td\", null, \"    0.2632\"), \" \", mdx(\"td\", null, \"    0.076\"), \" \", mdx(\"td\", null, \"    3.478\"), \" \", mdx(\"td\", null, \" 0.001\"), \" \", mdx(\"td\", null, \"    0.115\"), \" \", mdx(\"td\", null, \"    0.411\")), mdx(\"tr\", null, mdx(\"th\", null, \"fixed acidity\"), \"        \", mdx(\"td\", null, \"    0.3550\"), \" \", mdx(\"td\", null, \"    0.204\"), \" \", mdx(\"td\", null, \"    1.742\"), \" \", mdx(\"td\", null, \" 0.082\"), \" \", mdx(\"td\", null, \"   -0.045\"), \" \", mdx(\"td\", null, \"    0.755\")), mdx(\"tr\", null, mdx(\"th\", null, \"volatile acidity\"), \"     \", mdx(\"td\", null, \"   -0.5883\"), \" \", mdx(\"td\", null, \"    0.103\"), \" \", mdx(\"td\", null, \"   -5.706\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.790\"), \" \", mdx(\"td\", null, \"   -0.386\")), mdx(\"tr\", null, mdx(\"th\", null, \"citric acid\"), \"          \", mdx(\"td\", null, \"   -0.3117\"), \" \", mdx(\"td\", null, \"    0.132\"), \" \", mdx(\"td\", null, \"   -2.356\"), \" \", mdx(\"td\", null, \" 0.018\"), \" \", mdx(\"td\", null, \"   -0.571\"), \" \", mdx(\"td\", null, \"   -0.052\")), mdx(\"tr\", null, mdx(\"th\", null, \"residual sugar\"), \"       \", mdx(\"td\", null, \"    0.2039\"), \" \", mdx(\"td\", null, \"    0.093\"), \" \", mdx(\"td\", null, \"    2.185\"), \" \", mdx(\"td\", null, \" 0.029\"), \" \", mdx(\"td\", null, \"    0.021\"), \" \", mdx(\"td\", null, \"    0.387\")), mdx(\"tr\", null, mdx(\"th\", null, \"chlorides\"), \"            \", mdx(\"td\", null, \"   -0.1757\"), \" \", mdx(\"td\", null, \"    0.091\"), \" \", mdx(\"td\", null, \"   -1.931\"), \" \", mdx(\"td\", null, \" 0.054\"), \" \", mdx(\"td\", null, \"   -0.354\"), \" \", mdx(\"td\", null, \"    0.003\")), mdx(\"tr\", null, mdx(\"th\", null, \"free sulfur dioxide\"), \"  \", mdx(\"td\", null, \"    0.1652\"), \" \", mdx(\"td\", null, \"    0.107\"), \" \", mdx(\"td\", null, \"    1.546\"), \" \", mdx(\"td\", null, \" 0.122\"), \" \", mdx(\"td\", null, \"   -0.044\"), \" \", mdx(\"td\", null, \"    0.375\")), mdx(\"tr\", null, mdx(\"th\", null, \"total sulfur dioxide\"), \" \", mdx(\"td\", null, \"   -0.5286\"), \" \", mdx(\"td\", null, \"    0.115\"), \" \", mdx(\"td\", null, \"   -4.584\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.755\"), \" \", mdx(\"td\", null, \"   -0.303\")), mdx(\"tr\", null, mdx(\"th\", null, \"density\"), \"              \", mdx(\"td\", null, \"   -0.2451\"), \" \", mdx(\"td\", null, \"    0.186\"), \" \", mdx(\"td\", null, \"   -1.320\"), \" \", mdx(\"td\", null, \" 0.187\"), \" \", mdx(\"td\", null, \"   -0.609\"), \" \", mdx(\"td\", null, \"    0.119\")), mdx(\"tr\", null, mdx(\"th\", null, \"pH\"), \"                   \", mdx(\"td\", null, \"   -0.0311\"), \" \", mdx(\"td\", null, \"    0.133\"), \" \", mdx(\"td\", null, \"   -0.233\"), \" \", mdx(\"td\", null, \" 0.815\"), \" \", mdx(\"td\", null, \"   -0.292\"), \" \", mdx(\"td\", null, \"    0.230\")), mdx(\"tr\", null, mdx(\"th\", null, \"sulphates\"), \"            \", mdx(\"td\", null, \"    0.4795\"), \" \", mdx(\"td\", null, \"    0.093\"), \" \", mdx(\"td\", null, \"    5.143\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.297\"), \" \", mdx(\"td\", null, \"    0.662\")), mdx(\"tr\", null, mdx(\"th\", null, \"alcohol\"), \"              \", mdx(\"td\", null, \"    0.9432\"), \" \", mdx(\"td\", null, \"    0.134\"), \" \", mdx(\"td\", null, \"    7.014\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.680\"), \" \", mdx(\"td\", null, \"    1.207\"))), mdx(\"h3\", {\n    \"id\": \"feature-selection-using-rfe\"\n  }, \"Feature Selection using RFE\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.linear_model import LogisticRegression\\nlogReg = LogisticRegression()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.feature_selection import RFE\\nrfe = RFE(logReg,10)\\nrfe = rfe.fit(X_train,y_train)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"## RFE results\\nrfe_results = list(zip(X_train.columns,rfe.support_,rfe.ranking_))\\nsorted(rfe_results,key=lambda x : (x[2]))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"[('fixed acidity', True, 1),\\n ('volatile acidity', True, 1),\\n ('citric acid', True, 1),\\n ('residual sugar', True, 1),\\n ('chlorides', True, 1),\\n ('free sulfur dioxide', True, 1),\\n ('total sulfur dioxide', True, 1),\\n ('density', True, 1),\\n ('sulphates', True, 1),\\n ('alcohol', True, 1),\\n ('pH', False, 2)]\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RFE results show that \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"pH\"), \" can be dropped.\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_train.drop(columns=['pH'],inplace=True)\\nX_test.drop(columns=['pH'],inplace=True)\\n\\n\")), mdx(\"h3\", {\n    \"id\": \"assessing-model\"\n  }, \"Assessing Model\"), mdx(\"h4\", {\n    \"id\": \"model-1\"\n  }, \"Model 1\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_train.columns = X_train.columns[X_train.columns !='pH']\\nlogm1 = sm.GLM(y_train, sm.add_constant(X_train),family=sm.families.Binomial())\\nlogm1.fit().summary()\\n\")), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"caption\", null, \"Generalized Linear Model Regression Results\"), mdx(\"tr\", null, mdx(\"th\", null, \"Dep. Variable:\"), \"        \", mdx(\"td\", null, \"quality\"), \"     \", mdx(\"th\", null, \"  No. Observations:  \"), \"  \", mdx(\"td\", null, \"  1119\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model:\"), \"                  \", mdx(\"td\", null, \"GLM\"), \"       \", mdx(\"th\", null, \"  Df Residuals:      \"), \"  \", mdx(\"td\", null, \"  1108\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model Family:\"), \"        \", mdx(\"td\", null, \"Binomial\"), \"     \", mdx(\"th\", null, \"  Df Model:          \"), \"  \", mdx(\"td\", null, \"    10\")), mdx(\"tr\", null, mdx(\"th\", null, \"Link Function:\"), \"         \", mdx(\"td\", null, \"logit\"), \"      \", mdx(\"th\", null, \"  Scale:             \"), \" \", mdx(\"td\", null, \"  1.0000\")), mdx(\"tr\", null, mdx(\"th\", null, \"Method:\"), \"                \", mdx(\"td\", null, \"IRLS\"), \"       \", mdx(\"th\", null, \"  Log-Likelihood:    \"), \" \", mdx(\"td\", null, \" -570.89\")), mdx(\"tr\", null, mdx(\"th\", null, \"Date:\"), \"            \", mdx(\"td\", null, \"Fri, 07 Aug 2020\"), \" \", mdx(\"th\", null, \"  Deviance:          \"), \" \", mdx(\"td\", null, \"  1141.8\")), mdx(\"tr\", null, mdx(\"th\", null, \"Time:\"), \"                \", mdx(\"td\", null, \"18:45:03\"), \"     \", mdx(\"th\", null, \"  Pearson chi2:      \"), \" \", mdx(\"td\", null, \"1.08e+03\")), mdx(\"tr\", null, mdx(\"th\", null, \"No. Iterations:\"), \"          \", mdx(\"td\", null, \"5\"), \"        \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \")), mdx(\"tr\", null, mdx(\"th\", null, \"Covariance Type:\"), \"     \", mdx(\"td\", null, \"nonrobust\"), \"    \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \"))), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"tr\", null, mdx(\"td\", null), \"              \", mdx(\"th\", null, \"coef\"), \"     \", mdx(\"th\", null, \"std err\"), \"      \", mdx(\"th\", null, \"z\"), \"      \", mdx(\"th\", null, \"P>|z|\"), \"  \", mdx(\"th\", null, \"[0.025\"), \"    \", mdx(\"th\", null, \"0.975]\")), mdx(\"tr\", null, mdx(\"th\", null, \"const\"), \"                \", mdx(\"td\", null, \"    0.2631\"), \" \", mdx(\"td\", null, \"    0.076\"), \" \", mdx(\"td\", null, \"    3.478\"), \" \", mdx(\"td\", null, \" 0.001\"), \" \", mdx(\"td\", null, \"    0.115\"), \" \", mdx(\"td\", null, \"    0.411\")), mdx(\"tr\", null, mdx(\"th\", null, \"fixed acidity\"), \"        \", mdx(\"td\", null, \"    0.3894\"), \" \", mdx(\"td\", null, \"    0.141\"), \" \", mdx(\"td\", null, \"    2.762\"), \" \", mdx(\"td\", null, \" 0.006\"), \" \", mdx(\"td\", null, \"    0.113\"), \" \", mdx(\"td\", null, \"    0.666\")), mdx(\"tr\", null, mdx(\"th\", null, \"volatile acidity\"), \"     \", mdx(\"td\", null, \"   -0.5904\"), \" \", mdx(\"td\", null, \"    0.103\"), \" \", mdx(\"td\", null, \"   -5.750\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.792\"), \" \", mdx(\"td\", null, \"   -0.389\")), mdx(\"tr\", null, mdx(\"th\", null, \"citric acid\"), \"          \", mdx(\"td\", null, \"   -0.3128\"), \" \", mdx(\"td\", null, \"    0.132\"), \" \", mdx(\"td\", null, \"   -2.367\"), \" \", mdx(\"td\", null, \" 0.018\"), \" \", mdx(\"td\", null, \"   -0.572\"), \" \", mdx(\"td\", null, \"   -0.054\")), mdx(\"tr\", null, mdx(\"th\", null, \"residual sugar\"), \"       \", mdx(\"td\", null, \"    0.2110\"), \" \", mdx(\"td\", null, \"    0.088\"), \" \", mdx(\"td\", null, \"    2.389\"), \" \", mdx(\"td\", null, \" 0.017\"), \" \", mdx(\"td\", null, \"    0.038\"), \" \", mdx(\"td\", null, \"    0.384\")), mdx(\"tr\", null, mdx(\"th\", null, \"chlorides\"), \"            \", mdx(\"td\", null, \"   -0.1705\"), \" \", mdx(\"td\", null, \"    0.088\"), \" \", mdx(\"td\", null, \"   -1.933\"), \" \", mdx(\"td\", null, \" 0.053\"), \" \", mdx(\"td\", null, \"   -0.343\"), \" \", mdx(\"td\", null, \"    0.002\")), mdx(\"tr\", null, mdx(\"th\", null, \"free sulfur dioxide\"), \"  \", mdx(\"td\", null, \"    0.1609\"), \" \", mdx(\"td\", null, \"    0.105\"), \" \", mdx(\"td\", null, \"    1.528\"), \" \", mdx(\"td\", null, \" 0.127\"), \" \", mdx(\"td\", null, \"   -0.045\"), \" \", mdx(\"td\", null, \"    0.367\")), mdx(\"tr\", null, mdx(\"th\", null, \"total sulfur dioxide\"), \" \", mdx(\"td\", null, \"   -0.5228\"), \" \", mdx(\"td\", null, \"    0.113\"), \" \", mdx(\"td\", null, \"   -4.645\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.743\"), \" \", mdx(\"td\", null, \"   -0.302\")), mdx(\"tr\", null, mdx(\"th\", null, \"density\"), \"              \", mdx(\"td\", null, \"   -0.2686\"), \" \", mdx(\"td\", null, \"    0.156\"), \" \", mdx(\"td\", null, \"   -1.722\"), \" \", mdx(\"td\", null, \" 0.085\"), \" \", mdx(\"td\", null, \"   -0.574\"), \" \", mdx(\"td\", null, \"    0.037\")), mdx(\"tr\", null, mdx(\"th\", null, \"sulphates\"), \"            \", mdx(\"td\", null, \"    0.4816\"), \" \", mdx(\"td\", null, \"    0.093\"), \" \", mdx(\"td\", null, \"    5.196\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.300\"), \" \", mdx(\"td\", null, \"    0.663\")), mdx(\"tr\", null, mdx(\"th\", null, \"alcohol\"), \"              \", mdx(\"td\", null, \"    0.9287\"), \" \", mdx(\"td\", null, \"    0.119\"), \" \", mdx(\"td\", null, \"    7.803\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.695\"), \" \", mdx(\"td\", null, \"    1.162\"))), mdx(\"h4\", {\n    \"id\": \"model-2\"\n  }, \"Model 2\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"free sulfur dioxide\"), \" because of high p-value\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X = X_train.loc[:,X_train.columns != 'free sulfur dioxide']\\nlogm2 = sm.GLM(y_train, sm.add_constant(X),family=sm.families.Binomial())\\nlogm2.fit().summary()\\n\")), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"caption\", null, \"Generalized Linear Model Regression Results\"), mdx(\"tr\", null, mdx(\"th\", null, \"Dep. Variable:\"), \"        \", mdx(\"td\", null, \"quality\"), \"     \", mdx(\"th\", null, \"  No. Observations:  \"), \"  \", mdx(\"td\", null, \"  1119\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model:\"), \"                  \", mdx(\"td\", null, \"GLM\"), \"       \", mdx(\"th\", null, \"  Df Residuals:      \"), \"  \", mdx(\"td\", null, \"  1109\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model Family:\"), \"        \", mdx(\"td\", null, \"Binomial\"), \"     \", mdx(\"th\", null, \"  Df Model:          \"), \"  \", mdx(\"td\", null, \"     9\")), mdx(\"tr\", null, mdx(\"th\", null, \"Link Function:\"), \"         \", mdx(\"td\", null, \"logit\"), \"      \", mdx(\"th\", null, \"  Scale:             \"), \" \", mdx(\"td\", null, \"  1.0000\")), mdx(\"tr\", null, mdx(\"th\", null, \"Method:\"), \"                \", mdx(\"td\", null, \"IRLS\"), \"       \", mdx(\"th\", null, \"  Log-Likelihood:    \"), \" \", mdx(\"td\", null, \" -572.06\")), mdx(\"tr\", null, mdx(\"th\", null, \"Date:\"), \"            \", mdx(\"td\", null, \"Fri, 07 Aug 2020\"), \" \", mdx(\"th\", null, \"  Deviance:          \"), \" \", mdx(\"td\", null, \"  1144.1\")), mdx(\"tr\", null, mdx(\"th\", null, \"Time:\"), \"                \", mdx(\"td\", null, \"18:45:03\"), \"     \", mdx(\"th\", null, \"  Pearson chi2:      \"), \" \", mdx(\"td\", null, \"1.08e+03\")), mdx(\"tr\", null, mdx(\"th\", null, \"No. Iterations:\"), \"          \", mdx(\"td\", null, \"5\"), \"        \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \")), mdx(\"tr\", null, mdx(\"th\", null, \"Covariance Type:\"), \"     \", mdx(\"td\", null, \"nonrobust\"), \"    \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \"))), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"tr\", null, mdx(\"td\", null), \"              \", mdx(\"th\", null, \"coef\"), \"     \", mdx(\"th\", null, \"std err\"), \"      \", mdx(\"th\", null, \"z\"), \"      \", mdx(\"th\", null, \"P>|z|\"), \"  \", mdx(\"th\", null, \"[0.025\"), \"    \", mdx(\"th\", null, \"0.975]\")), mdx(\"tr\", null, mdx(\"th\", null, \"const\"), \"                \", mdx(\"td\", null, \"    0.2687\"), \" \", mdx(\"td\", null, \"    0.075\"), \" \", mdx(\"td\", null, \"    3.561\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.121\"), \" \", mdx(\"td\", null, \"    0.417\")), mdx(\"tr\", null, mdx(\"th\", null, \"fixed acidity\"), \"        \", mdx(\"td\", null, \"    0.4006\"), \" \", mdx(\"td\", null, \"    0.141\"), \" \", mdx(\"td\", null, \"    2.845\"), \" \", mdx(\"td\", null, \" 0.004\"), \" \", mdx(\"td\", null, \"    0.125\"), \" \", mdx(\"td\", null, \"    0.677\")), mdx(\"tr\", null, mdx(\"th\", null, \"volatile acidity\"), \"     \", mdx(\"td\", null, \"   -0.6186\"), \" \", mdx(\"td\", null, \"    0.102\"), \" \", mdx(\"td\", null, \"   -6.089\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.818\"), \" \", mdx(\"td\", null, \"   -0.420\")), mdx(\"tr\", null, mdx(\"th\", null, \"citric acid\"), \"          \", mdx(\"td\", null, \"   -0.3548\"), \" \", mdx(\"td\", null, \"    0.130\"), \" \", mdx(\"td\", null, \"   -2.738\"), \" \", mdx(\"td\", null, \" 0.006\"), \" \", mdx(\"td\", null, \"   -0.609\"), \" \", mdx(\"td\", null, \"   -0.101\")), mdx(\"tr\", null, mdx(\"th\", null, \"residual sugar\"), \"       \", mdx(\"td\", null, \"    0.2323\"), \" \", mdx(\"td\", null, \"    0.088\"), \" \", mdx(\"td\", null, \"    2.629\"), \" \", mdx(\"td\", null, \" 0.009\"), \" \", mdx(\"td\", null, \"    0.059\"), \" \", mdx(\"td\", null, \"    0.406\")), mdx(\"tr\", null, mdx(\"th\", null, \"chlorides\"), \"            \", mdx(\"td\", null, \"   -0.1646\"), \" \", mdx(\"td\", null, \"    0.088\"), \" \", mdx(\"td\", null, \"   -1.868\"), \" \", mdx(\"td\", null, \" 0.062\"), \" \", mdx(\"td\", null, \"   -0.337\"), \" \", mdx(\"td\", null, \"    0.008\")), mdx(\"tr\", null, mdx(\"th\", null, \"total sulfur dioxide\"), \" \", mdx(\"td\", null, \"   -0.4099\"), \" \", mdx(\"td\", null, \"    0.083\"), \" \", mdx(\"td\", null, \"   -4.911\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.574\"), \" \", mdx(\"td\", null, \"   -0.246\")), mdx(\"tr\", null, mdx(\"th\", null, \"density\"), \"              \", mdx(\"td\", null, \"   -0.2762\"), \" \", mdx(\"td\", null, \"    0.156\"), \" \", mdx(\"td\", null, \"   -1.771\"), \" \", mdx(\"td\", null, \" 0.077\"), \" \", mdx(\"td\", null, \"   -0.582\"), \" \", mdx(\"td\", null, \"    0.029\")), mdx(\"tr\", null, mdx(\"th\", null, \"sulphates\"), \"            \", mdx(\"td\", null, \"    0.4918\"), \" \", mdx(\"td\", null, \"    0.093\"), \" \", mdx(\"td\", null, \"    5.279\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.309\"), \" \", mdx(\"td\", null, \"    0.674\")), mdx(\"tr\", null, mdx(\"th\", null, \"alcohol\"), \"              \", mdx(\"td\", null, \"    0.9411\"), \" \", mdx(\"td\", null, \"    0.119\"), \" \", mdx(\"td\", null, \"    7.892\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.707\"), \" \", mdx(\"td\", null, \"    1.175\"))), mdx(\"h3\", {\n    \"id\": \"model-3\"\n  }, \"Model 3\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"free sulfur dioxide\"), \" because of high p-value\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X = X.loc[:,X.columns != 'free sulfur dioxide']\\nlogm3 = sm.GLM(y_train, sm.add_constant(X),family=sm.families.Binomial())\\nlogm3.fit().summary()\\n\")), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"caption\", null, \"Generalized Linear Model Regression Results\"), mdx(\"tr\", null, mdx(\"th\", null, \"Dep. Variable:\"), \"        \", mdx(\"td\", null, \"quality\"), \"     \", mdx(\"th\", null, \"  No. Observations:  \"), \"  \", mdx(\"td\", null, \"  1119\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model:\"), \"                  \", mdx(\"td\", null, \"GLM\"), \"       \", mdx(\"th\", null, \"  Df Residuals:      \"), \"  \", mdx(\"td\", null, \"  1109\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model Family:\"), \"        \", mdx(\"td\", null, \"Binomial\"), \"     \", mdx(\"th\", null, \"  Df Model:          \"), \"  \", mdx(\"td\", null, \"     9\")), mdx(\"tr\", null, mdx(\"th\", null, \"Link Function:\"), \"         \", mdx(\"td\", null, \"logit\"), \"      \", mdx(\"th\", null, \"  Scale:             \"), \" \", mdx(\"td\", null, \"  1.0000\")), mdx(\"tr\", null, mdx(\"th\", null, \"Method:\"), \"                \", mdx(\"td\", null, \"IRLS\"), \"       \", mdx(\"th\", null, \"  Log-Likelihood:    \"), \" \", mdx(\"td\", null, \" -572.06\")), mdx(\"tr\", null, mdx(\"th\", null, \"Date:\"), \"            \", mdx(\"td\", null, \"Fri, 07 Aug 2020\"), \" \", mdx(\"th\", null, \"  Deviance:          \"), \" \", mdx(\"td\", null, \"  1144.1\")), mdx(\"tr\", null, mdx(\"th\", null, \"Time:\"), \"                \", mdx(\"td\", null, \"18:45:03\"), \"     \", mdx(\"th\", null, \"  Pearson chi2:      \"), \" \", mdx(\"td\", null, \"1.08e+03\")), mdx(\"tr\", null, mdx(\"th\", null, \"No. Iterations:\"), \"          \", mdx(\"td\", null, \"5\"), \"        \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \")), mdx(\"tr\", null, mdx(\"th\", null, \"Covariance Type:\"), \"     \", mdx(\"td\", null, \"nonrobust\"), \"    \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \"))), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"tr\", null, mdx(\"td\", null), \"              \", mdx(\"th\", null, \"coef\"), \"     \", mdx(\"th\", null, \"std err\"), \"      \", mdx(\"th\", null, \"z\"), \"      \", mdx(\"th\", null, \"P>|z|\"), \"  \", mdx(\"th\", null, \"[0.025\"), \"    \", mdx(\"th\", null, \"0.975]\")), mdx(\"tr\", null, mdx(\"th\", null, \"const\"), \"                \", mdx(\"td\", null, \"    0.2687\"), \" \", mdx(\"td\", null, \"    0.075\"), \" \", mdx(\"td\", null, \"    3.561\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.121\"), \" \", mdx(\"td\", null, \"    0.417\")), mdx(\"tr\", null, mdx(\"th\", null, \"fixed acidity\"), \"        \", mdx(\"td\", null, \"    0.4006\"), \" \", mdx(\"td\", null, \"    0.141\"), \" \", mdx(\"td\", null, \"    2.845\"), \" \", mdx(\"td\", null, \" 0.004\"), \" \", mdx(\"td\", null, \"    0.125\"), \" \", mdx(\"td\", null, \"    0.677\")), mdx(\"tr\", null, mdx(\"th\", null, \"volatile acidity\"), \"     \", mdx(\"td\", null, \"   -0.6186\"), \" \", mdx(\"td\", null, \"    0.102\"), \" \", mdx(\"td\", null, \"   -6.089\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.818\"), \" \", mdx(\"td\", null, \"   -0.420\")), mdx(\"tr\", null, mdx(\"th\", null, \"citric acid\"), \"          \", mdx(\"td\", null, \"   -0.3548\"), \" \", mdx(\"td\", null, \"    0.130\"), \" \", mdx(\"td\", null, \"   -2.738\"), \" \", mdx(\"td\", null, \" 0.006\"), \" \", mdx(\"td\", null, \"   -0.609\"), \" \", mdx(\"td\", null, \"   -0.101\")), mdx(\"tr\", null, mdx(\"th\", null, \"residual sugar\"), \"       \", mdx(\"td\", null, \"    0.2323\"), \" \", mdx(\"td\", null, \"    0.088\"), \" \", mdx(\"td\", null, \"    2.629\"), \" \", mdx(\"td\", null, \" 0.009\"), \" \", mdx(\"td\", null, \"    0.059\"), \" \", mdx(\"td\", null, \"    0.406\")), mdx(\"tr\", null, mdx(\"th\", null, \"chlorides\"), \"            \", mdx(\"td\", null, \"   -0.1646\"), \" \", mdx(\"td\", null, \"    0.088\"), \" \", mdx(\"td\", null, \"   -1.868\"), \" \", mdx(\"td\", null, \" 0.062\"), \" \", mdx(\"td\", null, \"   -0.337\"), \" \", mdx(\"td\", null, \"    0.008\")), mdx(\"tr\", null, mdx(\"th\", null, \"total sulfur dioxide\"), \" \", mdx(\"td\", null, \"   -0.4099\"), \" \", mdx(\"td\", null, \"    0.083\"), \" \", mdx(\"td\", null, \"   -4.911\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.574\"), \" \", mdx(\"td\", null, \"   -0.246\")), mdx(\"tr\", null, mdx(\"th\", null, \"density\"), \"              \", mdx(\"td\", null, \"   -0.2762\"), \" \", mdx(\"td\", null, \"    0.156\"), \" \", mdx(\"td\", null, \"   -1.771\"), \" \", mdx(\"td\", null, \" 0.077\"), \" \", mdx(\"td\", null, \"   -0.582\"), \" \", mdx(\"td\", null, \"    0.029\")), mdx(\"tr\", null, mdx(\"th\", null, \"sulphates\"), \"            \", mdx(\"td\", null, \"    0.4918\"), \" \", mdx(\"td\", null, \"    0.093\"), \" \", mdx(\"td\", null, \"    5.279\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.309\"), \" \", mdx(\"td\", null, \"    0.674\")), mdx(\"tr\", null, mdx(\"th\", null, \"alcohol\"), \"              \", mdx(\"td\", null, \"    0.9411\"), \" \", mdx(\"td\", null, \"    0.119\"), \" \", mdx(\"td\", null, \"    7.892\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.707\"), \" \", mdx(\"td\", null, \"    1.175\"))), mdx(\"h3\", {\n    \"id\": \"model-4\"\n  }, \"Model 4\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"density\"), \" because of high p-value\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X = X.loc[:,X.columns != 'density']\\nlogm4 = sm.GLM(y_train, sm.add_constant(X),family=sm.families.Binomial())\\nlogm4.fit().summary()\\n\")), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"caption\", null, \"Generalized Linear Model Regression Results\"), mdx(\"tr\", null, mdx(\"th\", null, \"Dep. Variable:\"), \"        \", mdx(\"td\", null, \"quality\"), \"     \", mdx(\"th\", null, \"  No. Observations:  \"), \"  \", mdx(\"td\", null, \"  1119\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model:\"), \"                  \", mdx(\"td\", null, \"GLM\"), \"       \", mdx(\"th\", null, \"  Df Residuals:      \"), \"  \", mdx(\"td\", null, \"  1110\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model Family:\"), \"        \", mdx(\"td\", null, \"Binomial\"), \"     \", mdx(\"th\", null, \"  Df Model:          \"), \"  \", mdx(\"td\", null, \"     8\")), mdx(\"tr\", null, mdx(\"th\", null, \"Link Function:\"), \"         \", mdx(\"td\", null, \"logit\"), \"      \", mdx(\"th\", null, \"  Scale:             \"), \" \", mdx(\"td\", null, \"  1.0000\")), mdx(\"tr\", null, mdx(\"th\", null, \"Method:\"), \"                \", mdx(\"td\", null, \"IRLS\"), \"       \", mdx(\"th\", null, \"  Log-Likelihood:    \"), \" \", mdx(\"td\", null, \" -573.64\")), mdx(\"tr\", null, mdx(\"th\", null, \"Date:\"), \"            \", mdx(\"td\", null, \"Fri, 07 Aug 2020\"), \" \", mdx(\"th\", null, \"  Deviance:          \"), \" \", mdx(\"td\", null, \"  1147.3\")), mdx(\"tr\", null, mdx(\"th\", null, \"Time:\"), \"                \", mdx(\"td\", null, \"18:45:03\"), \"     \", mdx(\"th\", null, \"  Pearson chi2:      \"), \" \", mdx(\"td\", null, \"1.10e+03\")), mdx(\"tr\", null, mdx(\"th\", null, \"No. Iterations:\"), \"          \", mdx(\"td\", null, \"5\"), \"        \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \")), mdx(\"tr\", null, mdx(\"th\", null, \"Covariance Type:\"), \"     \", mdx(\"td\", null, \"nonrobust\"), \"    \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \"))), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"tr\", null, mdx(\"td\", null), \"              \", mdx(\"th\", null, \"coef\"), \"     \", mdx(\"th\", null, \"std err\"), \"      \", mdx(\"th\", null, \"z\"), \"      \", mdx(\"th\", null, \"P>|z|\"), \"  \", mdx(\"th\", null, \"[0.025\"), \"    \", mdx(\"th\", null, \"0.975]\")), mdx(\"tr\", null, mdx(\"th\", null, \"const\"), \"                \", mdx(\"td\", null, \"    0.2590\"), \" \", mdx(\"td\", null, \"    0.075\"), \" \", mdx(\"td\", null, \"    3.451\"), \" \", mdx(\"td\", null, \" 0.001\"), \" \", mdx(\"td\", null, \"    0.112\"), \" \", mdx(\"td\", null, \"    0.406\")), mdx(\"tr\", null, mdx(\"th\", null, \"fixed acidity\"), \"        \", mdx(\"td\", null, \"    0.2393\"), \" \", mdx(\"td\", null, \"    0.107\"), \" \", mdx(\"td\", null, \"    2.234\"), \" \", mdx(\"td\", null, \" 0.025\"), \" \", mdx(\"td\", null, \"    0.029\"), \" \", mdx(\"td\", null, \"    0.449\")), mdx(\"tr\", null, mdx(\"th\", null, \"volatile acidity\"), \"     \", mdx(\"td\", null, \"   -0.6496\"), \" \", mdx(\"td\", null, \"    0.101\"), \" \", mdx(\"td\", null, \"   -6.426\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.848\"), \" \", mdx(\"td\", null, \"   -0.451\")), mdx(\"tr\", null, mdx(\"th\", null, \"citric acid\"), \"          \", mdx(\"td\", null, \"   -0.3570\"), \" \", mdx(\"td\", null, \"    0.130\"), \" \", mdx(\"td\", null, \"   -2.747\"), \" \", mdx(\"td\", null, \" 0.006\"), \" \", mdx(\"td\", null, \"   -0.612\"), \" \", mdx(\"td\", null, \"   -0.102\")), mdx(\"tr\", null, mdx(\"th\", null, \"residual sugar\"), \"       \", mdx(\"td\", null, \"    0.1478\"), \" \", mdx(\"td\", null, \"    0.074\"), \" \", mdx(\"td\", null, \"    1.998\"), \" \", mdx(\"td\", null, \" 0.046\"), \" \", mdx(\"td\", null, \"    0.003\"), \" \", mdx(\"td\", null, \"    0.293\")), mdx(\"tr\", null, mdx(\"th\", null, \"chlorides\"), \"            \", mdx(\"td\", null, \"   -0.1540\"), \" \", mdx(\"td\", null, \"    0.088\"), \" \", mdx(\"td\", null, \"   -1.748\"), \" \", mdx(\"td\", null, \" 0.080\"), \" \", mdx(\"td\", null, \"   -0.327\"), \" \", mdx(\"td\", null, \"    0.019\")), mdx(\"tr\", null, mdx(\"th\", null, \"total sulfur dioxide\"), \" \", mdx(\"td\", null, \"   -0.4002\"), \" \", mdx(\"td\", null, \"    0.083\"), \" \", mdx(\"td\", null, \"   -4.822\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.563\"), \" \", mdx(\"td\", null, \"   -0.238\")), mdx(\"tr\", null, mdx(\"th\", null, \"sulphates\"), \"            \", mdx(\"td\", null, \"    0.4584\"), \" \", mdx(\"td\", null, \"    0.090\"), \" \", mdx(\"td\", null, \"    5.090\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.282\"), \" \", mdx(\"td\", null, \"    0.635\")), mdx(\"tr\", null, mdx(\"th\", null, \"alcohol\"), \"              \", mdx(\"td\", null, \"    1.0615\"), \" \", mdx(\"td\", null, \"    0.099\"), \" \", mdx(\"td\", null, \"   10.722\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.867\"), \" \", mdx(\"td\", null, \"    1.255\"))), mdx(\"h3\", {\n    \"id\": \"model-5\"\n  }, \"Model 5\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"chlorides\"), \" because of high p-value\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X = X.loc[:,X.columns != 'chlorides']\\nlogm5 = sm.GLM(y_train, sm.add_constant(X),family=sm.families.Binomial())\\nlogm5.fit().summary()\\n\")), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"caption\", null, \"Generalized Linear Model Regression Results\"), mdx(\"tr\", null, mdx(\"th\", null, \"Dep. Variable:\"), \"        \", mdx(\"td\", null, \"quality\"), \"     \", mdx(\"th\", null, \"  No. Observations:  \"), \"  \", mdx(\"td\", null, \"  1119\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model:\"), \"                  \", mdx(\"td\", null, \"GLM\"), \"       \", mdx(\"th\", null, \"  Df Residuals:      \"), \"  \", mdx(\"td\", null, \"  1111\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model Family:\"), \"        \", mdx(\"td\", null, \"Binomial\"), \"     \", mdx(\"th\", null, \"  Df Model:          \"), \"  \", mdx(\"td\", null, \"     7\")), mdx(\"tr\", null, mdx(\"th\", null, \"Link Function:\"), \"         \", mdx(\"td\", null, \"logit\"), \"      \", mdx(\"th\", null, \"  Scale:             \"), \" \", mdx(\"td\", null, \"  1.0000\")), mdx(\"tr\", null, mdx(\"th\", null, \"Method:\"), \"                \", mdx(\"td\", null, \"IRLS\"), \"       \", mdx(\"th\", null, \"  Log-Likelihood:    \"), \" \", mdx(\"td\", null, \" -575.22\")), mdx(\"tr\", null, mdx(\"th\", null, \"Date:\"), \"            \", mdx(\"td\", null, \"Fri, 07 Aug 2020\"), \" \", mdx(\"th\", null, \"  Deviance:          \"), \" \", mdx(\"td\", null, \"  1150.4\")), mdx(\"tr\", null, mdx(\"th\", null, \"Time:\"), \"                \", mdx(\"td\", null, \"18:45:03\"), \"     \", mdx(\"th\", null, \"  Pearson chi2:      \"), \" \", mdx(\"td\", null, \"1.11e+03\")), mdx(\"tr\", null, mdx(\"th\", null, \"No. Iterations:\"), \"          \", mdx(\"td\", null, \"5\"), \"        \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \")), mdx(\"tr\", null, mdx(\"th\", null, \"Covariance Type:\"), \"     \", mdx(\"td\", null, \"nonrobust\"), \"    \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \"))), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"tr\", null, mdx(\"td\", null), \"              \", mdx(\"th\", null, \"coef\"), \"     \", mdx(\"th\", null, \"std err\"), \"      \", mdx(\"th\", null, \"z\"), \"      \", mdx(\"th\", null, \"P>|z|\"), \"  \", mdx(\"th\", null, \"[0.025\"), \"    \", mdx(\"th\", null, \"0.975]\")), mdx(\"tr\", null, mdx(\"th\", null, \"const\"), \"                \", mdx(\"td\", null, \"    0.2577\"), \" \", mdx(\"td\", null, \"    0.075\"), \" \", mdx(\"td\", null, \"    3.438\"), \" \", mdx(\"td\", null, \" 0.001\"), \" \", mdx(\"td\", null, \"    0.111\"), \" \", mdx(\"td\", null, \"    0.405\")), mdx(\"tr\", null, mdx(\"th\", null, \"fixed acidity\"), \"        \", mdx(\"td\", null, \"    0.2787\"), \" \", mdx(\"td\", null, \"    0.105\"), \" \", mdx(\"td\", null, \"    2.659\"), \" \", mdx(\"td\", null, \" 0.008\"), \" \", mdx(\"td\", null, \"    0.073\"), \" \", mdx(\"td\", null, \"    0.484\")), mdx(\"tr\", null, mdx(\"th\", null, \"volatile acidity\"), \"     \", mdx(\"td\", null, \"   -0.6975\"), \" \", mdx(\"td\", null, \"    0.098\"), \" \", mdx(\"td\", null, \"   -7.105\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.890\"), \" \", mdx(\"td\", null, \"   -0.505\")), mdx(\"tr\", null, mdx(\"th\", null, \"citric acid\"), \"          \", mdx(\"td\", null, \"   -0.4242\"), \" \", mdx(\"td\", null, \"    0.125\"), \" \", mdx(\"td\", null, \"   -3.401\"), \" \", mdx(\"td\", null, \" 0.001\"), \" \", mdx(\"td\", null, \"   -0.669\"), \" \", mdx(\"td\", null, \"   -0.180\")), mdx(\"tr\", null, mdx(\"th\", null, \"residual sugar\"), \"       \", mdx(\"td\", null, \"    0.1398\"), \" \", mdx(\"td\", null, \"    0.073\"), \" \", mdx(\"td\", null, \"    1.914\"), \" \", mdx(\"td\", null, \" 0.056\"), \" \", mdx(\"td\", null, \"   -0.003\"), \" \", mdx(\"td\", null, \"    0.283\")), mdx(\"tr\", null, mdx(\"th\", null, \"total sulfur dioxide\"), \" \", mdx(\"td\", null, \"   -0.3884\"), \" \", mdx(\"td\", null, \"    0.082\"), \" \", mdx(\"td\", null, \"   -4.712\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.550\"), \" \", mdx(\"td\", null, \"   -0.227\")), mdx(\"tr\", null, mdx(\"th\", null, \"sulphates\"), \"            \", mdx(\"td\", null, \"    0.3856\"), \" \", mdx(\"td\", null, \"    0.078\"), \" \", mdx(\"td\", null, \"    4.946\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.233\"), \" \", mdx(\"td\", null, \"    0.538\")), mdx(\"tr\", null, mdx(\"th\", null, \"alcohol\"), \"              \", mdx(\"td\", null, \"    1.1119\"), \" \", mdx(\"td\", null, \"    0.096\"), \" \", mdx(\"td\", null, \"   11.633\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.925\"), \" \", mdx(\"td\", null, \"    1.299\"))), mdx(\"h3\", {\n    \"id\": \"model-6\"\n  }, \"Model 6\"), mdx(\"p\", null, \"\\u2014 Dropping \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"residual sugar\"), \" because of high p-value\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X = X.loc[:,X.columns != 'residual sugar']\\nlogm6 = sm.GLM(y_train, sm.add_constant(X),family=sm.families.Binomial())\\nlogm6.fit().summary()\\n\")), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"caption\", null, \"Generalized Linear Model Regression Results\"), mdx(\"tr\", null, mdx(\"th\", null, \"Dep. Variable:\"), \"        \", mdx(\"td\", null, \"quality\"), \"     \", mdx(\"th\", null, \"  No. Observations:  \"), \"  \", mdx(\"td\", null, \"  1119\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model:\"), \"                  \", mdx(\"td\", null, \"GLM\"), \"       \", mdx(\"th\", null, \"  Df Residuals:      \"), \"  \", mdx(\"td\", null, \"  1112\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model Family:\"), \"        \", mdx(\"td\", null, \"Binomial\"), \"     \", mdx(\"th\", null, \"  Df Model:          \"), \"  \", mdx(\"td\", null, \"     6\")), mdx(\"tr\", null, mdx(\"th\", null, \"Link Function:\"), \"         \", mdx(\"td\", null, \"logit\"), \"      \", mdx(\"th\", null, \"  Scale:             \"), \" \", mdx(\"td\", null, \"  1.0000\")), mdx(\"tr\", null, mdx(\"th\", null, \"Method:\"), \"                \", mdx(\"td\", null, \"IRLS\"), \"       \", mdx(\"th\", null, \"  Log-Likelihood:    \"), \" \", mdx(\"td\", null, \" -577.02\")), mdx(\"tr\", null, mdx(\"th\", null, \"Date:\"), \"            \", mdx(\"td\", null, \"Fri, 07 Aug 2020\"), \" \", mdx(\"th\", null, \"  Deviance:          \"), \" \", mdx(\"td\", null, \"  1154.0\")), mdx(\"tr\", null, mdx(\"th\", null, \"Time:\"), \"                \", mdx(\"td\", null, \"18:45:03\"), \"     \", mdx(\"th\", null, \"  Pearson chi2:      \"), \" \", mdx(\"td\", null, \"1.10e+03\")), mdx(\"tr\", null, mdx(\"th\", null, \"No. Iterations:\"), \"          \", mdx(\"td\", null, \"5\"), \"        \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \")), mdx(\"tr\", null, mdx(\"th\", null, \"Covariance Type:\"), \"     \", mdx(\"td\", null, \"nonrobust\"), \"    \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \"))), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"tr\", null, mdx(\"td\", null), \"              \", mdx(\"th\", null, \"coef\"), \"     \", mdx(\"th\", null, \"std err\"), \"      \", mdx(\"th\", null, \"z\"), \"      \", mdx(\"th\", null, \"P>|z|\"), \"  \", mdx(\"th\", null, \"[0.025\"), \"    \", mdx(\"th\", null, \"0.975]\")), mdx(\"tr\", null, mdx(\"th\", null, \"const\"), \"                \", mdx(\"td\", null, \"    0.2593\"), \" \", mdx(\"td\", null, \"    0.075\"), \" \", mdx(\"td\", null, \"    3.465\"), \" \", mdx(\"td\", null, \" 0.001\"), \" \", mdx(\"td\", null, \"    0.113\"), \" \", mdx(\"td\", null, \"    0.406\")), mdx(\"tr\", null, mdx(\"th\", null, \"fixed acidity\"), \"        \", mdx(\"td\", null, \"    0.2883\"), \" \", mdx(\"td\", null, \"    0.105\"), \" \", mdx(\"td\", null, \"    2.753\"), \" \", mdx(\"td\", null, \" 0.006\"), \" \", mdx(\"td\", null, \"    0.083\"), \" \", mdx(\"td\", null, \"    0.494\")), mdx(\"tr\", null, mdx(\"th\", null, \"volatile acidity\"), \"     \", mdx(\"td\", null, \"   -0.6874\"), \" \", mdx(\"td\", null, \"    0.097\"), \" \", mdx(\"td\", null, \"   -7.064\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.878\"), \" \", mdx(\"td\", null, \"   -0.497\")), mdx(\"tr\", null, mdx(\"th\", null, \"citric acid\"), \"          \", mdx(\"td\", null, \"   -0.4051\"), \" \", mdx(\"td\", null, \"    0.124\"), \" \", mdx(\"td\", null, \"   -3.271\"), \" \", mdx(\"td\", null, \" 0.001\"), \" \", mdx(\"td\", null, \"   -0.648\"), \" \", mdx(\"td\", null, \"   -0.162\")), mdx(\"tr\", null, mdx(\"th\", null, \"total sulfur dioxide\"), \" \", mdx(\"td\", null, \"   -0.3479\"), \" \", mdx(\"td\", null, \"    0.079\"), \" \", mdx(\"td\", null, \"   -4.402\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.503\"), \" \", mdx(\"td\", null, \"   -0.193\")), mdx(\"tr\", null, mdx(\"th\", null, \"sulphates\"), \"            \", mdx(\"td\", null, \"    0.3769\"), \" \", mdx(\"td\", null, \"    0.078\"), \" \", mdx(\"td\", null, \"    4.846\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.224\"), \" \", mdx(\"td\", null, \"    0.529\")), mdx(\"tr\", null, mdx(\"th\", null, \"alcohol\"), \"              \", mdx(\"td\", null, \"    1.1186\"), \" \", mdx(\"td\", null, \"    0.095\"), \" \", mdx(\"td\", null, \"   11.716\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.931\"), \" \", mdx(\"td\", null, \"    1.306\"))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"All the p-values are very low. So the variable which remain have statistically significant relationships.\")), mdx(\"h3\", {\n    \"id\": \"checking-multi-collinearity\"\n  }, \"Checking Multi-Collinearity\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from statsmodels.stats.outliers_influence import variance_inflation_factor\\ndef vif(X) :\\n    df = sm.add_constant(X)\\n    vif = [variance_inflation_factor(df.values,i) for i in range(df.shape[1])]\\n    vif_frame = pd.DataFrame({'vif' : vif[0:]},index = df.columns).reset_index()\\n    print(vif_frame.sort_values(by='vif',ascending=False))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"vif(X)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"index       vif\\n3           citric acid  2.735105\\n1         fixed acidity  2.113091\\n2      volatile acidity  1.498180\\n6               alcohol  1.163675\\n5             sulphates  1.150064\\n4  total sulfur dioxide  1.121176\\n0                 const  1.000000\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"As we can see, there\\u2019s no multi collinearity since VIF < 5\")), mdx(\"h3\", {\n    \"id\": \"final-model\"\n  }, \"Final Model\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print('Selected columns :' , X.columns)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Selected columns : Index(['fixed acidity', 'volatile acidity', 'citric acid',\\n       'total sulfur dioxide', 'sulphates', 'alcohol'],\\n      dtype='object')\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"logm_final = sm.GLM(y_train, sm.add_constant(X_train[X.columns]),family=sm.families.Binomial())\\nres = logm_final.fit()\\nres.summary()\\n\")), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"caption\", null, \"Generalized Linear Model Regression Results\"), mdx(\"tr\", null, mdx(\"th\", null, \"Dep. Variable:\"), \"        \", mdx(\"td\", null, \"quality\"), \"     \", mdx(\"th\", null, \"  No. Observations:  \"), \"  \", mdx(\"td\", null, \"  1119\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model:\"), \"                  \", mdx(\"td\", null, \"GLM\"), \"       \", mdx(\"th\", null, \"  Df Residuals:      \"), \"  \", mdx(\"td\", null, \"  1112\")), mdx(\"tr\", null, mdx(\"th\", null, \"Model Family:\"), \"        \", mdx(\"td\", null, \"Binomial\"), \"     \", mdx(\"th\", null, \"  Df Model:          \"), \"  \", mdx(\"td\", null, \"     6\")), mdx(\"tr\", null, mdx(\"th\", null, \"Link Function:\"), \"         \", mdx(\"td\", null, \"logit\"), \"      \", mdx(\"th\", null, \"  Scale:             \"), \" \", mdx(\"td\", null, \"  1.0000\")), mdx(\"tr\", null, mdx(\"th\", null, \"Method:\"), \"                \", mdx(\"td\", null, \"IRLS\"), \"       \", mdx(\"th\", null, \"  Log-Likelihood:    \"), \" \", mdx(\"td\", null, \" -577.02\")), mdx(\"tr\", null, mdx(\"th\", null, \"Date:\"), \"            \", mdx(\"td\", null, \"Fri, 07 Aug 2020\"), \" \", mdx(\"th\", null, \"  Deviance:          \"), \" \", mdx(\"td\", null, \"  1154.0\")), mdx(\"tr\", null, mdx(\"th\", null, \"Time:\"), \"                \", mdx(\"td\", null, \"18:45:04\"), \"     \", mdx(\"th\", null, \"  Pearson chi2:      \"), \" \", mdx(\"td\", null, \"1.10e+03\")), mdx(\"tr\", null, mdx(\"th\", null, \"No. Iterations:\"), \"          \", mdx(\"td\", null, \"5\"), \"        \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \")), mdx(\"tr\", null, mdx(\"th\", null, \"Covariance Type:\"), \"     \", mdx(\"td\", null, \"nonrobust\"), \"    \", mdx(\"th\", null, \"                     \"), \"     \", mdx(\"td\", null, \" \"))), mdx(\"table\", {\n    className: \"simpletable\"\n  }, mdx(\"tr\", null, mdx(\"td\", null), \"              \", mdx(\"th\", null, \"coef\"), \"     \", mdx(\"th\", null, \"std err\"), \"      \", mdx(\"th\", null, \"z\"), \"      \", mdx(\"th\", null, \"P>|z|\"), \"  \", mdx(\"th\", null, \"[0.025\"), \"    \", mdx(\"th\", null, \"0.975]\")), mdx(\"tr\", null, mdx(\"th\", null, \"const\"), \"                \", mdx(\"td\", null, \"    0.2593\"), \" \", mdx(\"td\", null, \"    0.075\"), \" \", mdx(\"td\", null, \"    3.465\"), \" \", mdx(\"td\", null, \" 0.001\"), \" \", mdx(\"td\", null, \"    0.113\"), \" \", mdx(\"td\", null, \"    0.406\")), mdx(\"tr\", null, mdx(\"th\", null, \"fixed acidity\"), \"        \", mdx(\"td\", null, \"    0.2883\"), \" \", mdx(\"td\", null, \"    0.105\"), \" \", mdx(\"td\", null, \"    2.753\"), \" \", mdx(\"td\", null, \" 0.006\"), \" \", mdx(\"td\", null, \"    0.083\"), \" \", mdx(\"td\", null, \"    0.494\")), mdx(\"tr\", null, mdx(\"th\", null, \"volatile acidity\"), \"     \", mdx(\"td\", null, \"   -0.6874\"), \" \", mdx(\"td\", null, \"    0.097\"), \" \", mdx(\"td\", null, \"   -7.064\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.878\"), \" \", mdx(\"td\", null, \"   -0.497\")), mdx(\"tr\", null, mdx(\"th\", null, \"citric acid\"), \"          \", mdx(\"td\", null, \"   -0.4051\"), \" \", mdx(\"td\", null, \"    0.124\"), \" \", mdx(\"td\", null, \"   -3.271\"), \" \", mdx(\"td\", null, \" 0.001\"), \" \", mdx(\"td\", null, \"   -0.648\"), \" \", mdx(\"td\", null, \"   -0.162\")), mdx(\"tr\", null, mdx(\"th\", null, \"total sulfur dioxide\"), \" \", mdx(\"td\", null, \"   -0.3479\"), \" \", mdx(\"td\", null, \"    0.079\"), \" \", mdx(\"td\", null, \"   -4.402\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"   -0.503\"), \" \", mdx(\"td\", null, \"   -0.193\")), mdx(\"tr\", null, mdx(\"th\", null, \"sulphates\"), \"            \", mdx(\"td\", null, \"    0.3769\"), \" \", mdx(\"td\", null, \"    0.078\"), \" \", mdx(\"td\", null, \"    4.846\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.224\"), \" \", mdx(\"td\", null, \"    0.529\")), mdx(\"tr\", null, mdx(\"th\", null, \"alcohol\"), \"              \", mdx(\"td\", null, \"    1.1186\"), \" \", mdx(\"td\", null, \"    0.095\"), \" \", mdx(\"td\", null, \"   11.716\"), \" \", mdx(\"td\", null, \" 0.000\"), \" \", mdx(\"td\", null, \"    0.931\"), \" \", mdx(\"td\", null, \"    1.306\"))), mdx(\"h3\", {\n    \"id\": \"making-predictions-on-train-set\"\n  }, \"Making Predictions on Train Set\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"selected_vars = X.columns\\ny_train_pred = res.predict(sm.add_constant(X_train[X.columns]))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(y_train_pred.head())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"858    0.855444\\n654    0.255470\\n721    0.172042\\n176    0.388875\\n692    0.379338\\ndtype: float64\\n\")), mdx(\"h3\", {\n    \"id\": \"wine-quality-vs-predicted-probability\"\n  }, \"Wine Quality vs Predicted Probability\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"predictions = pd.DataFrame({'Quality' : y_train.values,'class_probability' : y_train_pred.values.reshape(-1)}, index=X_train.index)\\nprint(predictions.head())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Quality  class_probability\\n858        1           0.855444\\n654        0           0.255470\\n721        0           0.172042\\n176        0           0.388875\\n692        0           0.379338\\n\")), mdx(\"h3\", {\n    \"id\": \"classification-threshold\"\n  }, \"Classification Threshold\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Let us assume that any probability < 0.5 is Bad and >0.5 is Good\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"predictions['Predicted_Quality'] = predictions['class_probability'].apply(lambda x : 1 if x > 0.5 else 0)\\nprint(predictions.head())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Quality  class_probability  Predicted_Quality\\n858        1           0.855444                  1\\n654        0           0.255470                  0\\n721        0           0.172042                  0\\n176        0           0.388875                  0\\n692        0           0.379338                  0\\n\")), mdx(\"h3\", {\n    \"id\": \"simple-metrics\"\n  }, \"Simple Metrics\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn import metrics\\n\")), mdx(\"h4\", {\n    \"id\": \"confusion-matrix\"\n  }, \"Confusion Matrix\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"confusion = metrics.confusion_matrix(predictions['Quality'],predictions['Predicted_Quality'])\\nprint(confusion)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"[[390 130]\\n [147 452]]\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The above result could be interpreted in the following manner\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"a\", \"[\", \"i,j\", \"]\", \" is the no of times class j was predicted when actual was class i\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"So TN : 390, FP : 130, FN : 147, TP : 452\")), mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"Predicted >\"), mdx(\"th\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"0\"), mdx(\"th\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"1\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"Actual\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  })), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }))), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"0\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"TN = 390\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"FP =130\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"1\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"FN =147\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"TP = 452\")))), mdx(\"p\", null, \"0 : bad, 1 : good\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Accuracy of the model\\nprint(metrics.accuracy_score(predictions['Quality'],predictions['Predicted_Quality']))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"0.7524575513851653\\n\")), mdx(\"h3\", {\n    \"id\": \"metrics-beyond-simple-accuracy\"\n  }, \"Metrics beyond Simple Accuracy\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"TP = confusion[1,1]\\nTN = confusion[0,0]\\nFP = confusion[0,1]\\nFN = confusion[1,0]\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"#### Metrics\\nimport math\\ndef model_metrics(TP,TN,FP,FN) :\\n    print('Accuracy :' , round((TP + TN)/float(TP+TN+FP+FN),3))\\n    print('Misclassification Rate / Error Rate :', round((FP + FN)/float(TP+TN+FP+FN),3))\\n    print('Sensitivity / True Positive Rate / Recall :', round(TP/float(FN + TP),3))\\n    sensitivity = round(TP/float(FN + TP),3)\\n    print('Specificity / True Negative Rate : ', round(TN/float(TN + FP),3))\\n    specificity = round(TN/float(TN + FP),3)\\n    print('False Positive Rate :',round(FP/float(TN + FP),3))\\n    print('Precision / Positive Predictive Value :', round(TP/float(TP + FP),3))\\n    precision = round(TP/float(TP + FP),3)\\n    print('Prevalance :',round((FN + TP)/float(TP+TN+FP+FN),3))\\n    print('Negative Predictive Value', round(TN/float(TN + FN),3))\\n    print('Likelihood Ratio : Sensitivity / 1-Specificity :', round(sensitivity/float(1-specificity) ,3))\\n    print('F1-score :', round(2*precision*sensitivity/(precision + sensitivity),3))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"model_metrics(TP,TN,FP,FN)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Accuracy : 0.752\\nMisclassification Rate / Error Rate : 0.248\\nSensitivity / True Positive Rate / Recall : 0.755\\nSpecificity / True Negative Rate :  0.75\\nFalse Positive Rate : 0.25\\nPrecision / Positive Predictive Value : 0.777\\nPrevalance : 0.535\\nNegative Predictive Value 0.726\\nLikelihood Ratio : Sensitivity / 1-Specificity : 3.02\\nF1-score : 0.766\\n\")), mdx(\"h3\", {\n    \"id\": \"roc-curve\"\n  }, \"ROC curve\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(predictions.head())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Quality  class_probability  Predicted_Quality\\n858        1           0.855444                  1\\n654        0           0.255470                  0\\n721        0           0.172042                  0\\n176        0           0.388875                  0\\n692        0           0.379338                  0\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# generating predictions for cutoffs between 0 and 1\\ncutoffs = pd.DataFrame()\\nfor i in np.arange(0,1,0.1) :\\n    cutoffs[i] = predictions['class_probability'].map(lambda x : 1 if x > i else 0)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"tpr = []\\nfpr = []\\nfor column in cutoffs.columns :\\n    confusion = metrics.confusion_matrix(predictions['Quality'],cutoffs[column])\\n    TP = confusion[1,1] # true positive\\n    TN = confusion[0,0] # true negatives\\n    FP = confusion[0,1] # false positives\\n    FN = confusion[1,0] # false negatives\\n    tpr.append(TP/float(TP + FN))\\n    fpr.append(FP/float(FP + TN))\\nplt.title('ROC curve')\\nplt.xlabel('False Positive Rate')\\nplt.ylabel('True Positive Rate')\\nsns.scatterplot(fpr,tpr);\\n\\n\\n\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"/blog/f3d5d5570006f2ef356220a87afe2d60/output_75_0.svg\",\n    \"alt\": \"svg\"\n  }))), mdx(\"h3\", {\n    \"id\": \"optimum-cut-off\"\n  }, \"Optimum Cut Off\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"sensitivity = []\\nspecificity = []\\naccuracy = []\\ncoffs = []\\nfor column in cutoffs.columns :\\n    confusion = metrics.confusion_matrix(predictions['Quality'],cutoffs[column])\\n    TP = confusion[1,1] # true positive\\n    TN = confusion[0,0] # true negatives\\n    FP = confusion[0,1] # false positives\\n    FN = confusion[1,0] # false negatives\\n    sensitivity.append(TP/float(TP + FN))\\n    specificity.append(1 - FP/float(FP + TN))\\n    accuracy.append((TP + TN)/(TP + TN + FP + FN))\\nfig,ax = plt.subplots()\\nax.set_xlabel('Cutoffs')\\nax.plot(cutoffs.columns,sensitivity,label='sensitivity')\\nax.plot(cutoffs.columns,specificity,label='specificity')\\nax.plot(cutoffs.columns,accuracy,label='accuracy')\\nax.legend(('sensitivity','specificity','accuracy'))\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"/blog/dadd25a3ae14e21fa3c988e13f3820ef/output_77_0.svg\",\n    \"alt\": \"svg\"\n  }))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"From the above plot, 0.5 seems like the optimum Threshold for classification\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"predictions['Final_Predictions'] = predictions['Predicted_Quality'].map(lambda x : 1 if x > 0.5 else 0)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"confusion_final = metrics.confusion_matrix(predictions['Quality'],predictions['Final_Predictions'])\\nTP = confusion_final[1,1]\\nTN = confusion_final[0,0]\\nFP = confusion_final[0,1]\\nFN = confusion_final[1,0]\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"#### Metrics\\nmodel_metrics(TP,TN,FP,FN)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Accuracy : 0.752\\nMisclassification Rate / Error Rate : 0.248\\nSensitivity / True Positive Rate / Recall : 0.755\\nSpecificity / True Negative Rate :  0.75\\nFalse Positive Rate : 0.25\\nPrecision / Positive Predictive Value : 0.777\\nPrevalance : 0.535\\nNegative Predictive Value 0.726\\nLikelihood Ratio : Sensitivity / 1-Specificity : 3.02\\nF1-score : 0.766\\n\")), mdx(\"h3\", {\n    \"id\": \"precision-and-recall\"\n  }, \"Precision and Recall\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"precision = [] # positive predictive power - TP / TP + FP\\nrecall = []   ## same as sensitivity\\n\\nfor column in cutoffs.columns :\\n    confusion = metrics.confusion_matrix(predictions['Quality'],cutoffs[column])\\n    TP = confusion[1,1] # true positive\\n    TN = confusion[0,0] # true negatives\\n    FP = confusion[0,1] # false positives\\n    FN = confusion[1,0] # false negatives\\n    precision.append(TP/float(TP + FP))\\n    recall.append(TP/float(FN + TP))\\n\\nfig,ax = plt.subplots()\\nax.set_xlabel('Cutoffs')\\nax.plot(cutoffs.columns,precision,label='precision')\\nax.plot(cutoffs.columns,recall,label='recall')\\nax.legend(('precision','recall'))\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"/blog/bcab01007e432cb6d6aebcf39c9fac90/output_83_0.svg\",\n    \"alt\": \"svg\"\n  }))), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# using sklearn utilities\\nfrom sklearn.metrics import precision_score, recall_score\\nprint('Precision',precision_score(predictions['Quality'],predictions['Predicted_Quality']))\\nprint('Recall', recall_score(predictions['Quality'],predictions['Predicted_Quality']))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Precision 0.7766323024054983\\nRecall 0.7545909849749582\\n\")), mdx(\"h3\", {\n    \"id\": \"predictions-on-test-set\"\n  }, \"Predictions on Test set\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(X_test[X.columns].head())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"fixed acidity  volatile acidity  citric acid  total sulfur dioxide  \\\\\\n1254      -0.302046          0.908335    -1.056968             -0.341840\\n1087      -0.244545         -1.905494     0.765915             -0.496144\\n822       -0.934554          0.025565    -0.702518             -0.310980\\n1514      -0.819552          1.680759    -0.297433              0.583983\\n902       -0.532049          0.549710    -0.854425             -0.403562\\n\\n      sulphates   alcohol\\n1254   0.203567  0.482194\\n1087   0.203567  0.766538\\n822   -0.099025 -0.560402\\n1514   0.385122 -1.097497\\n902    0.203567  0.387412\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"test_predictions = pd.DataFrame()\\nX_test_ = X_test[X.columns]\\ntest_predictions['Class_Probabilities'] = res.predict(sm.add_constant(X_test_))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"test_predictions['Original'] = y_test\\ntest_predictions.index = y_test.index\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Predictions are made using 0.5 as the threshold\\ntest_predictions['Predicted'] = test_predictions['Class_Probabilities'].map(lambda x : 1 if x > 0.5 else 0)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"#### Metrics\\nTN,FP,FN,TP = metrics.confusion_matrix(test_predictions['Original'],test_predictions['Predicted']).reshape(-1)\\nmodel_metrics(TP,TN,FP,FN)\\n\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Accuracy : 0.746\\nMisclassification Rate / Error Rate : 0.254\\nSensitivity / True Positive Rate / Recall : 0.797\\nSpecificity / True Negative Rate :  0.688\\nFalse Positive Rate : 0.312\\nPrecision / Positive Predictive Value : 0.745\\nPrevalance : 0.533\\nNegative Predictive Value 0.748\\nLikelihood Ratio : Sensitivity / 1-Specificity : 2.554\\nF1-score : 0.77\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","hero":{"full":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAECAwT/xAAWAQEBAQAAAAAAAAAAAAAAAAABAgP/2gAMAwEAAhADEAAAAcER5VUMT//EABkQAQEBAQEBAAAAAAAAAAAAAAECABEDEv/aAAgBAQABBQKfFZ+OLOm0yvN//8QAFREBAQAAAAAAAAAAAAAAAAAAECH/2gAIAQMBAT8Bh//EABYRAQEBAAAAAAAAAAAAAAAAAAARIf/aAAgBAgEBPwHVf//EABkQAAMAAwAAAAAAAAAAAAAAAAEQEQAiMv/aAAgBAQAGPwLnNgXav//EABsQAAMAAgMAAAAAAAAAAAAAAAABIRFBUWGx/9oACAEBAAE/Ic+TUvSD4E5hNXpQM32V7P/aAAwDAQACAAMAAAAQi8//xAAWEQEBAQAAAAAAAAAAAAAAAAAAEUH/2gAIAQMBAT8QxEf/xAAXEQADAQAAAAAAAAAAAAAAAAAAARFR/9oACAECAQE/EG6K0//EABoQAQADAAMAAAAAAAAAAAAAAAEAESExUWH/2gAIAQEAAT8QPKoW3KzM9lQQdOJY7D0gfaY2slkgO8rlvayf/9k=","aspectRatio":1.5031847133757963,"src":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/58fe7/evgeniy-konev-3OrRheb618Y-unsplash.jpg","srcSet":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/e0f30/evgeniy-konev-3OrRheb618Y-unsplash.jpg 236w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/86afd/evgeniy-konev-3OrRheb618Y-unsplash.jpg 472w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/58fe7/evgeniy-konev-3OrRheb618Y-unsplash.jpg 944w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/02748/evgeniy-konev-3OrRheb618Y-unsplash.jpg 1416w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/5c241/evgeniy-konev-3OrRheb618Y-unsplash.jpg 1888w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/097fa/evgeniy-konev-3OrRheb618Y-unsplash.jpg 1920w","srcWebp":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/99fbb/evgeniy-konev-3OrRheb618Y-unsplash.webp","srcSetWebp":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/77392/evgeniy-konev-3OrRheb618Y-unsplash.webp 236w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/1f177/evgeniy-konev-3OrRheb618Y-unsplash.webp 472w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/99fbb/evgeniy-konev-3OrRheb618Y-unsplash.webp 944w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/4a492/evgeniy-konev-3OrRheb618Y-unsplash.webp 1416w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/b0b8f/evgeniy-konev-3OrRheb618Y-unsplash.webp 1888w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/30cf3/evgeniy-konev-3OrRheb618Y-unsplash.webp 1920w","sizes":"(max-width: 944px) 100vw, 944px"},"regular":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAECAwT/xAAWAQEBAQAAAAAAAAAAAAAAAAABAgP/2gAMAwEAAhADEAAAAcER5VUMT//EABkQAQEBAQEBAAAAAAAAAAAAAAECABEDEv/aAAgBAQABBQKfFZ+OLOm0yvN//8QAFREBAQAAAAAAAAAAAAAAAAAAECH/2gAIAQMBAT8Bh//EABYRAQEBAAAAAAAAAAAAAAAAAAARIf/aAAgBAgEBPwHVf//EABkQAAMAAwAAAAAAAAAAAAAAAAEQEQAiMv/aAAgBAQAGPwLnNgXav//EABsQAAMAAgMAAAAAAAAAAAAAAAABIRFBUWGx/9oACAEBAAE/Ic+TUvSD4E5hNXpQM32V7P/aAAwDAQACAAMAAAAQi8//xAAWEQEBAQAAAAAAAAAAAAAAAAAAEUH/2gAIAQMBAT8QxEf/xAAXEQADAQAAAAAAAAAAAAAAAAAAARFR/9oACAECAQE/EG6K0//EABoQAQADAAMAAAAAAAAAAAAAAAEAESExUWH/2gAIAQEAAT8QPKoW3KzM9lQQdOJY7D0gfaY2slkgO8rlvayf/9k=","aspectRatio":1.4954128440366972,"src":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/1dc0b/evgeniy-konev-3OrRheb618Y-unsplash.jpg","srcSet":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/3a5ce/evgeniy-konev-3OrRheb618Y-unsplash.jpg 163w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/05730/evgeniy-konev-3OrRheb618Y-unsplash.jpg 327w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/1dc0b/evgeniy-konev-3OrRheb618Y-unsplash.jpg 653w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/f72c7/evgeniy-konev-3OrRheb618Y-unsplash.jpg 980w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/6e4a3/evgeniy-konev-3OrRheb618Y-unsplash.jpg 1306w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/097fa/evgeniy-konev-3OrRheb618Y-unsplash.jpg 1920w","srcWebp":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/0acdf/evgeniy-konev-3OrRheb618Y-unsplash.webp","srcSetWebp":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/ac59e/evgeniy-konev-3OrRheb618Y-unsplash.webp 163w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/7660b/evgeniy-konev-3OrRheb618Y-unsplash.webp 327w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/0acdf/evgeniy-konev-3OrRheb618Y-unsplash.webp 653w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/75470/evgeniy-konev-3OrRheb618Y-unsplash.webp 980w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/68d47/evgeniy-konev-3OrRheb618Y-unsplash.webp 1306w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/30cf3/evgeniy-konev-3OrRheb618Y-unsplash.webp 1920w","sizes":"(max-width: 653px) 100vw, 653px"},"narrow":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAECAwT/xAAWAQEBAQAAAAAAAAAAAAAAAAABAgP/2gAMAwEAAhADEAAAAcER5VUMT//EABkQAQEBAQEBAAAAAAAAAAAAAAECABEDEv/aAAgBAQABBQKfFZ+OLOm0yvN//8QAFREBAQAAAAAAAAAAAAAAAAAAECH/2gAIAQMBAT8Bh//EABYRAQEBAAAAAAAAAAAAAAAAAAARIf/aAAgBAgEBPwHVf//EABkQAAMAAwAAAAAAAAAAAAAAAAEQEQAiMv/aAAgBAQAGPwLnNgXav//EABsQAAMAAgMAAAAAAAAAAAAAAAABIRFBUWGx/9oACAEBAAE/Ic+TUvSD4E5hNXpQM32V7P/aAAwDAQACAAMAAAAQi8//xAAWEQEBAQAAAAAAAAAAAAAAAAAAEUH/2gAIAQMBAT8QxEf/xAAXEQADAQAAAAAAAAAAAAAAAAAAARFR/9oACAECAQE/EG6K0//EABoQAQADAAMAAAAAAAAAAAAAAAEAESExUWH/2gAIAQEAAT8QPKoW3KzM9lQQdOJY7D0gfaY2slkgO8rlvayf/9k=","aspectRatio":1.5,"src":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/eaa58/evgeniy-konev-3OrRheb618Y-unsplash.jpg","srcSet":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/5a3ee/evgeniy-konev-3OrRheb618Y-unsplash.jpg 114w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/41f8f/evgeniy-konev-3OrRheb618Y-unsplash.jpg 229w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/eaa58/evgeniy-konev-3OrRheb618Y-unsplash.jpg 457w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/c309b/evgeniy-konev-3OrRheb618Y-unsplash.jpg 686w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/e3008/evgeniy-konev-3OrRheb618Y-unsplash.jpg 914w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/097fa/evgeniy-konev-3OrRheb618Y-unsplash.jpg 1920w","srcWebp":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/15384/evgeniy-konev-3OrRheb618Y-unsplash.webp","srcSetWebp":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/31fce/evgeniy-konev-3OrRheb618Y-unsplash.webp 114w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/e3e25/evgeniy-konev-3OrRheb618Y-unsplash.webp 229w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/15384/evgeniy-konev-3OrRheb618Y-unsplash.webp 457w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/0258d/evgeniy-konev-3OrRheb618Y-unsplash.webp 686w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/64ea2/evgeniy-konev-3OrRheb618Y-unsplash.webp 914w,\n//blog/static/f2de6960ec4583e1469aec9e819f2b68/30cf3/evgeniy-konev-3OrRheb618Y-unsplash.webp 1920w","sizes":"(max-width: 457px) 100vw, 457px"},"seo":{"src":"//blog/static/f2de6960ec4583e1469aec9e819f2b68/0ff54/evgeniy-konev-3OrRheb618Y-unsplash.jpg"}}},{"id":"b86af459-161d-57ec-9fd4-7f55873916ab","slug":"/boom-bikes-demand-analysis","secret":false,"title":"Boom Bikes Demand Analysis","author":"Jayanth Boddu","date":"July 26th, 2020","dateForSEO":"2020-07-26T00:00:00.000Z","timeToRead":5,"excerpt":"Boom Bikes Demand Analysis using Linear Regression","canonical_url":null,"subscription":true,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Boom Bikes Demand Analysis\",\n  \"author\": \"Jayanth Boddu\",\n  \"date\": \"2020-07-26T00:00:00.000Z\",\n  \"hero\": \"./output_93_0.png\",\n  \"excerpt\": \"Boom Bikes Demand Analysis using Linear Regression\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h2\", {\n    \"id\": \"problem-statement\"\n  }, \"Problem Statement\"), mdx(\"p\", null, \"A bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \\u201Cdock\\u201D which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\"), mdx(\"p\", null, \"A US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state.\"), mdx(\"p\", null, \"In such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people\\u2019s needs once the situation gets better all around and stand out from other service providers and make huge profits.\"), mdx(\"p\", null, \"They have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Which variables are significant in predicting the demand for shared bikes.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How well those variables describe the bike demands\", mdx(\"br\", {\n    parentName: \"li\"\n  }), \"Based on various meteorological surveys and people\\u2019s styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors.\")), mdx(\"h2\", {\n    \"id\": \"business-goals\"\n  }, \"Business Goals\"), mdx(\"p\", null, \"The company needs to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer\\u2019s expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market.\"), mdx(\"h2\", {\n    \"id\": \"analysis-approach--conclusions\"\n  }, \"Analysis Approach & Conclusions\"), mdx(\"p\", null, \"This problem can be solved using Multiple Linear Regression Analysis. The company requires a two fold solution.\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"A model to predict demand with accuracy.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Insight into the significant relationships that exist between demand and available predictors.\")), mdx(\"p\", null, \"Analysis is carried out using a Mixed Feature Selection Approach. 15 features are selected algorithmically using Recursive Feature Elimination. Further selection is done manually by looking at multicollinearity and statistical significance of features and overall fit of the model.\\nThe 10 most significant features to understand demand have been reported.\"), mdx(\"p\", null, \"The data set is randomly divided into training and test data.\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Final Model\"), \" built on training data set explains 84% of the variability and achieves 81% on test data.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"The final relationship between demand and predictors is as follows.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cnt\"), \" = 2392.0791 + 1946.7864 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"yr\"), \" + 444.4907 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Saturday\"), \" + 466.0136 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"winter\"), \" - 890.3115 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"july\"), \" -1063.6669 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"spring\"), \" + 296.8008 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"workingday\"), \" - 1749.8275 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"hum\"), \" + 4471.6602 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"temp\"), \" - 1110.3191 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"windspeed\"), \" - 1273.7519 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"light snow/rain\"))), mdx(\"p\", null, \"where \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"temp\"), \" , \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"windspeed\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"hum\"), \" are normalized.\"), mdx(\"p\", null, \"Note :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Data has been cleaned to drop outliers that might affect the model adversely\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The model has been verified for Multicollinearity effects.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Residual Analysis has been carried out and the model satisfies the assumptions of Linear Regression (Residuals follow a normal distribution, Errors exhibit homoscedasticity)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Q-Q plot between residual distribution and normal distribution shows that residuals approximately follow a normal distribution. Some points significant deviation which deems further analysis\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Further Lag plot shows there is no auto-correlation in data.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Model is stable at 81%(+/-14%) coefficient of determination at 95% CI, ascertained through cross validation.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Features in the order of influence has been reported by standardizing all predictor values.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Outliers dropped during Data Understanding phase deems further analysis from business perspective.\")), mdx(\"h2\", {\n    \"id\": \"reading-and-understanding-data\"\n  }, \"Reading and Understanding Data\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data = pd.read_csv('./day.csv')\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data.head()\\n\")), mdx(\"h3\", {\n    \"id\": \"data-quality-checks\"\n  }, \"Data Quality Checks\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data.info()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"<class 'pandas.core.frame.DataFrame'>\\nRangeIndex: 730 entries, 0 to 729\\nData columns (total 16 columns):\\n #   Column      Non-Null Count  Dtype\\n---  ------      --------------  -----\\n 0   instant     730 non-null    int64\\n 1   dteday      730 non-null    object\\n 2   season      730 non-null    int64\\n 3   yr          730 non-null    int64\\n 4   mnth        730 non-null    int64\\n 5   holiday     730 non-null    int64\\n 6   weekday     730 non-null    int64\\n 7   workingday  730 non-null    int64\\n 8   weathersit  730 non-null    int64\\n 9   temp        730 non-null    float64\\n 10  atemp       730 non-null    float64\\n 11  hum         730 non-null    float64\\n 12  windspeed   730 non-null    float64\\n 13  casual      730 non-null    int64\\n 14  registered  730 non-null    int64\\n 15  cnt         730 non-null    int64\\ndtypes: float64(4), int64(11), object(1)\\nmemory usage: 91.4+ KB\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"No missing values\")), mdx(\"h3\", {\n    \"id\": \"visualizing-continuous-variables\"\n  }, \"Visualizing Continuous Variables\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# dropping `instant`,`dteday`,`casual`,`registered`\\n\\ndata = data.drop(columns=['instant','dteday','casual','registered'])\\n\")), mdx(\"p\", null, \"These variables were dropped since \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"instant\"), \" is the just the serial number of the record,\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"dteday\"), \" is redundant coz the required data for analysis is contained in mnth,yr\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"casual\"), \" + \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"registered\"), \" = \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"cnt\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# summary statistics of numerical variables\\ndata[['temp','atemp','hum','windspeed']].describe()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Scatter Plots of Continuous variables vs 'cnt'\\nsns.set_style(\\\"whitegrid\\\")\\nsns.pairplot(data=data,x_vars=['temp','atemp','hum','windspeed'],y_vars='cnt',kind='scatter',height=5,aspect=1);\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1455px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"25.42955326460481%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAABFUlEQVQY0yWQy07DQAxF+/8/wZIFEhskFgiVBQiBREt5qIiolDQFJaRp0rwm88zFdhczI9v3nrE98d5jHAOdEeu8Rd4MEtMF6zxWfw16bSVmTdEOiItONNo6fO9aVL3BGI6MiXMOgQIWXS9T3Ea5xAz7TGtcLH7kJaLknzclzp4SHAjSDhbnsy1m8R7KMIeAwTvUyuDqPcXNR4aXpKKCR3pQuHz9xXSZYcMdSQcBczKf3K0RZTUa8p0+xpiSr+q0fEhAj7dthfvVDh2PhuOoD1+FdOOozuN6H8QQZQ3mlI+LVnSLpKQOS+wJ6DwDSdQNBkobWGvBO7W0ho7GUYOGMQa8Fs47AmhjZXc9eVhnyNOTjg9r/gGai3zYJLzxJAAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/55fa9c8f9d76ef823f79b85f1626f213/4731d/output_15_0.webp 1455w\"],\n    \"sizes\": \"(max-width: 1455px) 100vw, 1455px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/55fa9c8f9d76ef823f79b85f1626f213/8df0c/output_15_0.png 1455w\"],\n    \"sizes\": \"(max-width: 1455px) 100vw, 1455px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/55fa9c8f9d76ef823f79b85f1626f213/8df0c/output_15_0.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The number of rentals per day seem to be increasing with temperature and adjusted temperature\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"adjusted temperature and temperature have similar trends\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"temp vs cnt has two outliers between 15 and 30\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"atemp vs cnt has two outliers between 20 and 35\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"hum vs cnt has two outliers below 20\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"windspeed vs cnt has one outlier above 30\")), mdx(\"h3\", {\n    \"id\": \"outliers-in-continuous-variables-vs-cnt\"\n  }, \"Outliers in Continuous Variables vs cnt\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"## Dropping outliers in continuous variables\\n# outliers in temp\\ndata = data.drop(index = data[(data['temp'] > 15) & (data['temp'] < 20) & (data['cnt'] < 100)].index)\\ndata = data.drop(index = data[(data['temp'] > 25) & (data['temp'] < 30) & (data['cnt'] < 2000)].index)\\n\\n\\n# outliers in atemp\\ndata = data.drop(index = data[(data['atemp'] > 20) & (data['atemp'] < 25) & (data['cnt'] < 100)].index)\\ndata = data.drop(index = data[(data['atemp'] > 30) & (data['atemp'] < 35) & (data['cnt'] < 2000)].index)\\n\\n\\n#outliers in hum\\ndata = data.drop(index = data[(data['hum'] < 20)].index)\\n\\n#outliers in windspeed\\ndata = data.drop(index = data[(data['windspeed'] > 30)].index)\\n\\n\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Looking at correlation with continuous variables\\ncorrelation = data[['temp','atemp','hum','windspeed','cnt']].corr()['cnt'].apply(lambda x : round(x,4))\\ncorrelation = pd.DataFrame(correlation).sort_values(by='cnt',ascending=False)\\ncorrelation.drop(index=['cnt'],inplace=True)\\n# dropping registered,casual, instant\\ncorrelation.style.background_gradient(cmap='GnBu')\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"There\\u2019s no signifcant correlation between \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"atemp\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"hum\"), \" , \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"windspeed\"), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Hence these are not dropped for now.\")), mdx(\"h3\", {\n    \"id\": \"visualizing-categorical-variables\"\n  }, \"Visualizing Categorical Variables\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Converting variables into categorical type\\ndata[['season','weathersit','mnth']] = data[['season','weathersit','mnth']].astype('category')\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Unique values in each categorical variable / [To check for disguised missing values]\\ncat_vars = ['season','yr','mnth','holiday','weekday','workingday','weathersit']\\nfor i in cat_vars :\\n    print('Unique values in ',i, data[i].unique())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Unique values in  season [1, 2, 3, 4]\\nCategories (4, int64): [1, 2, 3, 4]\\nUnique values in  yr [0 1]\\nUnique values in  mnth [1, 2, 3, 4, 5, ..., 8, 9, 10, 11, 12]\\nLength: 12\\nCategories (12, int64): [1, 2, 3, 4, ..., 9, 10, 11, 12]\\nUnique values in  holiday [0 1]\\nUnique values in  weekday [6 0 1 2 3 4 5]\\nUnique values in  workingday [0 1]\\nUnique values in  weathersit [2, 1, 3]\\nCategories (3, int64): [2, 1, 3]\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"No disguised missing values exist\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Replacing numbers with labels\\nseason_labels = {\\n    1 : 'spring',\\n    2 : 'summer',\\n    3 : 'fall',\\n    4 : 'winter'\\n}\\n\\nmnth_labels = {\\n    1 : 'january',\\n    2 : 'february',\\n    3 : 'march',\\n    4 : 'april',\\n    5 : 'may',\\n    6 : 'june',\\n    7 : 'july',\\n    8 : 'august',\\n    9 : 'september',\\n    10 : 'october',\\n    11 : 'november',\\n    12 : 'december'\\n}\\n\\nweekday_labels = { # considering the first row of dteday to be 01-01-2011\\n    0 : 'Sunday',\\n    1 : 'Monday',\\n    2 : 'Tuesday',\\n    3 : 'Wednesday',\\n    4 : 'Thursday',\\n    5 : 'Friday',\\n    6 : 'Saturday'\\n}\\n\\nweathersit_labels = {\\n    1 : 'clear',\\n    2 : 'cloudy',\\n    3 : 'light snow/rain'\\n}\\n\\n# replacing numerals with labels\\ndata['season'] = data['season'].replace(season_labels)\\ndata['mnth'] = data['mnth'].replace(mnth_labels)\\ndata['weekday'] = data['weekday'].replace(weekday_labels)\\ndata['weathersit'] = data['weathersit'].replace(weathersit_labels)\\n\\ndata.head()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"cat_vars = ['season','yr','mnth','holiday','weekday',  'workingday','weathersit']\\ndata1 = data[cat_vars]\\ndata1.loc[:,'cnt'] = data['cnt'].values\\ndata1[['yr','holiday','workingday']] = data1[['yr','holiday','workingday']].astype('category')\\nplot_dim = [3,3]\\nfig,axs = plt.subplots(*plot_dim)\\nfig.set_figheight(15)\\nfig.set_figwidth(20)\\nfor i in range(plot_dim[0]) :\\n    for j in range(plot_dim[1]) :\\n        axs[i,j].set(title = i*plot_dim[1]+j)\\n        sns.boxplot(data=data1,x='cnt',y=cat_vars[i*plot_dim[1]+j],width=0.4,ax=axs[i,j])\\n        if i*plot_dim[1]+j == 6 :\\n            break\\naxs[2,1].set_axis_off()\\naxs[2,2].set_axis_off()\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1214px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"71.82866556836903%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAACdUlEQVQ4y41Ta2/TQBD0H+bPIB4fQAIhUBFCSK0CErRFTZOqJA1NmkalebWqmzhJlZcd2+fznT3s3jVVhPjQk6zc7e3Ozs5NnCzPgUyj3h2g3vdAJ6Q6Q5ZlyOkuozt3ssDNeEZpysTSNIVIEkyuuhh2ziFpz4Vc42itoShhPPMxGNwian6Hmo+hKUETADd7Xqjg2dca1ktKiTiO4S+maLeOcFQrwLsbEI6Co5QCf9wip+KDxjYq7RLtGVATnjYg6WqK8LYFlURIEgkhhIkrmmanVsFeowFNxBwegTumRHd2dY36tx2M5hPTjUeQiQBDBpdFuO+fIJxcI4wlVkGAKIow6A9wUu3ioudRo8QC5lSYEpNcRFS5pDFJJ2X1YoYxMZqFEoGw07CGRsdYkDw+0ZdmOp7IYdqaaBMKqm0XH4pNBFFsmrDwDDD0PByWiuhc3RgW+l4GSaCFkzY+lZpYEbgBZBacxKvUm+Pl/iX8SFBTK3xKo4fBHNVfX+DeXpIMOemmzEPGpONWuYM3hz0iQYCKNGRbML9o1EV4/BbZ2Weo2DfW8X2fmgmMvTvsb23jrFw1rJiJlJYERk2kpx+hxYqVYoaZiftuC6MfTzE+eIUVPQr7URDDhAoXsznqu8do/z4nVrF5LEVsJHlr+qeM4e4LRP4MUvHIbBgCNSzpEGWwYxkrWbNa+5DR7+P8a7VXsOrbmgcNzYtR53d7p9htutZ3FOO79coN543z+o4nzPRD3OFCFpjXctjH8OdrBMMO+RLmpdfFj/0cNnAiBVreBcLlBKFLIocLrKX4F3Dz/L+9w9qEIkShUSC7rKxuuf3bbSY+dv0FWSwwcKCLoQoAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/fb58fffdaad9db38daf97d9a6821e7cb/5eb99/output_31_0.webp 1214w\"],\n    \"sizes\": \"(max-width: 1214px) 100vw, 1214px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/fb58fffdaad9db38daf97d9a6821e7cb/443e8/output_31_0.png 1214w\"],\n    \"sizes\": \"(max-width: 1214px) 100vw, 1214px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/fb58fffdaad9db38daf97d9a6821e7cb/443e8/output_31_0.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"From the season vs rentals per day plot , fall has the highest average rentals followed by summer.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Looking at year by year rentals, 2019 has had a median 2000 increase in rentals compared to 2018.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"From the month wise plot, September has the highest rentals, followed by the two months surrounding it. It seems like the trend is explained by seasonal rentals too\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Holidays show lower rental count compared to working days, with greater variability in demand on holidays.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"There is no significant difference between rentals vs weekdays, except that Thursdays and sundays have a higher variation in rentals than others.\")), mdx(\"h3\", {\n    \"id\": \"outliers-in-categorical-variables-vs-cnt\"\n  }, \"Outliers in Categorical Variables vs cnt\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Dropping outliers in Categorical Variables\\ndata = data.drop(index = data[(data['season'] == 'spring') & (data['cnt'] > 7000)].index)\\n\\n\")), mdx(\"h3\", {\n    \"id\": \"correlation\"\n  }, \"Correlation\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# correlation among variables\\nplt.figure(figsize=[10,10])\\nsns.heatmap(data.corr(),cmap='GnBu',center=0,annot=True)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"<matplotlib.axes._subplots.AxesSubplot at 0x7fde4bfdd610>\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"558px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"103.40501792114696%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsSAAALEgHS3X78AAAFhklEQVQ4yzWUe0yb5xXGP23qNGlrN03btK7dVG1SU3XTVu2fqqrUNl2T/jVNmiKSbEmkpFpJxbIQoIABAyN0DU1IyHUEsoT0stBLCgR8x/fvM9gONhcbCBeDjU3AXBIbmmSNqt+OXe2PR6+s7/XzPs85zzlKaiXLwfduUPheD1dCo3QnZ/ksNkVXfJrrc9N0zs4KZjAvTGBfjNIbn6QnMUNH5BYlXaNU3Bhj8e49jn+kEo0tooRuJVGer85jV2cXxV4zR3xODjuMFKsOCp1OCh0OGsMWmm52o7/ZT6nc2d1j5YdVBp6oNTKWusvzRR1oEeEam7nNY6818t3XjvLXHhN1wxrVQRV9wCOnRqlvgLIBH82jTs5Hrfwz7KY+pFJocfNUvZkt71iZuJ1he203/qkllFR2gwPXDez7pI/njrTy+M5m9l/+iGvzVs5HrKLIS42gIeQWlW5qhzxUDWlU+j383W6nxOVkIZPllQYTztE4SvzuuvzJTeWAnSd3NaM8U8HuU21Sq246Jo3oB23U+KzUBuWOx0K1kJc4zOiDLppCVk4M21i6t8krTU4GZ1dQJhdT1MiL5YNunn3zDN9+uZ4/n77EtalezoX78or+j7qhr9XqciWRszHs4t1hN4ubG7x+2kswvo6SfnCfmqCXaqlZS6CXyyNd7DrVzve2NfDbQxc4rGoUaz55UBV4qZK7OUdVQpr7ViLfFjY2+WPrANrUbZTYappqn4NK1cbVKRO9iR4KTrTlrf9sTwuHPV7ptsrbQljisuXVVapWdAGVQy4PxW4Pyc17FFwJEJxfRYkk4tSF/fkXW6MWPl2wsqf1fb7/hyZ+daiVfV397OvulziplAUG8wobRzzopCl7jSoHLBrxzCZ7r4UYuZ1FSWQylPl8HNFydfFQH7RTPuAVOz52/sfIdyROj25vZEdnP284g+j9bq6Ik3JpzOO6Pp7SGxiX2BT2jBGYT6NMp9Mc8WocEuk1QYFmzter2Oul4EMD33xBzyMv1lLwqYOD2lC+MZfGeymxGvlBqYGfVhiILGY4bJ1gePGu5HAjQ11Ik+6p+csNIyoVfqnZUJADvXa2FLWx5W9tbD15na1nhMjUR2fCyjuDZl48Z+TVVhOzq1nKXNNMrH2BsnI/y5lRCy2ChiGXNMien5QyGbvSAY231Ju86fLzxO6TKL+p5C+n2/ls7gaXJwycjto4N24jfX8DnTbL2LIoTKwtc3bMSsuI+WtCrT/foFKvQ+Kisr/fzz6zjx/tEMJnKtl7/t+YV4x8OGuiKWylWYK9LIQNgSmi6fWcwk2aRj28O+LOW64N+0Sh5C3kyxPXSoD18ntP61V2HL/IrpZ2dp5s5633P6BtykbbpI2cy+PhCeYkj0pKUq4bcFMuFnUS7jK3NT9elaL0aMjJv8aMAgMfz5swpY3syGX06Up+/UYzH8g0dURusPYgy9lIhNk7d1CiC3GOyobJzWYuY29rjjxh1aAzP1rtkxaBmauTfVyP9/KnYxdRntXx3MFTklkz12Im1v+b5dLkCNNrEptIcpltV5xsvdRPuebmWETIAl7Kg36KHF62txl5vd3IsaCFyzE7ddbPKRK7+y928FLFOX5fdYHY0iofzw2T+iIj+zC5zi/+YZHdZqHYbpMlapIpUCnqd1DwuZMflxv5iWStzGnhRNhM2y0b3SnZQoZOlN/V8I0X6hiLLdGXGiKZXROFqXWebrTyy0YzpW4HJ6NiXea0dDDAXoPKk9VGfq43ovPaODth50JExlNyWN37Cd96qZ7HtjUyPr+MfSnAwh1ZsPcffoV/boXB2ApTqysMz0/nT3XyFqFECtd4Emc0QezOGlPpJIlMmpFYhIlkHOfNGdyhGe49eEjmyyxffvWQ/wEqc+w6W3LlxwAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/280f33370459e073e9d90e18e34b9d86/c9b7d/output_36_1.webp 558w\"],\n    \"sizes\": \"(max-width: 558px) 100vw, 558px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/280f33370459e073e9d90e18e34b9d86/df9f3/output_36_1.png 558w\"],\n    \"sizes\": \"(max-width: 558px) 100vw, 558px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/280f33370459e073e9d90e18e34b9d86/df9f3/output_36_1.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Highest correlation with \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cnt\"), \" is seen in \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"temp\"), \" followed by \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"yr\"))), mdx(\"h2\", {\n    \"id\": \"data-preparation\"\n  }, \"Data Preparation\"), mdx(\"h3\", {\n    \"id\": \"creating-indictor-variables\"\n  }, \"Creating Indictor Variables\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# creating indicator variable columns\\nseason_indicators = pd.get_dummies(data['season'],drop_first=True)\\nmnth_indicators = pd.get_dummies(data['mnth'],drop_first=True)\\nweekday_indicators = pd.get_dummies(data['weekday'],drop_first=True)\\nweathersit_indicators = pd.get_dummies(data['weathersit'],drop_first=True)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# adding indicator variable columns to the dataset . Dropping original columns\\ndata = pd.concat([data,season_indicators,mnth_indicators,weekday_indicators,weathersit_indicators],axis=1)\\ndata = data.drop(columns=['season','mnth','weekday','weathersit'])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data.head()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data.columns\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Index(['yr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'cnt',\\n       'spring', 'summer', 'winter', 'august', 'december', 'february',\\n       'january', 'july', 'june', 'march', 'may', 'november', 'october',\\n       'september', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\\n       'Wednesday', 'cloudy', 'light snow/rain'],\\n      dtype='object')\\n\")), mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"Variable\"), mdx(\"th\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"Reference Label\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"season\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"fall\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"mnth\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"april\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"weekday\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"Friday\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"weathersit\"), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": null\n  }), \"clear\")))), mdx(\"h3\", {\n    \"id\": \"splitting-the-data-set-into-test--train-subsets\"\n  }, \"Splitting the data set into Test & Train subsets\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.model_selection import train_test_split\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"dtrain,dtest = train_test_split(data,train_size=0.7,test_size=0.3,random_state=120)\\n\")), mdx(\"h3\", {\n    \"id\": \"scaling-numerical-features\"\n  }, \"Scaling Numerical Features\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# normalization of continuous variables\\nfrom sklearn.preprocessing import MinMaxScaler\\nnumerical_scaler = MinMaxScaler()\\nnum_vars = ['temp','hum','windspeed']\\n\\nnumerical_scaler.fit(dtrain[num_vars])\\ndtrain[num_vars] = numerical_scaler.transform(dtrain[num_vars])\\n\")), mdx(\"h4\", {\n    \"id\": \"x_train--y_train\"\n  }, \"X_train , y_train\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"y_train = dtrain.pop('cnt')\\nX_train = dtrain\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"y_train.head()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"231    5191\\n717    5267\\n107    3429\\n595    4549\\n485    5740\\nName: cnt, dtype: int64\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_train.head()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_train.columns\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Index(['yr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'spring',\\n       'summer', 'winter', 'august', 'december', 'february', 'january', 'july',\\n       'june', 'march', 'may', 'november', 'october', 'september', 'Monday',\\n       'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', 'cloudy',\\n       'light snow/rain'],\\n      dtype='object')\\n\")), mdx(\"h2\", {\n    \"id\": \"modelling\"\n  }, \"Modelling\"), mdx(\"p\", null, \"Approach\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A mixed approach is followed.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"15 Best columns are chosen using RFE\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"And then p-value method is followed for further elimination.\")), mdx(\"h4\", {\n    \"id\": \"recursive-feature-elimination\"\n  }, \"Recursive Feature Elimination\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Selecting 15 Features using RFE\\n\\nfrom sklearn.feature_selection import RFE\\nfrom sklearn.linear_model import LinearRegression\\n\\nlr_estimator = LinearRegression()\\nrfe = RFE(lr_estimator,n_features_to_select=15, step=1)\\nselector = rfe.fit(X_train,y_train)\\n\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# RFE Feature Ranking\\nrfe_ranking = pd.DataFrame({'rank' : selector.ranking_, 'support': selector.support_, 'features' : X_train.columns}).sort_values(by='rank',ascending=True)\\nrfe_ranking\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Selected Features\\nselected_features = rfe_ranking.loc[rfe_ranking['rank'] == 1,'features'].values\\nselected_features\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"array(['yr', 'Sunday', 'Saturday', 'november', 'january', 'december',\\n       'winter', 'july', 'spring', 'holiday', 'workingday', 'hum', 'temp',\\n       'windspeed', 'light snow/rain'], dtype=object)\\n\")), mdx(\"h3\", {\n    \"id\": \"manual-elimination\"\n  }, \"Manual Elimination\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Following a stepwise elimination\\nimport statsmodels.api as sm\\ndef ols_fit(y,X) :\\n    X_train_sm = sm.add_constant(X)\\n    model = sm.OLS(y,X_train_sm).fit()\\n    print(model.summary())\\n    return model\\ndef vif(X) :\\n    df = sm.add_constant(X)\\n    vif = [variance_inflation_factor(df.values,i) for i in range(df.shape[1])]\\n    vif_frame = pd.DataFrame({'vif' : vif[0:]},index = df.columns).reset_index()\\n    print(vif_frame.sort_values(by='vif',ascending=False))\\n\")), mdx(\"h4\", {\n    \"id\": \"model-1\"\n  }, \"Model 1\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Using features selected by RFE : \\u2018yr\\u2019, \\u2018Sunday\\u2019, \\u2018Saturday\\u2019, \\u2018november\\u2019, \\u2018january\\u2019, \\u2018december\\u2019,\\n\\u2018winter\\u2019, \\u2018july\\u2019, \\u2018spring\\u2019, \\u2018holiday\\u2019, \\u2018workingday\\u2019, \\u2018hum\\u2019, \\u2018temp\\u2019,\\n\\u2018windspeed\\u2019, \\u2018light snow/rain\\u2019\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"features_1 = selected_features\\nols_fit(y_train,X_train[features_1])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.844\\nModel:                            OLS   Adj. R-squared:                  0.840\\nMethod:                 Least Squares   F-statistic:                     189.8\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          9.27e-188\\nTime:                        20:41:57   Log-Likelihood:                -4072.4\\nNo. Observations:                 506   AIC:                             8175.\\nDf Residuals:                     491   BIC:                             8238.\\nDf Model:                          14\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2278.2820    192.838     11.815      0.000    1899.393    2657.171\\nyr               1959.7590     69.543     28.180      0.000    1823.120    2096.398\\nSunday            497.0421     97.123      5.118      0.000     306.214     687.871\\nSaturday          874.2613     95.093      9.194      0.000     687.422    1061.101\\nnovember         -617.4927    158.994     -3.884      0.000    -929.885    -305.100\\njanuary          -391.9320    149.160     -2.628      0.009    -685.002     -98.862\\ndecember         -475.8630    142.634     -3.336      0.001    -756.112    -195.614\\nwinter            687.2832    121.588      5.653      0.000     448.387     926.180\\njuly             -804.3128    141.415     -5.688      0.000   -1082.166    -526.459\\nspring          -1010.6061    134.437     -7.517      0.000   -1274.749    -746.464\\nholiday           165.4153    160.101      1.033      0.302    -149.152     479.982\\nworkingday        741.5633     73.655     10.068      0.000     596.846     886.280\\nhum             -1782.6033    198.667     -8.973      0.000   -2172.947   -1392.260\\ntemp             4036.2727    275.497     14.651      0.000    3494.974    4577.571\\nwindspeed       -1167.6983    188.628     -6.190      0.000   -1538.315    -797.081\\nlight snow/rain -1276.7947    234.425     -5.446      0.000   -1737.395    -816.194\\n==============================================================================\\nOmnibus:                       74.940   Durbin-Watson:                   1.920\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              164.191\\nSkew:                          -0.800   Prob(JB):                     2.22e-36\\nKurtosis:                       5.286   Cond. No.                     6.67e+15\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n[2] The smallest eigenvalue is 3.03e-29. This might indicate that there are\\nstrong multicollinearity problems or that the design matrix is singular.\\n              index       vif\\n2            Sunday       inf\\n3          Saturday       inf\\n10          holiday       inf\\n11       workingday       inf\\n13             temp  3.530342\\n9            spring  2.972066\\n7            winter  2.265754\\n5           january  1.667765\\n4          november  1.649107\\n6          december  1.384399\\n8              july  1.332786\\n12              hum  1.302061\\n15  light snow/rain  1.179013\\n14        windspeed  1.161178\\n1                yr  1.035227\\n0             const  0.000000\\n\")), mdx(\"h4\", {\n    \"id\": \"model-2-\"\n  }, \"Model 2 :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"holiday\"), \" because of high p-value\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"del_feature = 'holiday'\\nselected_features = selected_features[selected_features!=del_feature]\\nols_fit(y_train,X_train[selected_features])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.844\\nModel:                            OLS   Adj. R-squared:                  0.840\\nMethod:                 Least Squares   F-statistic:                     189.8\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          9.27e-188\\nTime:                        20:41:57   Log-Likelihood:                -4072.4\\nNo. Observations:                 506   AIC:                             8175.\\nDf Residuals:                     491   BIC:                             8238.\\nDf Model:                          14\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2443.6973    302.113      8.089      0.000    1850.103    3037.291\\nyr               1959.7590     69.543     28.180      0.000    1823.120    2096.398\\nSunday            331.6268    208.945      1.587      0.113     -78.910     742.164\\nSaturday          708.8460    208.062      3.407      0.001     300.043    1117.649\\nnovember         -617.4927    158.994     -3.884      0.000    -929.885    -305.100\\njanuary          -391.9320    149.160     -2.628      0.009    -685.002     -98.862\\ndecember         -475.8630    142.634     -3.336      0.001    -756.112    -195.614\\nwinter            687.2832    121.588      5.653      0.000     448.387     926.180\\njuly             -804.3128    141.415     -5.688      0.000   -1082.166    -526.459\\nspring          -1010.6061    134.437     -7.517      0.000   -1274.749    -746.464\\nworkingday        576.1480    191.468      3.009      0.003     199.950     952.346\\nhum             -1782.6033    198.667     -8.973      0.000   -2172.947   -1392.260\\ntemp             4036.2727    275.497     14.651      0.000    3494.974    4577.571\\nwindspeed       -1167.6983    188.628     -6.190      0.000   -1538.315    -797.081\\nlight snow/rain -1276.7947    234.425     -5.446      0.000   -1737.395    -816.194\\n==============================================================================\\nOmnibus:                       74.940   Durbin-Watson:                   1.920\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              164.191\\nSkew:                          -0.800   Prob(JB):                     2.22e-36\\nKurtosis:                       5.286   Cond. No.                         20.6\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n              index        vif\\n0             const  78.227579\\n10       workingday   6.747604\\n3          Saturday   4.580552\\n2            Sunday   4.352788\\n12             temp   3.530342\\n9            spring   2.972066\\n7            winter   2.265754\\n5           january   1.667765\\n4          november   1.649107\\n6          december   1.384399\\n8              july   1.332786\\n11              hum   1.302061\\n14  light snow/rain   1.179013\\n13        windspeed   1.161178\\n1                yr   1.035227\\n\")), mdx(\"h4\", {\n    \"id\": \"model-3-\"\n  }, \"Model 3 :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Sunday\"), \" because of high p-value\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"del_feature = 'Sunday'\\nselected_features = selected_features[selected_features!=del_feature]\\nols_fit(y_train,X_train[selected_features])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.843\\nModel:                            OLS   Adj. R-squared:                  0.839\\nMethod:                 Least Squares   F-statistic:                     203.6\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          2.22e-188\\nTime:                        20:41:57   Log-Likelihood:                -4073.7\\nNo. Observations:                 506   AIC:                             8175.\\nDf Residuals:                     492   BIC:                             8234.\\nDf Model:                          13\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2717.6842    248.317     10.944      0.000    2229.791    3205.578\\nyr               1958.8083     69.648     28.124      0.000    1821.964    2095.652\\nSaturday          442.9774    123.597      3.584      0.000     200.134     685.820\\nnovember         -627.3327    159.118     -3.943      0.000    -939.968    -314.698\\njanuary          -391.6152    149.390     -2.621      0.009    -685.136     -98.095\\ndecember         -485.7607    142.718     -3.404      0.001    -766.172    -205.350\\nwinter            687.9955    121.774      5.650      0.000     448.733     927.258\\njuly             -808.0743    141.613     -5.706      0.000   -1086.316    -529.833\\nspring          -1018.8530    134.544     -7.573      0.000   -1283.204    -754.502\\nworkingday        310.9383     93.623      3.321      0.001     126.989     494.888\\nhum             -1777.8858    198.952     -8.936      0.000   -2168.785   -1386.986\\ntemp             4023.0506    275.796     14.587      0.000    3481.168    4564.933\\nwindspeed       -1166.7398    188.918     -6.176      0.000   -1537.925    -795.555\\nlight snow/rain -1274.2371    234.781     -5.427      0.000   -1735.535    -812.939\\n==============================================================================\\nOmnibus:                       76.586   Durbin-Watson:                   1.907\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              168.964\\nSkew:                          -0.814   Prob(JB):                     2.04e-37\\nKurtosis:                       5.316   Cond. No.                         17.6\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n              index        vif\\n0             const  52.686107\\n11             temp   3.527114\\n8            spring   2.967626\\n6            winter   2.265723\\n4           january   1.667762\\n3          november   1.646599\\n2          Saturday   1.611416\\n9        workingday   1.608346\\n5          december   1.381753\\n7              july   1.332412\\n10              hum   1.301769\\n13  light snow/rain   1.178957\\n12        windspeed   1.161167\\n1                yr   1.035151\\n\")), mdx(\"h4\", {\n    \"id\": \"model-4\"\n  }, \"Model 4\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"january\"), \" because this information might also be contained in \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"winter\"), \".\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"del_feature = 'january'\\nselected_features = selected_features[selected_features!=del_feature]\\nols_fit(y_train,X_train[selected_features])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.841\\nModel:                            OLS   Adj. R-squared:                  0.837\\nMethod:                 Least Squares   F-statistic:                     217.4\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          4.41e-188\\nTime:                        20:41:58   Log-Likelihood:                -4077.2\\nNo. Observations:                 506   AIC:                             8180.\\nDf Residuals:                     493   BIC:                             8235.\\nDf Model:                          12\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2563.5282    242.686     10.563      0.000    2086.701    3040.355\\nyr               1951.9279     70.012     27.880      0.000    1814.370    2089.486\\nSaturday          437.2585    124.312      3.517      0.000     193.013     681.504\\nnovember         -576.6481    158.877     -3.630      0.000    -888.808    -264.489\\ndecember         -380.3554    137.749     -2.761      0.006    -651.004    -109.707\\nwinter            696.8818    122.450      5.691      0.000     456.294     937.470\\njuly             -846.1814    141.702     -5.972      0.000   -1124.595    -567.768\\nspring          -1101.5863    131.566     -8.373      0.000   -1360.086    -843.087\\nworkingday        310.1011     94.178      3.293      0.001     125.061     495.141\\nhum             -1775.7238    200.131     -8.873      0.000   -2168.939   -1382.508\\ntemp             4232.4252    265.545     15.939      0.000    3710.686    4754.164\\nwindspeed       -1126.2015    189.402     -5.946      0.000   -1498.335    -754.068\\nlight snow/rain -1259.9614    236.112     -5.336      0.000   -1723.871    -796.052\\n==============================================================================\\nOmnibus:                       70.215   Durbin-Watson:                   1.923\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              144.730\\nSkew:                          -0.775   Prob(JB):                     3.74e-32\\nKurtosis:                       5.112   Cond. No.                         16.9\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n              index        vif\\n0             const  49.731331\\n10             temp   3.231303\\n7            spring   2.804334\\n5            winter   2.263968\\n3          november   1.622287\\n2          Saturday   1.610914\\n8        workingday   1.608327\\n6              july   1.318372\\n9               hum   1.301747\\n4          december   1.272074\\n12  light snow/rain   1.178323\\n11        windspeed   1.153386\\n1                yr   1.033680\\n\")), mdx(\"h4\", {\n    \"id\": \"model-5\"\n  }, \"Model 5\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"december\"), \" because this information might also be contained in \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"winter\"), \".\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"del_feature = 'december'\\nselected_features = selected_features[selected_features!=del_feature]\\nols_fit(y_train,X_train[selected_features])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.839\\nModel:                            OLS   Adj. R-squared:                  0.835\\nMethod:                 Least Squares   F-statistic:                     233.3\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          1.22e-187\\nTime:                        20:41:58   Log-Likelihood:                -4081.1\\nNo. Observations:                 506   AIC:                             8186.\\nDf Residuals:                     494   BIC:                             8237.\\nDf Model:                          11\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2484.0272    242.583     10.240      0.000    2007.406    2960.648\\nyr               1945.4495     70.440     27.619      0.000    1807.051    2083.848\\nSaturday          435.8371    125.141      3.483      0.001     189.962     681.712\\nnovember         -443.0313    152.340     -2.908      0.004    -742.345    -143.718\\nwinter            603.4461    118.468      5.094      0.000     370.683     836.209\\njuly             -874.0132    142.287     -6.143      0.000   -1153.576    -594.450\\nspring          -1106.1972    132.435     -8.353      0.000   -1366.402    -845.992\\nworkingday        296.4789     94.677      3.131      0.002     110.459     482.499\\nhum             -1801.9289    201.242     -8.954      0.000   -2197.325   -1406.533\\ntemp             4372.9630    262.363     16.668      0.000    3857.478    4888.448\\nwindspeed       -1096.9814    190.369     -5.762      0.000   -1471.015    -722.948\\nlight snow/rain -1259.4132    237.690     -5.299      0.000   -1726.420    -792.406\\n==============================================================================\\nOmnibus:                       67.769   Durbin-Watson:                   1.914\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              129.549\\nSkew:                          -0.778   Prob(JB):                     7.39e-29\\nKurtosis:                       4.929   Cond. No.                         16.7\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n              index        vif\\n0             const  49.031354\\n9              temp   3.112593\\n6            spring   2.803882\\n4            winter   2.091074\\n2          Saturday   1.610886\\n7        workingday   1.603914\\n3          november   1.471790\\n5              july   1.311701\\n8               hum   1.298820\\n11  light snow/rain   1.178322\\n10        windspeed   1.149786\\n1                yr   1.032520\\n\")), mdx(\"h4\", {\n    \"id\": \"model-6\"\n  }, \"Model 6\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"november\"), \" because this information might also be contained in \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"winter\"), \".\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"del_feature = 'november'\\nselected_features = selected_features[selected_features!=del_feature]\\nfinal_model = ols_fit(y_train,X_train[selected_features])\\nvif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.836\\nModel:                            OLS   Adj. R-squared:                  0.833\\nMethod:                 Least Squares   F-statistic:                     252.0\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          4.89e-187\\nTime:                        20:41:58   Log-Likelihood:                -4085.3\\nNo. Observations:                 506   AIC:                             8193.\\nDf Residuals:                     495   BIC:                             8239.\\nDf Model:                          10\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2392.0791    242.318      9.872      0.000    1915.980    2868.178\\nyr               1946.7864     70.967     27.432      0.000    1807.353    2086.220\\nSaturday          444.4907    126.045      3.526      0.000     196.842     692.139\\nwinter            466.0136    109.450      4.258      0.000     250.970     681.057\\njuly             -890.3115    143.244     -6.215      0.000   -1171.752    -608.871\\nspring          -1063.6669    132.613     -8.021      0.000   -1324.220    -803.114\\nworkingday        296.8008     95.388      3.112      0.002     109.386     484.216\\nhum             -1749.8275    201.947     -8.665      0.000   -2146.607   -1353.048\\ntemp             4471.6602    262.111     17.060      0.000    3956.673    4986.648\\nwindspeed       -1110.3191    191.742     -5.791      0.000   -1487.049    -733.590\\nlight snow/rain -1273.7519    239.422     -5.320      0.000   -1744.160    -803.344\\n==============================================================================\\nOmnibus:                       69.587   Durbin-Watson:                   1.898\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              136.276\\nSkew:                          -0.788   Prob(JB):                     2.56e-30\\nKurtosis:                       4.995   Cond. No.                         16.5\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n              index        vif\\n0             const  48.198446\\n8              temp   3.060511\\n5            spring   2.769692\\n3            winter   1.758336\\n2          Saturday   1.609975\\n6        workingday   1.603912\\n4              july   1.309666\\n7               hum   1.288526\\n10  light snow/rain   1.177815\\n9         windspeed   1.149118\\n1                yr   1.032476\\n\")), mdx(\"h2\", {\n    \"id\": \"verifying-multicollinearity\"\n  }, \"Verifying MultiCollinearity\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"vif(X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"              index        vif\\n0             const  48.198446\\n8              temp   3.060511\\n5            spring   2.769692\\n3            winter   1.758336\\n2          Saturday   1.609975\\n6        workingday   1.603912\\n4              july   1.309666\\n7               hum   1.288526\\n10  light snow/rain   1.177815\\n9         windspeed   1.149118\\n1                yr   1.032476\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"VIF < 5 for selected features. No significant multicollinearity observed. Similar indicating comparison of R-squared and adjusted R-squared.\")), mdx(\"h2\", {\n    \"id\": \"final-model\"\n  }, \"Final Model\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"final_model = ols_fit(y_train,X_train[selected_features])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"                            OLS Regression Results\\n==============================================================================\\nDep. Variable:                    cnt   R-squared:                       0.836\\nModel:                            OLS   Adj. R-squared:                  0.833\\nMethod:                 Least Squares   F-statistic:                     252.0\\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):          4.89e-187\\nTime:                        20:41:58   Log-Likelihood:                -4085.3\\nNo. Observations:                 506   AIC:                             8193.\\nDf Residuals:                     495   BIC:                             8239.\\nDf Model:                          10\\nCovariance Type:            nonrobust\\n===================================================================================\\n                      coef    std err          t      P>|t|      [0.025      0.975]\\n-----------------------------------------------------------------------------------\\nconst            2392.0791    242.318      9.872      0.000    1915.980    2868.178\\nyr               1946.7864     70.967     27.432      0.000    1807.353    2086.220\\nSaturday          444.4907    126.045      3.526      0.000     196.842     692.139\\nwinter            466.0136    109.450      4.258      0.000     250.970     681.057\\njuly             -890.3115    143.244     -6.215      0.000   -1171.752    -608.871\\nspring          -1063.6669    132.613     -8.021      0.000   -1324.220    -803.114\\nworkingday        296.8008     95.388      3.112      0.002     109.386     484.216\\nhum             -1749.8275    201.947     -8.665      0.000   -2146.607   -1353.048\\ntemp             4471.6602    262.111     17.060      0.000    3956.673    4986.648\\nwindspeed       -1110.3191    191.742     -5.791      0.000   -1487.049    -733.590\\nlight snow/rain -1273.7519    239.422     -5.320      0.000   -1744.160    -803.344\\n==============================================================================\\nOmnibus:                       69.587   Durbin-Watson:                   1.898\\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              136.276\\nSkew:                          -0.788   Prob(JB):                     2.56e-30\\nKurtosis:                       4.995   Cond. No.                         16.5\\n==============================================================================\\n\\nWarnings:\\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"10 features have been selected.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"All the features are statistically significant \", \"[low p-value]\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The model over is a good fit with Prob (F-statistic): 4.89e-187\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The model explains 83.6% variability in the training data. Adjusted R-square being 83.3%\")), mdx(\"h2\", {\n    \"id\": \"residual-analysis\"\n  }, \"Residual Analysis\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Residual Analysis of Trained Data\\nX_train_sm = sm.add_constant(X_train[selected_features])\\n\\ny_train_pred = final_model.predict(X_train_sm)\\nfig,ax = plt.subplots(1,2)\\nfig.set_figheight(8)\\nfig.set_figwidth(16)\\n\\nax[0].set(title='Frequency Distribution of Residuals')\\nsns.distplot(y_train-y_train_pred, bins=30, ax=ax[0])\\n\\nax[1].set(title='Predicted Values vs Residuals')\\n\\\\\\nsns.regplot(y_train_pred,y_train-y_train_pred,ax=ax[1])\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"953px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"50.2623294858342%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABsklEQVQoz12S3WsTQRTF8/8j9M0nH4QWBB+s0JeCtIUqsTXYNhba1JgPmxjjJulmd2cz33u8d2Y3sS4cZmbvnd/cOXdaWms45+C9hxACWZYhz3M8pWsYY8L/qqpCjrU2rJXSIS+jPB415SnjQk5LSrkF8kb+CmkxXIgw51gDNCYCgZhnfQVJoEIapKWGZ2BTBcs5HxJ/pyU6w2UN3FXIGxRB5+tNWPdma4wWBdr9BCd3czrHo8VX3gJ9BP4i4MVgEYF1zBO0kBrfJinedh7RpfHFcQ97Hx7w7usEh1cTzJ7K/4B1heOlwNHNNPhSVTugIOCqUOg+pvj4PcHLsz5enQ9wdj9HZ7TCZCWeexgqpI2nlPDmcow1+cJ+cSw2xIU4H7zIZQBMSb1ZBqEMNqRnHjbQ49sZ9tsjJLSpAf7bZa6avSyVhbEOqVDYaEvdtjugq7vHgfdXUxx8HuPnUmx9ZKCrgSwGaVPLRilNFSqltkDWNfnz+tMw6PwhCR1mcXUsnu+eWBXBNlph+dkwcCMVlnmJ0Z8Mlz+SKOryl0GCeSpg6Rb8NV5yIxvxI+eRb6qoH38ByeUAcfS3uaEAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/f569aa67afc4f2c48d079ec72b0bd1aa/49089/output_82_0.webp 953w\"],\n    \"sizes\": \"(max-width: 953px) 100vw, 953px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/f569aa67afc4f2c48d079ec72b0bd1aa/0d20c/output_82_0.png 953w\"],\n    \"sizes\": \"(max-width: 953px) 100vw, 953px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/f569aa67afc4f2c48d079ec72b0bd1aa/0d20c/output_82_0.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Mean of Residuals\\n(y_train-y_train_pred).mean()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"4.763163951972846e-12\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Residual errors follow a normal distribution with mean=0\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Variance of Errors doesnt follow any trends\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Residual errors are independent of each other since the Predicted values vs Residuals plot doesn\\u2019t show any trend.\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Verifying the normality of distribution of residuals\\nmean = (y_train-y_train_pred).mean()\\nstd = (y_train-y_train_pred).std()\\n\\nref_normal = np.random.normal(mean,std,(y_train-y_train_pred).shape[0])\\n\\n\\npercs = np.linspace(0,100,21)\\nqn_ref_normal = np.percentile(ref_normal, percs)\\nqn_residual = np.percentile(y_train - y_train_pred , percs)\\n\\nplt.plot(qn_ref_normal,qn_residual, ls=\\\"\\\", marker=\\\"o\\\")\\n\\nx = np.linspace(np.min((qn_ref_normal.min(),qn_residual.min())), np.max((qn_ref_normal.max(),qn_residual.max())))\\nm = plt.plot(x,x, color=\\\"k\\\", ls=\\\"--\\\")\\nplt.title('Q-Q Plot : Reference Normal vs Distribution of Residuals ')\\nplt.savefig('q-q-plot.png')\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"384px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"67.96875%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAABoElEQVQ4y41U2U7DQAzM/38LPwESUl94AAFCUCHlaHPfd3MMGSdbQptKjLSK1/baY683GiYMwwDf93E4HBAEAY7HI0zThG3bIlPveZ7sdV0Xm/K3LAuGYaBtaoaCFoYhTqcTqqpCURTyLcsSaZrKnivLMtFxUVb6fPEnib3pTsRGaDSQITGOIxT+IxPlkrCoG4mjMXrXdbIh077vZV3Ks73DOPQSKEgyvOwNhEnOLOcYGikrhjxMBlxruVtkIi5qPLwZePqykFYN1B2cAzZNg7ZtNxnOjj2Gfma1+7Rx9/iObzuaA/Ud+sln7a8Ni+IWQ4L9uX/Vsfswp/JUNb/nVAwJyLHY6iF1hBcleP4yEaa57OnTrXyGS4Ys95IhQX2aJHCCGO0SfM1KVXHF0HEcyaQy0pFjwMFlfwllXzO5ybCu63MmsoqiSGZrXG5+3eMtVle3TIY05HkuE89MPNi020zWsirzD0PVaD4rlsgRqdsOpp+KzL6pKtRBJuSX/mtZAqoxIcg2jmOR7en2+Sxp4ySoB8AvwYpc1xWZ/wNWR/wAScVDqAPmkAIAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/13143c212e4aee8e78ed4f76cf5c977e/8d1ab/output_85_0.webp 384w\"],\n    \"sizes\": \"(max-width: 384px) 100vw, 384px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/13143c212e4aee8e78ed4f76cf5c977e/b492f/output_85_0.png 384w\"],\n    \"sizes\": \"(max-width: 384px) 100vw, 384px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/13143c212e4aee8e78ed4f76cf5c977e/b492f/output_85_0.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"This plot further shows that the residual distribution is approximately normal for all test data with values within range of training data.\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# lag plot to assess independence of data points\\nfrom pandas.plotting import lag_plot\\nlag_plot(y_train-y_train_pred)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"<matplotlib.axes._subplots.AxesSubplot at 0x7fde4fb985d0>\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"397px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"65.4911838790932%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAACWUlEQVQ4y3VTy2oUURCd/3AnLtwpuHQhih/hL7iVgCLZiAslJmtxLSKKGJTEOEGNq2ggYUwiM+Mz0clMJky/u2/f24/bx6pqexTEC0XfR9WpU6eqW6AVxzGUUijLEkVRIM9z+capobsCUZrBjzVQWeR0fxQowFqYLJf3guIqW8e2GJDB0jQlHyvGwNZWcKKUHC0F1EDdYYBxkErw5p6L/UksICW9T8hXUwIBjKJIWNaApWTWeQFlciidIc0K9IY+3n+b4M7LPu6ufcHVJ9tYaPex+nEENzYYeYlUJIBZlonZqkJFxplMXiJQGZZ3hlj/6uDhxj5mF3dxfn4Nx2ae4+TsCs7NvcF8u4dX3bEkZSItZsXLGEP0S9rVgJx1i8r6PA7xrHOAS/fWcfbWa5y60caJ68s4Td8zN1cx8/gDlraHJIWqGXKpDMYMmZ0yBWkT4ZC0OiLbGXiS/dNhgMv3N3Fx4S2OX1vCBWI6t9LDg3d7yIhITqZJIgEMgkA0dIiVlxjqqkG9LGLSkEVn1k+3BqLh7RddXHnUQeeHK02J0lwm4J8ucyBYR2oM68kSNJIMSfSBmxDTEItbP7Hx3ZG9AJV2OnICmCSJAHLJDMAPvGcnNtbViTQOPEWgCv1RIF+dFfJeCYm/GDYl/w+Q79w4JdMSyFKENOw8m1xNSXeBMn8AuSlsTbZmwNmaM0vBTMvfCbkJvqpnlN95z/GtShzrJTOoNVzXlXMYhmK8PM+bypKSj9yFEVw/QF2lL71oNUANMP/HXD4vBmAnXr7vw3GcqU/zQ2jyafrA51/kktNlQxkQTAAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/ac624317c9e71585e8a69e1ffd54f707/ae302/output_87_1.webp 397w\"],\n    \"sizes\": \"(max-width: 397px) 100vw, 397px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/ac624317c9e71585e8a69e1ffd54f707/4e17c/output_87_1.png 397w\"],\n    \"sizes\": \"(max-width: 397px) 100vw, 397px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/ac624317c9e71585e8a69e1ffd54f707/4e17c/output_87_1.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Lagplot of residuals shows no trend. Hence the error terms have constant variance\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hence, assumptions of Linear Regression are satisfied by this model\")), mdx(\"h2\", {\n    \"id\": \"prediction\"\n  }, \"Prediction\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"y_test = dtest.pop('cnt')\\nX_test = dtest\\nX_test[num_vars] = numerical_scaler.transform(X_test[num_vars])\\nX_test = X_test[selected_features]\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_test = sm.add_constant(X_test)\\ny_test_pred = final_model.predict(X_test)\\n\")), mdx(\"h2\", {\n    \"id\": \"model-evaluation\"\n  }, \"Model Evaluation\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# Plotting Actual vs Predicted No of rentals\\nfig,ax = plt.subplots()\\nfig.set_figheight(8)\\nfig.set_figwidth(20)\\nl1,=ax.plot(range(len(y_test)),y_test)\\nl2, = ax.plot(range(len(y_test_pred)),y_test_pred)\\nplt.legend([l1,l2],['Actual','Predicted'])\\nplt.title('Predicted vs Actual No of Rentals');\\nplt.ylabel('No of Bike Rentals')\\nplt.xticks([])\\nplt.show()\\n\\nplt.figure(figsize=[8,8])\\nplt.scatter(y_test,y_test_pred);\\nplt.title('Predicted vs Actual No of Rentals');\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1172px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"39.50511945392492%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABpElEQVQozzWSCZPTMAyF8/9/F7OwQGFgaUvTg15Jm6O5beew86Fku57R2JKfniU/ec45mqZmGAamNY4ON46yj5PDdK+Ums1oJb6d4xNufOIEyWDdjPX6vqftBzqj6FtF0zkK1VKbjnawqLZHdRbTy8OtpRsclbFYYanaYSbqTUNSaXo5e1NlphuILjuy4y/SKCC9nWjKB3FW8rj4cs7Is5R7cERXOcdbQpymxFHIPU4o70eO/pt0UeMpbeh0RbRdEK9fCNefuYmVhZBcNyT+V6LzlizcU5yXJNcdweoLp81Pon9/uPk/UMGKy+oVkwV4TdOgtSY5bwT4wm35iXz3TQgOJJIQ/n0l9BcUhwXZeT0/bPI7VXIlf8TS1W+q0Ge3XFA+7u9/aKVtnZyIjmuqMsfqkiQ4SPJ36jSgjK8Upzeq25b6vsf2rXRVY0WEtogos4T9JcS0LV7XdTg7zIJoY2bFpqWbEhVJ8tAxCEFbxvQqR8vfTgU4289YayqUxCqlGQXrWWtn6Z3cuuc4TPJ/jIx143OcmAlm+xiXyYRklIKY8yz/AXR1Ys6SX9XNAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/edbf5da11059d439e8b21f5487aef0f7/fccb5/output_93_0.webp 1172w\"],\n    \"sizes\": \"(max-width: 1172px) 100vw, 1172px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/edbf5da11059d439e8b21f5487aef0f7/08110/output_93_0.png 1172w\"],\n    \"sizes\": \"(max-width: 1172px) 100vw, 1172px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/edbf5da11059d439e8b21f5487aef0f7/08110/output_93_0.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"489px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"97.95501022494886%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAACk0lEQVQ4y51VyY7TQBD1/x/5Ac5cENw4ICHQjEAgBmYkGMJkgCyOHe9be2kvj6qyOzhRBiQsdbrdS/Wr9145Vtu26LrubPM8D9vtFmEYwnVdOI4D3/exs23EcYS+72Vf3/85YyVJAqXUYXHetNbgC5umOfQ8v48LqGoca5pv21lA0DMMgwTk/rTxw2sYN0J3PcKiRqU7mUpLjW1U8qLst9I0RVEUZxEyKp4XWqjvaa7RhJSQdxR4FeR48n6Fq18hhn5E+1eEBlk39fy+CRXsWMFNK3z4GeC7m+H1wsPl0kesmhHhQxxy48DjuEeQlYLKoYCvbl0s9xmeX20kcJBVqBpC2AqpY2qmMVd5pVE2nOqAHQVQNL6nAKugwPU6ws02QUuX7OJyymTisK5rUW8e0KRfUNDlPh/5pMNf7EQ4e0fpiWBDL5c2bXc4Z7EgVVUdpWwWs7JGkNdQdYOnHzd49HKBhZMym8KrUDLtNecsQ7ZBNY5HuzBvd4TQjhQu7nwJuiZRWuEWR0KasRVFEYky8qCnquFUVK2Jn0IIf3FjU6prLN1U5lmUh0ScbCO/KOpWSFbU3+5SQlPg2Scbjy9+4O19ICoam5n+tEnpMY9iXDJnmFdYk5Jf7Rg+2eR6EwuXYp8pA+OKswiNzxihJrXYnCyEk5RiHX543nA9N/xZDotCiW1Y+pwK/hupyIb1yKhc9OZC0xtk8/cjlcuypK9KI/yURPibxR6fybg+BdT/E1CKn15YPa7Tyztv9NjMSiMlxymf1v8hZa7luq6QEV8sBgdm27AHza3zr868nxfCkbFN7XJ5sThs7HNI/oVQAhpPJXEMrus8z5FlmYzZ9PzVDoJANvNfAiPhd7OXLcdfq5jO8/MbGqQT+Lp231MAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/static/c015ff3ed7b50f920d936d862c27b8be/1b445/output_93_1.webp 489w\"],\n    \"sizes\": \"(max-width: 489px) 100vw, 489px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"//blog/static/c015ff3ed7b50f920d936d862c27b8be/7600e/output_93_1.png 489w\"],\n    \"sizes\": \"(max-width: 489px) 100vw, 489px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"//blog/static/c015ff3ed7b50f920d936d862c27b8be/7600e/output_93_1.png\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Predicted vs observed value plots shows that the model is reasonably accurate.\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.metrics import mean_squared_error,r2_score\\nmse = mean_squared_error(y_test, y_test_pred)\\nrsquared_test = r2_score(y_test, y_test_pred)\\nrsquared_train = r2_score(y_train, y_train_pred)\\nprint('R-squared for train data:',round(rsquared_train,2))\\nprint('R-squared for test data:',round(rsquared_test,2))\\nprint('Mean Squared Error',round(mse,3))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"R-squared for train data: 0.84\\nR-squared for test data: 0.81\\nMean Squared Error 666097.695\\n\")), mdx(\"h2\", {\n    \"id\": \"model-stability\"\n  }, \"Model Stability\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# R-square using cross validation\\n\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.linear_model import LinearRegression\\nlr = LinearRegression()\\nclr = cross_val_score(lr,X_train[selected_features],y_train,cv=10, scoring='r2')\\nclr\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"array([0.76577509, 0.89378885, 0.73439962, 0.87831664, 0.84127272,\\n       0.85375903, 0.87521829, 0.68697543, 0.73861901, 0.87571386])\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(\\\"R-square at 0.95 confidence level : %0.2f (+/- %0.2f)\\\" % (clr.mean(), clr.std() * 2))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"R-square at 0.95 confidence level : 0.81 (+/- 0.14)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"selected_features\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"array(['yr', 'Saturday', 'winter', 'july', 'spring', 'workingday', 'hum',\\n       'temp', 'windspeed', 'light snow/rain'], dtype=object)\\n\")), mdx(\"h2\", {\n    \"id\": \"top-features\"\n  }, \"Top Features\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# standardizing numerical variables\\n\\nfrom sklearn.preprocessing import StandardScaler\\nreg_features = selected_features\\nscaler = StandardScaler()\\ndata = X_train[selected_features]\\nstd_num = scaler.fit(data[['temp','windspeed','hum']])\\n\\n\\nstd_X_train = pd.DataFrame(data = scaler.transform(data[['temp','windspeed','hum']]), columns=['temp','windspeed','hum'])\\nfor i in reg_features :\\n    std_X_train[i] = data[i].values\\n\\n\\nreshaped_y_train = y_train.values.reshape(-1,1)\\n\\n# Fitting linear regression model\\nstd_model = lr.fit(std_X_train, reshaped_y_train)\\n\\n# Coefficients and intercept\\nresult = pd.DataFrame(data = std_model.coef_, columns = std_X_train.columns, index=['MLR Coefficients']).T\\nresult = result.sort_values(by='MLR Coefficients',ascending=False)\\nprint('\\\\nIntercept :',std_model.intercept_)\\nresult\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Intercept : [2392.07911232]\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Upon standardized the values of predictor variables, the above shows that the top features influencing demand are \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"temp\"), \", followed by \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"yr\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"hum\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"In case of continuous variables, the above data could be interpreted as - With every standard deviation increase in continuous variables, demand increases by \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"xxx\"), \", when all other modelled paramters are held unchanged.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"In case of categorical variables, the above data could be interpreted as - Compared to the reference level, the change in demand is \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"xxx\"), \",, when all other modelled paramters are held unchanged.\")), mdx(\"h2\", {\n    \"id\": \"conclusion\"\n  }, \"Conclusion\"), mdx(\"p\", null, \"Analysis is carried out using a Mixed Feature Selection Approach. 15 features are selected algorithmically using Recursive Feature Elimination. Further selection is done manually by looking at multicollinearity and statistical significance of features and overall fit of the model.\\nThe 10 most significant features to understand demand have been reported.\"), mdx(\"p\", null, \"The data set is randomly divided into training and test data.\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Final Model\"), \" built on training data set explains 84% of the variability and achieves 81% on test data.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"The final relationship between demand and predictors is as follows.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cnt\"), \" = 2392.0791 + 1946.7864 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"yr\"), \" + 444.4907 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Saturday\"), \" + 466.0136 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"winter\"), \" - 890.3115 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"july\"), \" -1063.6669 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"spring\"), \" + 296.8008 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"workingday\"), \" - 1749.8275 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"hum\"), \" + 4471.6602 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"temp\"), \" - 1110.3191 \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \" \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"windspeed\"), \" - 1273.7519 \"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"light snow/rain\"))), mdx(\"p\", null, \"where \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"temp\"), \" , \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"windspeed\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"hum\"), \" are normalized.\"), mdx(\"p\", null, \"Note :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Data has been cleaned to drop outliers that might affect the model adversely\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The model has been verified for Multicollinearity effects.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Residual Analysis has been carried out and the model satisfies the assumptions of Linear Regression (Residuals follow a normal distribution, Errors exhibit homoscedasticity)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Q-Q plot between residual distribution and normal distribution shows that residuals follow a normal distribution for all interpolations. Extraplorations show significant deviation, not affecting Linear Regression applicability.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Further Lag plot shows there is no auto-correlation in data.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Model is stable at 81%(+/-14%) coefficient of determination at 95% CI, ascertained through cross validation.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Features in the order of influence has been reported by standardizing all predictor values.\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","hero":{"full":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABpElEQVQozzWSCZPTMAyF8/9/F7OwQGFgaUvTg15Jm6O5beew86Fku57R2JKfniU/ec45mqZmGAamNY4ON46yj5PDdK+Ums1oJb6d4xNufOIEyWDdjPX6vqftBzqj6FtF0zkK1VKbjnawqLZHdRbTy8OtpRsclbFYYanaYSbqTUNSaXo5e1NlphuILjuy4y/SKCC9nWjKB3FW8rj4cs7Is5R7cERXOcdbQpymxFHIPU4o70eO/pt0UeMpbeh0RbRdEK9fCNefuYmVhZBcNyT+V6LzlizcU5yXJNcdweoLp81Pon9/uPk/UMGKy+oVkwV4TdOgtSY5bwT4wm35iXz3TQgOJJIQ/n0l9BcUhwXZeT0/bPI7VXIlf8TS1W+q0Ge3XFA+7u9/aKVtnZyIjmuqMsfqkiQ4SPJ36jSgjK8Upzeq25b6vsf2rXRVY0WEtogos4T9JcS0LV7XdTg7zIJoY2bFpqWbEhVJ8tAxCEFbxvQqR8vfTgU4289YayqUxCqlGQXrWWtn6Z3cuuc4TPJ/jIx143OcmAlm+xiXyYRklIKY8yz/AXR1Ys6SX9XNAAAAAElFTkSuQmCC","aspectRatio":2.5376344086021505,"src":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/a1946/output_93_0.png","srcSet":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/5b37e/output_93_0.png 236w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/49058/output_93_0.png 472w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/a1946/output_93_0.png 944w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/fa56b/output_93_0.png 1172w","srcWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/99fbb/output_93_0.webp","srcSetWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/77392/output_93_0.webp 236w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/1f177/output_93_0.webp 472w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/99fbb/output_93_0.webp 944w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/cd064/output_93_0.webp 1172w","sizes":"(max-width: 944px) 100vw, 944px"},"regular":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABpElEQVQozzWSCZPTMAyF8/9/F7OwQGFgaUvTg15Jm6O5beew86Fku57R2JKfniU/ec45mqZmGAamNY4ON46yj5PDdK+Ums1oJb6d4xNufOIEyWDdjPX6vqftBzqj6FtF0zkK1VKbjnawqLZHdRbTy8OtpRsclbFYYanaYSbqTUNSaXo5e1NlphuILjuy4y/SKCC9nWjKB3FW8rj4cs7Is5R7cERXOcdbQpymxFHIPU4o70eO/pt0UeMpbeh0RbRdEK9fCNefuYmVhZBcNyT+V6LzlizcU5yXJNcdweoLp81Pon9/uPk/UMGKy+oVkwV4TdOgtSY5bwT4wm35iXz3TQgOJJIQ/n0l9BcUhwXZeT0/bPI7VXIlf8TS1W+q0Ge3XFA+7u9/aKVtnZyIjmuqMsfqkiQ4SPJ36jSgjK8Upzeq25b6vsf2rXRVY0WEtogos4T9JcS0LV7XdTg7zIJoY2bFpqWbEhVJ8tAxCEFbxvQqR8vfTgU4289YayqUxCqlGQXrWWtn6Z3cuuc4TPJ/jIx143OcmAlm+xiXyYRklIKY8yz/AXR1Ys6SX9XNAAAAAElFTkSuQmCC","aspectRatio":2.546875,"src":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/3ddd4/output_93_0.png","srcSet":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/078a8/output_93_0.png 163w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/e56da/output_93_0.png 327w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/3ddd4/output_93_0.png 653w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/c5cc7/output_93_0.png 980w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/fa56b/output_93_0.png 1172w","srcWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/0acdf/output_93_0.webp","srcSetWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/ac59e/output_93_0.webp 163w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/7660b/output_93_0.webp 327w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/0acdf/output_93_0.webp 653w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/75470/output_93_0.webp 980w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/cd064/output_93_0.webp 1172w","sizes":"(max-width: 653px) 100vw, 653px"},"narrow":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABpElEQVQozzWSCZPTMAyF8/9/F7OwQGFgaUvTg15Jm6O5beew86Fku57R2JKfniU/ec45mqZmGAamNY4ON46yj5PDdK+Ums1oJb6d4xNufOIEyWDdjPX6vqftBzqj6FtF0zkK1VKbjnawqLZHdRbTy8OtpRsclbFYYanaYSbqTUNSaXo5e1NlphuILjuy4y/SKCC9nWjKB3FW8rj4cs7Is5R7cERXOcdbQpymxFHIPU4o70eO/pt0UeMpbeh0RbRdEK9fCNefuYmVhZBcNyT+V6LzlizcU5yXJNcdweoLp81Pon9/uPk/UMGKy+oVkwV4TdOgtSY5bwT4wm35iXz3TQgOJJIQ/n0l9BcUhwXZeT0/bPI7VXIlf8TS1W+q0Ge3XFA+7u9/aKVtnZyIjmuqMsfqkiQ4SPJ36jSgjK8Upzeq25b6vsf2rXRVY0WEtogos4T9JcS0LV7XdTg7zIJoY2bFpqWbEhVJ8tAxCEFbxvQqR8vfTgU4289YayqUxCqlGQXrWWtn6Z3cuuc4TPJ/jIx143OcmAlm+xiXyYRklIKY8yz/AXR1Ys6SX9XNAAAAAElFTkSuQmCC","aspectRatio":2.533333333333333,"src":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/502b1/output_93_0.png","srcSet":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/f2e6d/output_93_0.png 114w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/4ddba/output_93_0.png 229w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/502b1/output_93_0.png 457w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/7ddc2/output_93_0.png 686w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/435bf/output_93_0.png 914w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/fa56b/output_93_0.png 1172w","srcWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/15384/output_93_0.webp","srcSetWebp":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/31fce/output_93_0.webp 114w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/e3e25/output_93_0.webp 229w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/15384/output_93_0.webp 457w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/0258d/output_93_0.webp 686w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/64ea2/output_93_0.webp 914w,\n//blog/static/edbf5da11059d439e8b21f5487aef0f7/cd064/output_93_0.webp 1172w","sizes":"(max-width: 457px) 100vw, 457px"},"seo":{"src":"//blog/static/edbf5da11059d439e8b21f5487aef0f7/fa56b/output_93_0.png"}}}]}},"staticQueryHashes":["1143375668","1491088328","1921650733","2068910035","2444214635"]}